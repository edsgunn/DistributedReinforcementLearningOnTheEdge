{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.000.000.000.000.00\n",
      "0.000.000.000.000.00\n",
      "0.000.000.000.000.00\n",
      "0.000.000.000.000.00\n",
      "0.000.000.000.000.00\n",
      "\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-0.99-0.99-0.99-0.99-0.99\n",
      "-0.99-0.90-0.90-0.90-0.90\n",
      "-0.90-0.90-0.90-0.900.00\n",
      "0.000.000.000.000.00\n",
      "0.000.000.000.000.00\n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.629}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.719, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.719, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-0.99-0.99-0.99-0.99-0.99\n",
      "-0.99-1.72-0.99-1.72-0.99\n",
      "-0.99-0.99-0.90-0.90-0.90\n",
      "-0.90-0.900.000.000.00\n",
      "0.000.000.000.000.00\n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.8009, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.3913900000000003, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.3913900000000003, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.3913900000000003, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8747, 2: -1.8009, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.629}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.629}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -1.719, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-1.87-1.72-0.99-0.99-0.99\n",
      "-1.72-1.72-1.72-1.72-0.99\n",
      "-0.99-1.72-0.99-0.90-0.90\n",
      "-0.99-0.99-0.90-0.900.00\n",
      "-0.90-0.90-0.900.000.00\n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.8747, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.3913900000000003, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.719, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.629}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.8009}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.8009}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.8009}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.3913900000000003, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.3913900000000003, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.3913900000000003, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.523339, 3: -2.4724800000000005, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -2.47887, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.47887, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.629}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-1.88-1.79-1.72-1.72-0.99\n",
      "-2.46-1.79-1.72-1.72-0.99\n",
      "-1.80-1.72-1.63-1.72-0.99\n",
      "-1.72-1.72-0.99-0.900.00\n",
      "-1.72-0.99-0.900.000.00\n",
      "\n",
      "Action values: {0: -1.88199, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.539638, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.539638, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.539638, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5315290000000004, 2: -2.46429, 3: -2.4724800000000005, 4: -3.0834549000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5315290000000004, 2: -2.597868, 3: -2.4724800000000005, 4: -3.0834549000000004}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5315290000000004, 2: -2.597868, 3: -2.4724800000000005, 4: -3.0834549000000004}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5315290000000004, 2: -2.597868, 3: -3.1499568000000004, 4: -3.0834549000000004}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.539638, 3: -3.2236822800000002, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.4724800000000005, 3: -3.0818988000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.4724800000000005, 3: -3.0818988000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.46519, 2: -2.4724800000000005, 3: -3.0818988000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -3.0818988000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -2.4724800000000005, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.719, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46429, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -1.8009, 3: -2.5306290000000002, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46429, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.629}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.629}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -2.38239}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.39229, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.46429, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.39229, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.39229, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -2.5306290000000002}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-2.55-2.54-2.47-1.88-1.88\n",
      "-2.53-2.47-2.46-1.72-1.72\n",
      "-1.80-1.72-1.79-1.72-0.99\n",
      "-1.72-1.72-0.99-0.900.00\n",
      "-1.72-0.99-0.900.000.00\n",
      "\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.6126928, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.6126928, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.6126928, 3: -3.2236822800000002, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -2.5396380000000005, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.3913900000000003, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.3913900000000003, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46429, 2: -1.8738000000000001, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46429, 2: -1.8738000000000001, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46429, 2: -1.8738000000000001, 3: -2.46429, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -2.5315290000000004, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -2.5315290000000004, 2: -2.6716599, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -2.6716599, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -3.1566726000000007, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -3.1566726000000007, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -3.1566726000000007, 3: -3.0818988000000003, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -3.21837606, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -3.21837606, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3439624209, 1: -3.1440609000000004, 2: -3.21837606, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -2.5315290000000004, 2: -2.597868, 3: -3.2648051700000007, 4: -3.0834549000000004}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.523339, 3: -2.4724800000000005, 4: -1.8009}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.523339, 3: -2.4724800000000005, 4: -1.8009}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.523339, 3: -2.4724800000000005, 4: -2.538819}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -2.6118819, 2: -2.597868, 3: -3.2648051700000007, 4: -3.0834549000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.664207, 3: -3.0818988000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.47887, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.47887, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.47887, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-3.22-3.14-2.61-2.53-2.47\n",
      "-2.61-2.54-2.46-1.87-1.72\n",
      "-2.47-1.87-1.79-1.72-0.99\n",
      "-1.72-1.72-1.72-0.900.00\n",
      "-1.72-0.99-0.900.000.00\n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2649445800000003, 2: -3.21837606, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1425939, 2: -3.1566726000000007, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.664207, 3: -3.0818988000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -2.47887, 4: -2.546109}, Best action: 2, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -2.46519, 2: -2.523339, 3: -2.4724800000000005, 4: -3.1499568}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -1.719, 4: -1.8738000000000001}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -1.719, 4: -1.8738000000000001}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -2.46429, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -2.5389090000000003, 2: -2.523339, 3: -2.4724800000000005, 4: -3.1499568}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -2.5389090000000003, 2: -2.523339, 3: -2.4724800000000005, 4: -3.1499568}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -2.5389090000000003, 2: -2.523339, 3: -3.1499568000000004, 4: -3.1499568}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.1446909, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8747, 2: -1.8009, 3: -1.7919, 4: -2.5306290000000002}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.538819, 3: -3.1446909, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1617756000000004, 2: -2.664207, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1617756000000004, 2: -2.664207, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1617756000000004, 2: -2.664207, 3: -3.0818988000000003, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46429, 2: -1.8738000000000001, 3: -2.46429, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-3.22-3.16-2.61-2.53-2.47\n",
      "-2.61-3.08-2.54-2.46-1.87\n",
      "-2.54-2.47-1.80-1.72-0.99\n",
      "-2.46-1.79-1.72-0.900.00\n",
      "-1.87-1.72-0.990.000.00\n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2649445800000003, 2: -3.767338665, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2649445800000003, 2: -3.767338665, 3: -3.2236822800000002, 4: -3.337977087}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2649445800000003, 2: -3.767338665, 3: -3.8335508748000002, 4: -3.337977087}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -2.6118819, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.0834549000000004}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -2.5389090000000003, 2: -2.6701119, 3: -3.25890027, 4: -3.1499568}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -2.664207, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-3.34-3.16-2.61-2.53-2.47\n",
      "-3.08-3.08-2.54-2.46-1.87\n",
      "-2.67-2.47-1.80-1.72-0.99\n",
      "-2.47-1.87-1.72-0.900.00\n",
      "-1.87-1.87-1.000.000.00\n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.3421187970000004, 2: -3.767338665, 3: -3.9279601972800005, 4: -3.337977087}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.3421187970000004, 2: -3.767338665, 3: -3.9279601972800005, 4: -3.337977087}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.3421187970000004, 2: -3.767338665, 3: -3.9279601972800005, 4: -3.93755914917}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -3.21770448, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.0834549000000004}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -3.21770448, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.0834549000000004}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -3.21770448, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.7059439590000007}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1617756000000004, 2: -3.1624956, 3: -3.0818988000000003, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2101696800000004, 1: -3.21770448, 2: -3.7119970980000003, 3: -3.2648051700000007, 4: -3.8274328629000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7318103487000007, 2: -3.767338665, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.21770448, 2: -3.7119970980000003, 3: -3.2648051700000007, 4: -3.8274328629000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.1499658000000004, 2: -2.6701119, 3: -3.25890027, 4: -3.1499568}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.46519, 2: -2.538819, 3: -3.1446909, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8747, 2: -1.8009, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-3.77-3.16-2.61-2.53-2.47\n",
      "-3.26-3.15-2.54-2.46-1.87\n",
      "-3.15-2.54-1.87-1.72-1.00\n",
      "-2.47-2.46-1.72-0.900.00\n",
      "-1.87-1.87-1.000.000.00\n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.8795216636700003, 2: -3.767338665, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.2707756800000003, 2: -3.1566726000000007, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -2.6716599, 3: -3.22197948, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -2.6716599, 3: -3.22197948, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -2.6716599, 3: -3.22197948, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -2.5315290000000004, 2: -2.6716599, 3: -3.2560755390000002, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46429, 2: -2.4797700000000003, 3: -2.46429, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-3.78-3.16-3.09-2.61-2.47\n",
      "-3.26-3.15-2.54-2.46-1.87\n",
      "-3.15-2.54-1.87-1.79-1.00\n",
      "-2.47-2.46-1.73-0.990.00\n",
      "-1.87-1.87-1.000.000.00\n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.8795216636700003, 2: -3.8336386725000007, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.8795216636700003, 2: -3.8336386725000007, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340787869691901, 1: -3.8795216636700003, 2: -3.8336386725000007, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.2707756800000003, 2: -3.3258452400000005, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.2707756800000003, 2: -3.3258452400000005, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7738391409000003, 1: -3.2707756800000003, 2: -3.3258452400000005, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1617756000000004, 2: -3.1624956, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.3258452400000005, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.0850029, 2: -3.2177044800000005, 3: -3.22197948, 4: -3.391113897}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.664207, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8747, 2: -2.4724800000000005, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-3.84-3.38-3.16-2.61-2.47\n",
      "-3.26-3.16-2.55-2.46-1.87\n",
      "-3.15-2.54-2.47-1.79-1.00\n",
      "-2.47-2.46-1.79-0.990.00\n",
      "-1.87-1.87-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.43932611169419, 1: -3.8795216636700003, 2: -3.8413965091500004, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.7314368730000003, 3: -3.3835850019, 4: -3.7180339470000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -3.8795216636700003, 2: -4.024843502454, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.3845610870000002, 2: -3.7119970980000003, 3: -3.2648051700000007, 4: -3.8274328629000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.3845610870000002, 2: -3.7119970980000003, 3: -3.2648051700000007, 4: -3.8274328629000003}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.3845610870000002, 2: -3.7119970980000003, 3: -3.8709727047000007, 4: -3.8274328629000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.1499658000000004, 2: -3.16381509, 3: -3.25890027, 4: -3.1499568}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.1499658000000004, 2: -3.16381509, 3: -3.25890027, 4: -3.1499568}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.1499658000000004, 2: -3.16381509, 3: -3.25890027, 4: -3.766460688}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.1499568000000004, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.27734397, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.27734397, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.664297, 2: -2.538819, 3: -3.1446909, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.48715, 2: -2.4724800000000005, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8018, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.48715, 2: -2.598687, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.88199, 2: -1.8747, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8747, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-3.93-3.72-3.16-2.61-2.47\n",
      "-3.71-3.16-2.55-2.46-1.87\n",
      "-3.16-2.55-2.52-1.80-1.00\n",
      "-2.66-2.48-1.87-0.990.00\n",
      "-1.87-1.88-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.43932611169419, 1: -3.932444354067001, 2: -4.024843502454, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -3.932444354067001, 2: -4.024843502454, 3: -3.9279601972800005, 4: -4.000872140487001}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -3.932444354067001, 2: -4.024843502454, 3: -4.474443779524801, 4: -4.000872140487001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.7899211167, 2: -3.7119970980000003, 3: -4.02859175094, 4: -3.8274328629000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.1617756000000004, 2: -3.1624956, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.664297, 2: -3.1565907000000006, 3: -3.1446909, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.664297, 2: -3.1565907000000006, 3: -3.1446909, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.664297, 2: -3.1565907000000006, 3: -3.1446909, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.665026, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.88199, 2: -1.8747, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.00-3.72-3.16-2.61-2.47\n",
      "-3.79-3.16-2.55-2.46-1.87\n",
      "-3.16-3.14-2.52-1.80-1.00\n",
      "-2.66-2.55-1.88-1.000.00\n",
      "-1.87-1.88-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.43932611169419, 1: -4.2999620847867, 2: -4.024843502454, 3: -4.5327243047467505, 4: -4.000872140487001}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -4.2999620847867, 2: -4.024843502454, 3: -4.5327243047467505, 4: -4.000872140487001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -4.2999620847867, 2: -4.024843502454, 3: -4.5327243047467505, 4: -4.540793647843171}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.7314368730000003, 3: -4.380771047762701, 4: -3.7180339470000003}, Best action: 4, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -4.2999620847867, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.7899211167, 2: -3.8322379458000007, 3: -4.02859175094, 4: -3.8274328629000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.2177053800000004, 2: -3.16381509, 3: -3.25890027, 4: -3.8281183668000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1750434000000003, 2: -3.1565907000000006, 3: -3.1446909, 4: -3.379776489}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.2177053800000004, 2: -3.763581138, 3: -3.25890027, 4: -3.8281183668000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -3.1632246000000004}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.1499568000000004, 2: -2.4797700000000003, 3: -2.664207, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.897389, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.897389, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.6126109, 2: -1.897389, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.40-3.72-3.16-2.61-2.47\n",
      "-3.83-3.16-2.55-2.46-1.87\n",
      "-3.25-3.16-2.52-1.80-1.00\n",
      "-2.68-2.55-1.88-1.000.00\n",
      "-2.61-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.43932611169419, 1: -4.39983231300567, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.84168233457, 2: -3.8322379458000007, 3: -4.02859175094, 4: -3.8274328629000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.84168233457, 2: -3.8322379458000007, 3: -4.02859175094, 4: -3.8274328629000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.84168233457, 2: -3.8322379458000007, 3: -4.02859175094, 4: -4.382963905239001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.2785258500000003, 2: -3.1624956, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6723979, 2: -2.664207, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6723979, 2: -2.664207, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6723979, 2: -2.664207, 3: -3.0752649, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.26501658, 2: -3.2177044800000005, 3: -3.22197948, 4: -3.391113897}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.26501658, 2: -3.2177044800000005, 3: -3.22197948, 4: -3.391113897}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.26501658, 2: -3.2177044800000005, 3: -3.22197948, 4: -3.391113897}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -3.1492278000000002, 2: -2.6716599, 3: -3.2560755390000002, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -3.1492278000000002, 2: -2.6716599, 3: -3.2560755390000002, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -3.1492278000000002, 2: -2.6716599, 3: -3.2560755390000002, 4: -3.27069378}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0982869900000005, 1: -3.1492278000000002, 2: -2.6716599, 3: -3.2560755390000002, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -3.1962384900000007, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665026, 2: -2.4724800000000005, 3: -3.1962384900000007, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665026, 2: -2.4724800000000005, 3: -3.1962384900000007, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665026, 2: -3.1499568000000004, 3: -3.1962384900000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665026, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665026, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8747, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.44-3.72-3.22-3.15-2.69\n",
      "-3.84-3.28-2.66-2.46-1.90\n",
      "-3.25-3.16-2.52-1.80-1.00\n",
      "-2.68-2.55-1.88-1.000.00\n",
      "-2.61-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.43932611169419, 1: -4.440203850249568, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.43932611169419, 1: -4.440203850249568, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.939786761641714, 1: -4.440203850249568, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.84168233457, 2: -3.8448452305800003, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25070208, 1: -3.379851108, 2: -3.763581138, 3: -3.25890027, 4: -3.8281183668000005}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.9172369182569997, 2: -3.8448452305800003, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.2785258500000003, 2: -3.27859785, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1750434000000003, 2: -3.1565907000000006, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.600154, 2: -2.598687, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -2.6723979, 2: -2.664207, 3: -3.0752649, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538819, 2: -2.4797700000000003, 3: -2.46429, 4: -2.664207}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -2.6723979, 2: -3.1624956, 3: -3.0752649, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.600154, 2: -2.598687, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.600154, 2: -2.598687, 3: -3.0752649, 4: -2.5306290000000002}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.600154, 2: -2.598687, 3: -3.0752649, 4: -3.2028723900000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8018, 2: -1.8738000000000001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.46-3.72-3.22-3.15-2.69\n",
      "-3.92-3.28-3.08-2.48-1.90\n",
      "-3.26-3.18-2.60-1.87-1.00\n",
      "-2.68-2.55-1.88-1.000.00\n",
      "-2.61-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -4.455783076026657, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.9172369182569997, 2: -3.9400904615580004, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.379851108, 2: -3.763581138, 3: -3.25890027, 4: -3.8281183668000005}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.379851108, 2: -3.763581138, 3: -3.25890027, 4: -3.8281183668000005}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.379851108, 2: -3.763581138, 3: -3.8655992457, 4: -3.8281183668000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.6842077, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.22360938, 2: -2.6723889, 3: -2.664207, 4: -3.1632246000000004}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.2785987500000005, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.4121933477999997, 2: -3.763581138, 3: -4.024239322050001, 4: -3.8281183668000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.2785987500000005, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8997308, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.52-3.72-3.22-3.15-2.69\n",
      "-3.93-3.28-3.08-2.48-1.90\n",
      "-3.76-3.18-2.60-1.87-1.00\n",
      "-3.28-2.67-1.88-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -4.518540211390835, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -3.9314329105257, 2: -3.9400904615580004, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.79746731178, 2: -3.763581138, 3: -4.024239322050001, 4: -3.8281183668000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1750434000000003, 2: -3.25956366, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.705284548, 2: -2.666484, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.88199, 2: -1.88937, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999998999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.53-3.72-3.22-3.15-2.69\n",
      "-3.94-3.28-3.08-2.48-1.90\n",
      "-3.80-3.21-2.60-1.87-1.00\n",
      "-3.28-2.69-1.89-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -4.536314678664901, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -4.536314678664901, 2: -4.850908898933188, 3: -4.5327243047467505, 4: -4.614202601772057}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -4.536314678664901, 2: -4.850908898933188, 3: -5.024779117319543, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -4.341644012832571, 2: -3.9400904615580004, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.7846910520000003, 2: -3.27859785, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2170492800000003, 2: -3.1624956, 3: -3.0752649, 4: -3.337247358}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.7846910520000003, 2: -3.718824354, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.7846910520000003, 2: -3.718824354, 3: -3.8084273208000003, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.7846910520000003, 2: -3.718824354, 3: -3.8084273208000003, 4: -3.9755302659900003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2170492800000003, 2: -3.1624956, 3: -3.9450863970900003, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538819, 2: -2.4797700000000003, 3: -3.311071299, 4: -2.664207}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.1492278000000002, 2: -3.1698747900000006, 3: -3.2560755390000002, 4: -3.7366818399000006}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.538819, 2: -2.4797700000000003, 3: -3.311071299, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.897389, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.55-3.72-3.22-3.17-2.69\n",
      "-3.95-3.78-3.22-2.54-1.90\n",
      "-3.80-3.21-2.60-1.87-1.00\n",
      "-3.28-2.69-1.89-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -4.545104741728471, 2: -4.850908898933188, 3: -5.076892801450525, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -4.341644012832571, 2: -3.9496733046558004, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.7846910520000003, 2: -3.8335038714, 3: -3.8084273208000003, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.37735638, 2: -3.25956366, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.8775787101000003, 2: -3.8335038714, 3: -3.8084273208000003, 4: -4.309800753339001}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -4.341644012832571, 2: -4.360567082585581, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -4.341644012832571, 2: -4.360567082585581, 3: -4.02859175094, 4: -4.4424091266219}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.243783350447001, 1: -4.341644012832571, 2: -4.360567082585581, 3: -4.566018493355401, 4: -4.4424091266219}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -4.553745850944045, 2: -4.850908898933188, 3: -5.076892801450525, 4: -4.614202601772057}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.012912474309378, 1: -4.341644012832571, 2: -4.360567082585581, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.850908898933188, 3: -5.076892801450525, 4: -4.614202601772057}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.850908898933188, 3: -5.076892801450525, 4: -4.614202601772057}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.850908898933188, 3: -5.076892801450525, 4: -5.098924367612572}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.7314368730000003, 3: -4.821046393453497, 4: -3.7180339470000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.7314368730000003, 3: -4.821046393453497, 4: -3.7180339470000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.7314368730000003, 3: -4.821046393453497, 4: -4.28341089177}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.26501658, 2: -3.3319484280000005, 3: -3.22197948, 4: -3.391113897}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -3.7778791860000007, 2: -3.8829470661, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.8775787101000003, 2: -3.8335038714, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2170492800000003, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.600154, 2: -2.6193267000000002, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.898198919, 2: -1.88937, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -0.999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.40-3.88-3.27-3.17-2.69\n",
      "-4.34-3.88-3.33-2.54-1.90\n",
      "-3.80-3.26-2.62-1.87-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.396698386963319, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -4.382926054434, 2: -3.8829470661, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.26501658, 2: -3.3319484280000005, 3: -4.28228008866, 4: -3.391113897}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.327829668, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.6904051000000004, 2: -2.6193267000000002, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88937, 2: -1.8738000000000001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.48-3.93-3.33-3.17-2.69\n",
      "-4.34-3.88-3.34-2.54-1.90\n",
      "-3.80-3.26-2.68-1.89-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.484856962237332, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -4.382926054434, 2: -3.9329581364100004, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92671221489, 1: -4.382926054434, 2: -3.9329581364100004, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4733081155499, 1: -4.382926054434, 2: -3.9329581364100004, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.3319484280000005, 3: -4.28228008866, 4: -3.391113897}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.22353648, 2: -3.1698747900000006, 3: -3.2560755390000002, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.6850096, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8997308, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.53-3.99-3.39-3.22-2.71\n",
      "-4.34-3.88-3.34-2.54-1.90\n",
      "-3.80-3.26-2.68-1.89-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.529122590284633, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.382926054434, 2: -3.9921740403210006, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.800793422700001, 3: -4.28228008866, 4: -3.391113897}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.800793422700001, 3: -4.28228008866, 4: -3.391113897}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.800793422700001, 3: -4.28228008866, 4: -3.98591364627}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.22353648, 2: -3.3918452550000002, 3: -3.2560755390000002, 4: -3.7366818399000006}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.538819, 2: -2.68486209, 3: -3.311071299, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88937, 2: -1.89737919, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -0.9999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.59-4.05-3.88-3.26-2.71\n",
      "-4.34-3.88-3.34-2.66-1.90\n",
      "-3.80-3.26-2.68-1.90-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.586573231688474, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.382926054434, 2: -4.0460196606021, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.89114389107, 3: -4.28228008866, 4: -4.377234037014}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.92204368908, 2: -3.89114389107, 3: -4.28228008866, 4: -4.377234037014}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.434678318798901, 1: -3.92204368908, 2: -3.89114389107, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.278797038, 2: -3.3918452550000002, 3: -3.2560755390000002, 4: -3.7366818399000006}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -3.92204368908, 2: -3.926535575697, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.3544375938000006, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.3544375938000006, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.3544375938000006, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -3.93689509578}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.6904051000000004, 2: -2.67971067, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8988559999999999, 2: -1.89737919, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.64-4.35-3.93-3.28-2.71\n",
      "-4.34-3.88-3.41-2.66-1.90\n",
      "-3.80-3.26-2.69-1.90-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.635933248256549, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.382926054434, 2: -4.450854095980111, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.382926054434, 2: -4.450854095980111, 3: -4.821046393453497, 4: -4.350804956307001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.382926054434, 2: -4.450854095980111, 3: -4.821046393453497, 4: -4.85923251023937}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.8775787101000003, 2: -3.8891603039400002, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.37735638, 2: -3.25956366, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.6904051000000004, 2: -2.7048482109, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.898198919, 2: -1.8981270000000001, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -0.9999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.89-4.45-3.93-3.28-2.71\n",
      "-4.34-3.89-3.41-2.66-1.90\n",
      "-3.80-3.38-2.70-1.90-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.887745339434326, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.479131360624401, 2: -4.450854095980111, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -3.995374728888, 2: -3.926535575697, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.278797038, 2: -3.3918452550000002, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.6842716, 2: -2.68486209, 3: -3.311071299, 4: -2.664207}, Best action: 4, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.40600940208, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70652338, 2: -2.7048482109, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8988559999999999, 2: -1.8997379109, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -0.99999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.99-4.48-3.95-3.37-2.71\n",
      "-4.34-3.89-3.43-2.66-1.90\n",
      "-3.80-3.38-2.71-1.90-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.993966351687322, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990543794866321, 1: -5.415833689285001, 2: -4.993966351687322, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.441394853328353, 1: -5.415833689285001, 2: -4.993966351687322, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.479131360624401, 2: -4.5255792259125815, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.92800443561, 2: -3.8891603039400002, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.431527991037, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70652338, 2: -2.70855818109, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.898198919, 2: -1.8997317, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.03-4.50-3.95-3.37-2.71\n",
      "-4.34-3.91-3.44-2.66-1.90\n",
      "-3.80-3.38-2.71-1.90-1.00\n",
      "-3.28-2.69-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.027493037274497, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.498132982253841, 2: -4.5255792259125815, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9088484244000004, 1: -3.92800443561, 2: -4.0684537031339705, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.515980521989384, 2: -4.5255792259125815, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -3.92800443561, 2: -4.0684537031339705, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.37735638, 2: -3.4051844970000005, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.705284548, 2: -2.6910603, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8998198838, 2: -1.8997317, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -0.99999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.05-4.53-3.95-3.37-2.71\n",
      "-4.34-4.03-3.44-2.66-1.90\n",
      "-3.80-3.38-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.046237019353061, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.533281645043039, 2: -4.5255792259125815, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -3.995374728888, 2: -3.9484791583497003, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.90984745599, 2: -3.3918452550000002, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373873218, 1: -3.90984745599, 2: -3.3918452550000002, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9702246283800005, 1: -3.90984745599, 2: -3.3918452550000002, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.707282908, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.899972999, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.07-4.53-4.00-3.43-2.71\n",
      "-4.34-4.03-3.44-2.66-1.90\n",
      "-3.80-3.38-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.070342874924497, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.533281645043039, 2: -4.550826040854515, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533026902047091, 1: -4.533281645043039, 2: -4.550826040854515, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.025054480862853, 1: -4.533281645043039, 2: -4.550826040854515, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.028459111361, 2: -4.0684537031339705, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4174944810000003, 2: -3.4051844970000005, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4174944810000003, 2: -3.4051844970000005, 3: -3.8208104478000005, 4: -3.379776489}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4174944810000003, 2: -3.4051844970000005, 3: -3.8208104478000005, 4: -3.9755966049900002}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7081934623899997, 2: -2.70855818109, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8998198838, 2: -1.89996507, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.08-4.55-4.00-3.43-2.71\n",
      "-4.34-4.04-3.44-2.66-1.90\n",
      "-3.80-3.42-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.078786078150593, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.078786078150593, 3: -5.076892801450525, 4: -5.33912864489714}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.078786078150593, 3: -5.519972449319978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.616380044706714, 2: -4.550826040854515, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -3.995374728888, 2: -4.02768522241497, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4354367369037, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709673452117, 2: -2.70855818109, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8998774999999999, 2: -1.8997379109, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.09-4.59-4.03-3.43-2.71\n",
      "-4.34-4.04-3.44-2.66-1.90\n",
      "-3.80-3.42-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.094047700907217, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.616380044706714, 2: -4.591336134484732, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.082241229780798, 2: -4.02768522241497, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.43208368098, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.7097064199900003, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.89999729909, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.13-4.62-4.08-3.44-2.71\n",
      "-4.34-4.04-3.44-2.66-1.90\n",
      "-3.80-3.42-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.128387039023355, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.616380044706714, 2: -4.621558643604599, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0404648672261, 2: -4.0684537031339705, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4174944810000003, 2: -3.4341551542358997, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.705284548, 2: -2.7078887070000004, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999722700000001, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.15-4.62-4.08-3.44-2.71\n",
      "-4.34-4.07-3.44-2.66-1.90\n",
      "-3.80-3.43-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.152106540114774, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6344145469238125, 2: -4.621558643604599, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.082241229780798, 2: -4.082756303835297, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.43747580037327, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709673452117, 2: -2.709643525938, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8998774999999999, 2: -1.899973791009, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -0.999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.16-4.63-4.08-3.44-2.71\n",
      "-4.34-4.07-3.44-2.66-1.90\n",
      "-3.80-3.43-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.158673155331203, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6344145469238125, 2: -4.668771260482906, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.07221701633261, 2: -4.0684537031339705, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438558836047107, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709673452117, 2: -2.7098651275937997, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999819875700001, 2: -1.89996507, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -0.999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.17-4.66-4.08-3.44-2.71\n",
      "-4.34-4.07-3.44-2.66-1.90\n",
      "-3.80-3.43-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.169743098541408, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.658888954230898, 2: -4.668771260482906, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.07221701633261, 2: -4.092078027511554, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4330299319799997, 2: -3.4341551542358997, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7095059935, 2: -2.7078887070000004, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999819875700001, 2: -1.899995697, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.19-4.66-4.08-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.43-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.190674362781168, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.664384678652503, 2: -4.668771260482906, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.087975946537061, 2: -4.092078027511554, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4366928458680004, 2: -3.4341551542358997, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099390519116997, 2: -2.7098651275937997, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89998694, 2: -1.899973791009, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.20-4.67-4.08-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.197219025986644, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.677698984560269, 2: -4.668771260482906, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.092579521280428, 2: -4.082756303835297, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.4380705682899, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.7099684542619, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8999997299009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.20-4.67-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2014266235898186, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.677698984560269, 2: -4.673909732154882, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.092579521280428, 2: -4.093112790698349, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4386913798194807, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099390519116997, 2: -2.7099652834766697, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999981987489, 2: -1.899995697, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -0.9999998999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.206009545404436, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.677698984560269, 2: -4.6823803854526345, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.090463269584785, 2: -4.092078027511554, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4366928458680004, 2: -3.4384062687745676, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7095059935, 2: -2.7097742806317, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899997226919, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.209537132034262, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.681045146819702, 2: -4.6823803854526345, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.092767532111559, 2: -4.092078027511554, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438919770030425, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70999041976117, 2: -2.7099652834766697, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89998694, 2: -1.8999973791000901, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -0.9999998999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.21-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.212600282127385, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.682687716966329, 2: -4.6823803854526345, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.094597969781822, 2: -4.093112790698349, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.438881504781129, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.7099966266459194, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.899999972990009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.21-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.213988140429373, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.682687716966329, 2: -4.683659399010926, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.092767532111559, 2: -4.0947328164757995, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4383691393218, 2: -3.4384062687745676, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.70994835315439, 2: -2.7097742806317, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999981987489, 2: -1.8999994887, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.214375864785663, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.683410472706996, 2: -4.683659399010926, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.094355756061814, 2: -4.0947328164757995, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438754081243857, 2: -3.4384062687745676, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70999041976117, 2: -2.709985949747667, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899998613, 2: -1.8999973791000901, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.215000069371233, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.684769209680769, 2: -4.683659399010926, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.094597969781822, 2: -4.094805297942549, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438963856619145, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70999041976117, 2: -2.7099964720458396, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.899999819874809, 2: -1.8999994887, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -0.99999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2152641201359735, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.684769209680769, 2: -4.6849902954243685, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.094544653313581, 2: -4.0947328164757995, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438754081243857, 2: -3.438929246173067, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.70994835315439, 2: -2.709975969049779, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.89999972269109, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.68-4.09-3.44-2.71\n",
      "-4.34-4.09-3.44-2.66-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.21618947185502, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6850580901520775, 2: -4.6849902954243685, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0950205208396895, 2: -4.094805297942549, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.438985418061308, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.709999640786499, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.899999997298993, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.6842716, 2: -2.68486209, 3: -3.9899747455848, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.6842716, 2: -2.68486209, 3: -3.9899747455848, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.6842716, 2: -2.68486209, 3: -3.9899747455848, 4: -3.3244283700000006}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899998613, 2: -1.8999997379100082, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -0.99999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.16\n",
      "-4.34-4.09-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2164610864792404, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6850580901520775, 2: -4.685291320875901, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.094845271138881, 2: -4.0947328164757995, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389886256684625, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709998627823117, 2: -2.7099964720458396, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999998532, 2: -1.8999997379100082, 3: -3.0937815000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.899999997298993, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -0.9999999999999999, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.16\n",
      "-4.34-4.09-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216543161671107, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685239390360605, 2: -4.685291320875901, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.094845271138881, 2: -4.095054068439035, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389335741794413, 2: -3.438929246173067, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709998627823117, 2: -2.7099994349116905, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.899999819874809, 2: -1.8999999407700001, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.16\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2166982223592, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685348608658555, 2: -4.685291320875901, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0950205208396895, 2: -4.095058718423914, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389960049239763, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099997168809074, 2: -2.7099994349116905, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999998532, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -0.999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.16\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2167557921454, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685348608658555, 2: -4.685495753967738, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095017216514072, 2: -4.095054068439035, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389335741794413, 2: -3.438991813154032, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709994610695222, 2: -2.709975969049779, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.89999998198748, 2: -1.8999999407700001, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -0.999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.16\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.21680795222797, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685498806242254, 2: -4.685495753967738, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.09508881607239, 2: -4.095058718423914, 3: -4.28228008866, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.438998250843195, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.16707486407865, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.16707486407865, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7731757509, 1: -3.16707486407865, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8999999997298993, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216932355936665, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685498806242254, 2: -4.685547137320144, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0950379167367545, 2: -4.095054068439035, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389738923482653, 2: -3.438991813154032, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709994610695222, 2: -2.709997548928678, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899999972269101, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216947268649893, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685530593180996, 2: -4.685547137320144, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095072644475771, 2: -4.095054068439035, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999142770867, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099997168809074, 2: -2.7099998245831687, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.89999998198748, 2: -1.899999993267, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216974507341596, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685546854753718, 2: -4.685547137320144, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095072644475771, 2: -4.095094712488306, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438993023897956, 2: -3.438991813154032, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999570979496, 2: -2.7099998245831687, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89999998451, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -0.9999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216990403084671, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685563527500746, 2: -4.685547137320144, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.09508881607239, 2: -4.09509445502538, 3: -4.28228008866, 4: -4.377234037014}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685563527500746, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095090633102343, 2: -4.095094712488306, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438993023897956, 2: -3.43899903922777, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999438607494, 2: -2.709997548928678, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999981987479, 2: -1.899999993267, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -0.9999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.216992221537784, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685579765562973, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095093412667579, 2: -4.095094712488306, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438997317022025, 2: -3.43899903922777, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999438607494, 2: -2.709999749439138, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.89999999722691, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217018832259787, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685583640817036, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095097168054599, 2: -4.095094712488306, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999684950622, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999570979496, 2: -2.709999969911417, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999981987479, 2: -1.8999999992457, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217024632287778, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685585081197232, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095097168054599, 2: -4.095099216058834, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389992769742728, 2: -3.43899903922777, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999942507806, 2: -2.709999969911417, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89999999837, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -0.99999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217026378998535, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685587214243949, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095098938579953, 2: -4.095099216058834, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389992769742728, 2: -3.438999879551025, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7099999416145466, 2: -2.709999749439138, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999998198747, 2: -1.8999999992457, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -0.99999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217028281437452, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685588861674157, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099308207156, 2: -4.095099216058834, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389999337444017, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999942507806, 2: -2.7099999956708416, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999998198747, 2: -1.89999999991647, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217029806099813, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589251175072, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099308207156, 2: -4.095099867938849, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999724743129, 2: -3.438999879551025, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7099999416145466, 2: -2.7099999743329306, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999997226908, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2170302740617895, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6855893647653035, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.09509970786265, 2: -4.095099867938849, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999251820957, 2: -3.438999879551025, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999992791766, 2: -2.7099999956708416, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999998288999, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -0.999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030412866075, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589699845276, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099873222595, 2: -4.095099867938849, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389999887175726, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999992791766, 2: -2.7099999994284936, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999819874, 2: -1.89999999991647, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -0.999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030698161282, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589863014996, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099873222595, 2: -4.095099977655119, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999251820957, 2: -3.4389999844484844, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7099999939368344, 2: -2.7099999743329306, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999819874, 2: -1.8999999999908372, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2170308588582746, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589883611802, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099926719758, 2: -4.095099977655119, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999717278834, 2: -3.4389999844484844, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.7099999939368344, 2: -2.709999997418703, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899999999972269, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030891611387, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589929004184, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099969771562, 2: -4.095099977655119, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999992261624, 2: -3.4389999844484844, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999860258, 2: -2.7099999994284936, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999820802, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -0.9999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030931654527, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589968415383, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099984380428, 2: -4.095099977655119, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389999982878905, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999860258, 2: -2.7099999999283346, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999981987, 2: -1.8999999999908372, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -0.9999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030967581913, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589978742184, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099984380428, 2: -4.095099996378703, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999992261624, 2: -3.4389999979819286, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999371221, 2: -2.709999997418703, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999981987, 2: -1.8999999999990027, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.21703097953936, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589985222365, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099992169958, 2: -4.095099996378703, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999971353116, 2: -3.4389999979819286, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999371221, 2: -2.7099999997404116, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999972268, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030985984052, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589992179903, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0950999968965975, 2: -4.095099996378703, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999999715598, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999786037, 2: -2.7099999999283346, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899999999998127, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -0.99999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030992264127, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68558999628474, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0950999968965975, 2: -4.095099999407505, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.43899999920422, 2: -3.4389999979819286, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999786037, 2: -2.7099999999913162, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999998198, 2: -1.8999999999990027, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -0.99999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030996217052, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589997114718, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099998055022, 2: -4.095099999407505, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.43899999920422, 2: -3.438999999780862, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999934876, 2: -2.7099999997404116, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999998198, 2: -1.8999999999998922, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030997284627, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68558999813604, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0950999991609205, 2: -4.095099999407505, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999997101555, 2: -3.438999999780862, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999934876, 2: -2.709999999973895, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999997226, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030998218655, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999133949, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999681318, 2: -4.095099999407505, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999999913511, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999970525, 2: -2.7099999999913162, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999998045, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -0.999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.2170309991203645, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999433473, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999681318, 2: -4.095099999870695, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999999182654, 2: -3.438999999780862, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999970525, 2: -2.7099999999989732, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.899999999999982, 2: -1.8999999999998922, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -0.999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.21703099945315, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999685216, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.09509999979063, 2: -4.095099999870695, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999999182654, 2: -3.438999999975699, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999993263, 2: -2.709999999973895, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.899999999999982, 2: -1.8999999999999884, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030999690341, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999798932, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999912858, 2: -4.095099999870695, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999999984317, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999999618, 2: -2.7099999999989732, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999795, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -0.9999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.217030999806169, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999875155, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999875155, 2: -4.837201585546614, 3: -4.821046393453497, 4: -4.936093355115477}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999912858, 2: -4.095099999974367, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999999706813, 2: -3.438999999975699, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999993263, 2: -2.709999999997375, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999722, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.34-4.69-4.10-3.74-2.76\n",
      "-4.34-4.10-3.44-2.68-1.90\n",
      "-3.80-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.33912864489714}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.415833689285001, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.758607066856397}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.341644012832571, 2: -4.360567082585581, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.79746731178, 2: -3.8481432678000003, 3: -4.024239322050001, 4: -3.8281183668000005}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.2785987500000005, 2: -3.27793446, 3: -3.27734397, 4: -3.325968999}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.2785987500000005, 2: -3.27793446, 3: -3.27734397, 4: -3.325968999}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.2785987500000005, 2: -3.27793446, 3: -3.8823830127, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999304, 2: -2.709999999997375, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999999981, 2: -1.8999999999999884, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -0.9999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-4.96-4.69-4.10-3.74-2.76\n",
      "-4.36-4.10-3.44-2.68-1.90\n",
      "-3.83-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -4.9583150193228835, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.410112923825057, 2: -4.360567082585581, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0950999999675375, 2: -4.095099999974367, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999991611, 2: -3.438999999975699, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999999618, 2: -2.7099999999998805, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999999981, 2: -1.8999999999999988, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.93-4.69-4.10-3.74-2.76\n",
      "-4.41-4.10-3.44-2.68-1.90\n",
      "-3.83-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -4.927890838826609, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.410112923825057, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.934395346878, 2: -3.8481432678000003, 3: -4.024239322050001, 4: -3.8281183668000005}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.934395346878, 2: -3.8481432678000003, 3: -4.024239322050001, 4: -3.8281183668000005}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.934395346878, 2: -3.8481432678000003, 3: -4.024239322050001, 4: -4.383587713788}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999991611, 2: -3.4389999999972605, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999304, 2: -2.7099999999997277, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999972, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.96-4.69-4.10-3.74-2.76\n",
      "-4.44-4.10-3.44-2.68-1.90\n",
      "-3.93-3.44-2.71-1.90-1.00\n",
      "-3.28-2.71-1.90-1.000.00\n",
      "-2.66-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -4.964980552180958, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.441787169490506, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.934395346878, 2: -4.070404326773205, 3: -4.024239322050001, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.2785987500000005, 2: -3.422893445997874, 3: -3.94336521387, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.6723889, 3: -2.664207, 4: -3.1632246000000004}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.6723889, 3: -2.664207, 4: -3.1632246000000004}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.6723889, 3: -3.3244283700000006, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999997, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-4.99-4.69-4.10-3.74-2.76\n",
      "-4.44-4.10-3.44-2.68-1.90\n",
      "-3.95-3.44-2.71-1.90-1.00\n",
      "-3.33-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -4.994345662505406, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.53103894792023, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.53103894792023, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -4.4424091266219}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.53103894792023, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -4.942592305225929}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.9491045221878003, 2: -4.070404326773205, 3: -4.024239322050001, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.3858675450000004, 2: -3.422893445997874, 3: -3.94336521387, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.3858675450000004, 2: -3.422893445997874, 3: -3.94336521387, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.3858675450000004, 2: -3.422893445997874, 3: -3.94336521387, 4: -3.92663178909}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.70623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.00-4.69-4.10-3.74-2.76\n",
      "-4.55-4.10-3.44-2.68-1.90\n",
      "-3.99-3.44-2.71-1.90-1.00\n",
      "-3.42-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -4.99778595881428, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.551878557764141, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -3.98894534140878, 2: -4.070404326773205, 3: -4.024239322050001, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4306402554, 2: -3.422893445997874, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999928, 2: -2.7099999999997277, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999999997, 2: -1.8999999999999988, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.09-4.69-4.10-3.74-2.76\n",
      "-4.59-4.10-3.44-2.68-1.90\n",
      "-4.02-3.44-2.71-1.90-1.00\n",
      "-3.43-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.086800227670382, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.586233582317526, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.071438225399156, 2: -4.070404326773205, 3: -4.024239322050001, 4: -4.4553548182968}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.071438225399156, 2: -4.070404326773205, 3: -4.024239322050001, 4: -4.4553548182968}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.071438225399156, 2: -4.070404326773205, 3: -4.562057783065501, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999999985976, 2: -3.4389999999972605, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70999999999996, 2: -2.7099999999998805, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899999999999998, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.12-4.69-4.10-3.74-2.76\n",
      "-4.62-4.10-3.44-2.68-1.90\n",
      "-4.07-3.44-2.71-1.90-1.00\n",
      "-3.43-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.123529224444234, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.618257209092253, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.071438225399156, 2: -4.092630432675102, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4306402554, 2: -3.4373893445995667, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.15-4.69-4.10-3.74-2.76\n",
      "-4.65-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.153141261809148, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.659690683482542, 2: -4.653087708232263, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999977069, 2: -4.095099999974367, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389999999976, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.70999999999996, 2: -2.7099999999999866, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.8999999999999997, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.18-4.69-4.10-3.74-2.76\n",
      "-4.66-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.184315169849048, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.659690683482542, 2: -4.682339770802463, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.085962429413915, 2: -4.092630432675102, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.43785937563, 2: -3.4373893445995667, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999928, 2: -2.709999999999972, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.19-4.69-4.10-3.74-2.76\n",
      "-4.68-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.192780970605764, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.675598636173525, 2: -4.682339770802463, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.09288161206704, 2: -4.092630432675102, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4389999999985976, 2: -3.4389999999996292, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999993, 2: -2.709999999999972, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.69-4.10-3.74-2.76\n",
      "-4.68-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.206512992361132, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.682590514084184, 2: -4.682339770802463, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999977069, 2: -4.095099999995493, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999837, 2: -3.4389999999996292, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999999996, 2: -2.7099999999999866, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999997, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.69-4.10-3.74-2.76\n",
      "-4.68-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.213346513586108, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.682590514084184, 2: -4.6852649770616726, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.09288161206704, 2: -4.094853043266374, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.43785937563, 2: -3.4388389344598984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.7099623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.21-4.69-4.10-3.74-2.76\n",
      "-4.68-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2142329677668, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6834931571827205, 2: -4.6852649770616726, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.093954255467003, 2: -4.094853043266374, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438855472572, 2: -3.4388389344598984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999993, 2: -2.7099999999999973, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.68-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.215052754094684, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.684452262646545, 2: -4.6852649770616726, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.094854962459219, 2: -4.094853043266374, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999837, 2: -3.438999999999952, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999999, 2: -2.7099999999999973, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21591160815317, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685276191310418, 2: -4.6852649770616726, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999997407, 2: -4.095099999995493, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999999999728, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.709999999999996, 2: -2.7099999999999986, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.216655792235272, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685276191310418, 2: -4.685557497702517, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.094854962459219, 2: -4.095075304326505, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438855472572, 2: -3.438983893445984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.70999623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.09-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.216739294184967, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685360138723009, 2: -4.685557497702517, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.094958429029242, 2: -4.095075304326505, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389825007581, 2: -3.438983893445984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709999623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.216815641784134, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685452341385987, 2: -4.685557497702517, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095071668516985, 2: -4.095075304326505, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389979454259, 2: -3.438983893445984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.709999999999999, 2: -2.7099999999999995, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.216897960701062, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685553285637356, 2: -4.685557497702517, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095084120542945, 2: -4.095075304326505, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999982, 2: -3.438999999999952, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999999995, 2: -2.7099999999999986, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2169879574363645, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685566325068205, 2: -4.685557497702517, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999997407, 2: -4.095099999999329, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999982, 2: -3.438999999999994, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.7099999999999995, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217000368882675, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685566325068205, 2: -4.685586749768151, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095084120542945, 2: -4.095097530432612, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389979454259, 2: -3.4389983893445977, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.7099999623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217008760193513, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685574770146606, 2: -4.685586749768151, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095096747849273, 2: -4.095097530432612, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389997640775993, 2: -3.4389983893445977, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217016439838102, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685585842772571, 2: -4.685586749768151, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950983701540515, 2: -4.095097530432612, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999998, 2: -3.438999999999994, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7099999999999995, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217026176629593, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685587583927673, 2: -4.685586749768151, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999726, 2: -4.095099999999329, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.43899999999997, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217027884975162, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685587583927673, 2: -4.685589674976271, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950983701540515, 2: -4.0950997530432565, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389997640775993, 2: -3.4389998389344596, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.70999999623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217028731478932, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855884382175494, 2: -4.685589674976271, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099645918261, 2: -4.0950997530432565, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999973361261, 2: -3.4389998389344596, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217029508104108, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589557015547, 2: -4.685589674976271, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099834128738, 2: -4.0950997530432565, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.438999999999998, 2: -3.438999999999999, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030491993004, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589755666593, 2: -4.685589674976271, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999726, 2: -4.095099999999908, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.438999999999999, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21703068593008, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589755666593, 2: -4.685589967497405, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099834128738, 2: -4.095099975304325, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999973361261, 2: -3.438999983893446, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709999999623889, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030770682948, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589841210937, 2: -4.685589967497405, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099961835495, 2: -4.095099975304325, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999970314764, 2: -3.438999983893446, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030848449154, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589953207845, 2: -4.685589967497405, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099983137241, 2: -4.095099975304325, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21703094694327, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589975317288, 2: -4.685589967497405, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999972, 2: -4.095099999999908, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.438999999999997, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030968367225, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589975317288, 2: -4.685589996749666, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099983137241, 2: -4.095099997530433, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999970314764, 2: -3.4389999983893444, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.7099999999623887, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030976843725, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899838728945, 2: -4.685589996749666, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.09509999590922, 2: -4.095099997530433, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999996726823, 2: -3.4389999983893444, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030984621418, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589995073758, 2: -4.685589996749666, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.09509999828629, 2: -4.095099997530433, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030994471886, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899975070265, 2: -4.685589996749666, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999972, 2: -4.095099999999988, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030996814418, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899975070265, 2: -4.685589999674944, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.09509999828629, 2: -4.095099999753043, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999996726823, 2: -3.4389999998389347, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709999999996239, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030997662134, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589998362598, 2: -4.685589999674944, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950999995635025, 2: -4.095099999753043, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999964222, 2: -3.4389999998389347, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030998439918, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999482698, 2: -4.685589999674944, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999825887, 2: -4.095099999753043, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999424977, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999748235, 2: -4.685589999674944, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999998, 2: -4.095099999999988, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4389999999999996, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999679202, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999748235, 2: -4.685589999967484, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999825887, 2: -4.095099999975305, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999964222, 2: -3.4389999999838934, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709999999999624, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21703099976399, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999833792, 2: -4.685589999967484, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999953609, 2: -4.095099999975305, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999996118, 2: -3.4389999999838934, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309998417705, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999945803, 2: -4.685589999967484, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999982314, 2: -4.095099999975305, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309999402775, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999974576, 2: -4.685589999967484, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095099999999998, 2: -4.095099999999999, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21703099996769, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999974576, 2: -4.685589999996746, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999982314, 2: -4.095099999997531, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999996118, 2: -3.4389999999983893, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.709999999999962, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999976176, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999983133, 2: -4.685589999996746, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999995087, 2: -4.095099999997531, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999581, 2: -3.4389999999983893, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309999839555, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999994334, 2: -4.685589999996746, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950999999982045, 2: -4.095099999997531, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999993806, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899999974335, 2: -4.685589999996746, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.095099999999999, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999996744, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899999974335, 2: -4.685589999999674, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950999999982045, 2: -4.0950999999997535, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999581, 2: -3.438999999999839, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.7099999999999964, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999997595, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68558999999829, 2: -4.685589999999674, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999481, 2: -4.0950999999997535, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999955, 2: -3.438999999999839, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999998375, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999408, 2: -4.685589999999674, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999817, 2: -4.0950999999997535, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999358, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999741, 2: -4.685589999999674, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999673, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999741, 2: -4.6855899999999675, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999817, 2: -4.0950999999999755, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999955, 2: -3.438999999999984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.7099999999999995, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999757, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999826, 2: -4.6855899999999675, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999945, 2: -4.0950999999999755, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999995, 2: -3.438999999999984, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999835, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999939, 2: -4.6855899999999675, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999982, 2: -4.0950999999999755, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999935, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999975, 2: -4.6855899999999675, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309999999676, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999975, 2: -4.685589999999997, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999982, 2: -4.095099999999998, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.438999999999995, 2: -3.4389999999999983, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999976, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999983, 2: -4.685589999999997, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999993, 2: -4.095099999999998, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999999999996, 2: -3.4389999999999983, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309999999835, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999993, 2: -4.685589999999997, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.095099999999998, 2: -4.095099999999998, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4389999999999996, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999993, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999998, 2: -4.685589999999997, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999997, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999998, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950999999999995, 2: -4.095099999999998, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999998, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685589999999998, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0950999999999995, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217030999999998, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855899999999995, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170309999999995, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.339394844769799, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.9, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -3.0752649, 4: -3.3252237090000003}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.734864569, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.47-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4685864569000002, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -4.68559, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -4.5440020503414, 4: -4.309800753339001}, Best action: 2, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -5.049200660776535, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -5.049200660776535, 3: -4.7940663631976115, 4: -5.064400778337979}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.883468824263538, 2: -5.049200660776535, 3: -5.262600390509826, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.705377882426355, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.233059184765348, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.687568788242636, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.220236636953071, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685787878824264, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217511845542962, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685609787882427, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217095112739062, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685591978788243, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217039014092383, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590197878825, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031961691086, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590019787883, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170311121972945, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590001978788, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031012822548, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000197879, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031001442537, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000019788, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000160282, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000001979, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000017632, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000000198, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000001924, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559000000002, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000000209, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000000002, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.4553548182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.98-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000000023, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.977396402820409, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.42-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.419938717624153, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68558999991693, 2: -4.837201585546614, 3: -4.821046393453497, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.237321771695129, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999991693, 2: -4.837201585546614, 3: -4.821046393453497, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.219060077162784, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68558999999917, 2: -4.837201585546614, 3: -4.821046393453497, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217233907715607, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999999918, 2: -4.837201585546614, 3: -4.821046393453497, 4: -5.188937235410424}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.326770969468893, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999999918, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.228004996946822, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.685589999999992, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.218128399694677, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.6855899999999995, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217140739969468, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217041973996947, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217032097399695, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.2170311097399695, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217031010973997, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.2170310010974, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.68559, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.309800753339001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.84-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.21703100010974, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.837201585546614, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.09508881607239, 2: -4.09509445502538, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.34-4.70-4.10-3.74-2.76\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.339836384303732, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.700742099573297, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095098881607239, 2: -4.09509445502538, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.8013419769843195, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.8013419769843195, 3: -4.4024629420548, 4: -3.7366818399000006}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.8013419769843195, 3: -4.4024629420548, 4: -4.300380474309001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7557074861890833, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.89999999997299, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.24-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.241584739084744, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.687100718527887, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095098881607239, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.220710055916063, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.685740165954653, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099888160724, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.217520540014876, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.685604926005651, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099988816073, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.2170920440660655, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.685591483541584, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099998881608, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.21703830607529, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.685590147448261, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074463580571147, 1: -4.859497610204591, 2: -4.685590147448261, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099999888161, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.45-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.453394186284533, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.714770640282041, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.26-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.264303637256907, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.688508064028205, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.224121895588536, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685881806402821, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217976452745139, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685619180640282, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.720.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217149181593143, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685592918064028, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.8019, 3: -2.677239, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.46-1.720.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170451817911765, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590291806403, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -2.71, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -2.4823900000000005, 3: -2.46429, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.4823900000000005, 3: -2.46429, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -3.1670749000000002, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -3.1670749000000002, 3: -3.397077846, 4: -3.1632246000000004}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -3.1670749000000002, 3: -3.397077846, 4: -3.7785343860000005}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.4823900000000005, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.8019, 3: -2.677239, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.8019, 3: -2.677239, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.8019, 3: -2.677239, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.22-2.54-1.080.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170326545423045, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855900291806405, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -3.227443390000001, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.22360938, 2: -3.227443390000001, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8334845358000003, 2: -3.227443390000001, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.5406290000000005, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.08019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031189090549, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590002918064, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031021272687, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000291807, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031002363633, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.6855900000291815, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.21703100026, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000002918, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000028364, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000000293, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.2170310000030735, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559000000003, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000000332, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.685590000000003, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000000036, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031000000004, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.4892522301995665, 1: -5.217031, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1387953548663035, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.584127337441706, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4892522301995665, 1: -5.584127337441706, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.895219529481605, 1: -5.584127337441706, 2: -5.532019330870159, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590014654236, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0950999999888165, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.2485298449569475, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590001456365, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099999998882, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.220180885675351, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590000144731, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0950999999998885, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.217345988684768, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590000014383, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095099999999989, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.217062498880127, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.6855900000014294, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0950999999999995, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.21703414988917, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.6855900000001425, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.217031314989033, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590000000015, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.217031031498915, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590000000002, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202774377490207, 1: -4.859497610204591, 2: -4.685590000000002, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.57-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.63595034891696, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.63595034891696, 3: -5.565813968233978, 4: -5.8626859950064905}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.970457610952989, 1: -5.584127337441706, 2: -5.63595034891696, 3: -5.96489071109292, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2537406337441706, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.220701963374418, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217398096337442, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217067709633745, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217034670963375, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031367096338, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031036709634, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2170310036709635, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000367097, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.21703100003671, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000003671, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000367, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000037, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000004, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.439, 3: -3.94336521387, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.86-2.71-1.90-1.000.00\n",
      "-3.28-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.8550235978, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -3.2806538290000002, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.0290168, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.44195864569, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0974965030089, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439295864569, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.687531167437209, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.09557930060178, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390295864569, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.218603345624139, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.686172350231162, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951718950902665, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390029586456903, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217659938249656, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685706470046233, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095109586012036, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439000295864569, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217188234562414, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685609411674373, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095101198251505, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439000029586457, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217062446912483, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685592911751156, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100143790181, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439000002958646, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217036503209686, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590407645162, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100016775522, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390000002958647, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2170318805135505, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559005435269, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100001917203, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390000000295866, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031132077034, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590006988204, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100000215686, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390000000029586, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031018868148, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000873526, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100000023965, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439000000000296, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2170310025943705, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000106765, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951000000026365, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.43900000000003, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -1.9, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -3.0197359000000006, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.71, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.0197359000000006, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.0197359000000006, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.0197359000000006, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000345917, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000012812, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100000000288, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439000000000003, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.21703100004497, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000001514, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951000000000315, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390000000000005, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000005724, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000176, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100000000004, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000715, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000021, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000088, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000002, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000011, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000001, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-2.01-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -2.71, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.0937815000000004, 4: -2.546109}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -3.2333482900000003, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -2.012623129, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.00008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.85-1.90-1.00\n",
      "-3.94-2.71-1.91-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.439, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.85355956349, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9113272668, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.56-2.73-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.5552832464269, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.733531042457, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9011392220700003, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.19-3.47-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.18928942960579, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.46968846903286, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7132758741224006, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9001145717460002, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.00000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.76-4.10-3.44-2.68-1.90\n",
      "-4.13-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.76188343798069, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.129376602877196, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4447223049424305, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7104203905265005, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000115221285, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.000000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "V:\n",
      "-5.28-4.69-4.10-3.51-2.71\n",
      "-4.72-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.278828684764359, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.720983392128598, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.103162727291088, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4399127468207085, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.710051371976735, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.90000115870824, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0000000008018999, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.70-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.251879416100601, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.695660148318641, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.096645597653883, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4391328859832266, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7100060757513478, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000116520363, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.00000000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.22867266174816, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68784894893151, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095362197411802, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390182099569144, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.710000701956629, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000117169902, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.000000000008019, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.220024914809339, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.686028274796711, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095140969806281, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.4390023895805606, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.710000079686425, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000011781943, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0000000000008018, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.21768539406627, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6856670130227585, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095106032540882, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.43900030350406, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.7100000089229797, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000000118469, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0000000000000802, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217158819955062, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68560258766039, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100849092377, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.43900003757802, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3103415700000003, 1: -2.710000000988258, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000988258, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000000011912, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.000000000000008, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.82-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217053978000422, 2: -5.63595034891696, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439000000800489, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000001084745, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000011976, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0000000000000009, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.82-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217053978000422, 2: -5.258922934891697, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685591946530865, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.095100115347434, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.9252766754578023, 3: -3.8208104478000005, 4: -4.0557591030690014}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.404366474252743, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.8382266359000003, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000001205, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.43-3.48-2.71-1.90-1.00\n",
      "-3.94-2.71-1.90-1.000.00\n",
      "-2.87-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217034874490043, 2: -5.258922934891697, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590288084509, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.432079114218, 2: -4.449400222504275, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.9428319612700005, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.8715689908999997, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.91939707, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.96-4.10-3.44-2.68-1.90\n",
      "-4.45-3.48-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2170316207974565, 2: -5.258922934891697, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.958543111325032, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.449400222504275, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.47892266359, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.7100000000000977, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000000000012, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.26-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.258922934891697, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095100000648396, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000001679133, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000011818, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000000000001, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.22122019348917, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000525201, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951000002008495, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000263643, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000000011826, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.21744991977433, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000215209, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.09510000004144, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000035945, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000118, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217072892151752, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000055087, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095100000007056, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439000000000455, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000012, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217035189259796, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000011223, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095100000001073, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439000000000055, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000000000013, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.21703141893507, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000001992, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095100000000152, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000000067, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031041895121, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000000323, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.09510000000002, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439000000000001, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031004189774, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000000048, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.095100000000002, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031000419017, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000000007, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.2170310000419065, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031000004192, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.21703100000042, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031000000042, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031000000005, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.217031, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.215605337749023, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.44-4.69-4.10-3.51-2.71\n",
      "-5.00-4.10-3.44-2.68-1.90\n",
      "-4.16-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.438123082253021, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.999868491360966, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.162867379758327, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.442992266359079, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.7100000000000195, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.49-4.69-4.10-3.51-2.71\n",
      "-4.77-4.10-3.44-2.68-1.90\n",
      "-4.11-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.493705786227685, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.771909426740342, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.105110473726687, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439399226635924, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.7100000000000017, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.31-4.69-4.10-3.51-2.71\n",
      "-4.70-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.314617214282445, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.702330426392651, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.096424420947767, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439039922663594, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.240349366806292, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6883368236069565, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095264779452288, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390039922663593, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.2215877638022645, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6859981537170485, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.09511971168098, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439000399226636, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217817280891036, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685646781833299, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095102294541673, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000399226635, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217155621374076, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685597536762084, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100261791524, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000039922666, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217049566914696, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590965727343, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951000294128885, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000003992265, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217033638930618, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6855901203971735, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100003264663, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439000000039923, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031361414772, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590014684094, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000358804, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000000039924, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031048035594, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559000175904, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000039114, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000000003993, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031006228383, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000207587, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000004234, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.43900000000004, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000790984, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000024189, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000000456, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439000000000004, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000098692, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000002788, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000000049, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4390000000000005, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000012128, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000318, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000000006, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.21703100000147, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000036, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.095100000000001, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000176, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000005, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000022, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000001, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031000000003, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.970457610952989, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.62-2.71-1.90-1.000.00\n",
      "-2.74-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -4.0951, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -4.849617888924723, 4: -4.0557591030690014}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5369018000505, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.620254078756, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.74186852579, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.901939707, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.29-3.44-2.71-1.90-1.00\n",
      "-3.48-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.28609598379741, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4829389137655, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.714758015249, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9001939707, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.84-4.10-3.44-2.68-1.90\n",
      "-4.15-3.44-2.71-1.90-1.00\n",
      "-3.45-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.840296746875902, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.149790118529796, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4472478837282403, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.7106329177918997, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90001939707, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.34-4.69-4.10-3.51-2.71\n",
      "-4.75-4.10-3.44-2.68-1.90\n",
      "-4.11-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.342343464969481, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.745359670696725, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.1072497976728535, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.440337451784263, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.71007900340589, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000019397069998, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.28-4.69-4.10-3.51-2.71\n",
      "-4.70-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.277975679761296, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.701408303184684, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.097398315712539, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4391977379371976, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.710009471503259, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000001939706999, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.235938293555725, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.689033466045625, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0954899993003835, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4390274457113597, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.7100011042665932, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000193970699, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.22171093685253, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.686250246037873, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095161230956239, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.4390036390270766, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.7100001261382856, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000001939707, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21803379297593, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685705621678341, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095109070707556, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -3.439000466074719, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6634877280000007, 1: -3.8975775994800004, 2: -2.7100000141849914, 3: -3.397077846, 4: -3.8431841076000004}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -4.2113251062874735, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -4.2113251062874735, 2: -3.98199725299, 3: -3.94336521387, 4: -4.035215890359}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.972885491718, 1: -4.2113251062874735, 2: -3.98199725299, 3: -4.4884623446217, 4: -4.035215890359}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095101284591278, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.98199725299, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.53-3.44-2.71-1.90-1.00\n",
      "-3.49-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.880.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21722493285705, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685608909440955, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.5349279033810275, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.493299725299, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.6126109, 2: -2.458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-5.04-4.10-3.44-2.68-1.90\n",
      "-4.18-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.61-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170657099328785, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.041852492682728, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.183065567830293, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4444299725299, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -2.6144119, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.1458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.51-4.69-4.10-3.51-2.71\n",
      "-4.79-4.10-3.44-2.68-1.90\n",
      "-4.11-3.44-2.71-1.90-1.00\n",
      "-3.44-3.08-2.09-1.000.00\n",
      "-2.71-1.90-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.505607090066298, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.792468359210811, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.1082948345322485, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.43954299725299, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -3.288673639, 3: -3.0759939000000003, 4: -3.4331366979}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.735509358725299, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.1670749000000002, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000001939705, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.01458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.33-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.84-2.76-2.09-1.000.00\n",
      "-2.71-1.91-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.332460079967387, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.706965651892203, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.096859311228147, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.8388816048725305, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.755707490157116, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.911809800019397, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.42-3.44-2.71-1.90-1.00\n",
      "-3.52-2.72-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.245888186029423, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.689152607284019, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.419180031069564, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.5160112275145172, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.724136687031423, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9023619600019397, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.95-4.10-3.44-2.68-1.90\n",
      "-4.19-3.44-2.71-1.90-1.00\n",
      "-3.46-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.222802430502997, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.948451085894749, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.189887097393716, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4581518392469044, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7133268563047137, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900354294000194, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.43-4.69-4.10-3.51-2.71\n",
      "-4.79-4.10-3.44-2.68-1.90\n",
      "-4.12-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.430525622625046, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.788653657478386, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.120091699529364, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.443609937531509, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7106196637706286, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000472392000194, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.32-4.69-4.10-3.51-2.71\n",
      "-4.72-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.321862024819997, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.716139642366623, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.101333219353458, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.43996292140736, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7101002301290786, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900005904900002, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.252259312798964, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.693693871912964, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.096503288275308, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4391774785452895, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100148059819094, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000007085880002, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.227117967529397, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.687537050694296, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095384086449215, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390297406998753, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710002054554471, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000826686, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21961680781532, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.686014815093293, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095152498611821, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439004638259109, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000272417013, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90000000944784, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2176336810071, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685675005384905, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.09510900685106, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390006844836916, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000348944517, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000010628821, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2171601224624835, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685605796087849, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095101455116897, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000096712875, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000043503796, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000001180979, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000001458, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217056707077406, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685592758253472, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100223849118, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000131950953, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000005306972, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000129909, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000001459, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217035804893053, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6855904571431335, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100033072939, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000017493745, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000635927, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000014172, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000147, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031850775244, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590072503394, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100004724287, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000002264474, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000075073, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000001536, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000016, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031143805274, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590011077013, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000655851, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000287255, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000008753, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000168, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000002, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031023352908, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590001638941, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000088853, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000035816, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000000000101, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000000000002, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031003662833, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000235865, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951000000117865, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.43900000000044, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000000115, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000001, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000557334, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000033134, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000001535, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000000533, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000000013, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000082573, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000004557, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000197, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000000067, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000011948, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000615, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000025, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000000000001, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.810.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000001693, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000082, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000003, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.80919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-2.55-1.080.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000236, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000011, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.5554438999999998, 3: -3.7086409260000006, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.5554438999999998, 3: -3.7086409260000006, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.5554438999999998, 3: -3.7086409260000006, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-3.23-2.09-1.000.00\n",
      "-2.71-2.03-1.010.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000032, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000001, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -3.2333482900000003, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.03108878, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.86-2.87-2.09-1.000.00\n",
      "-2.71-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000004, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.8629121149000003, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.8685167408, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9196633170000001, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.44-3.44-2.71-1.90-1.00\n",
      "-3.61-2.74-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.438468813069, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.6097897715380003, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.74177896085, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9026217756000001, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.96-4.10-3.44-2.68-1.90\n",
      "-4.27-3.44-2.71-1.90-1.00\n",
      "-3.48-2.72-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.96371873858589, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.26777659625268, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4818199354423003, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.715301534321, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90032772195, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.44-4.69-4.10-3.51-2.71\n",
      "-4.85-4.10-3.44-2.68-1.90\n",
      "-4.15-3.44-2.71-1.90-1.00\n",
      "-3.45-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.442315278254571, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.85327091682326, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.147051807333532, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4475762363442404, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7107956082116003, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900039326634, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.38-4.69-4.10-3.51-2.71\n",
      "-4.74-4.10-3.44-2.68-1.90\n",
      "-4.11-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.375380970452298, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.744439055622487, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.107241932172188, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4405020662858203, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7101114153947004, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000045881072998, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.28-4.69-4.10-3.51-2.71\n",
      "-4.70-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.280533732099444, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.701309870621721, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.097530866908733, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4392404530982894, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100148579063825, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90000052435512, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2361143684135385, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.689130989258246, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095537853700488, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439036080213999, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100019105182858, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000589899508, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.221807538140533, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68629876042322, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095173010343388, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390051555412113, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000238833689, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000065544391, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000080919, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.218082749756862, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6857200144204665, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.09511147702272, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000709009409, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000291924644, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000007209885, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000008092, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217241486656264, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68561229783045, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095101721999893, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000094546837, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000035032474, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000786534, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000008091, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217070109908291, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685593624602959, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100248782927, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000122923143, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000000414034, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000085207, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000808, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217037846919226, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6855905639744675, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100034835068, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000001564599, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000000048305, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000009176, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000000008, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170321415112415, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590084613851, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100004750833, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000000195587, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000055737, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000983, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000009, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031182688344, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559001230956, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000633509, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000240737, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000006372, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000106, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031028239578, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590001744099, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000082851, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000029235, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000000724, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000000000001, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031004236678, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000241519, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000010653, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000003513, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000000000008, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000619298, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000032781, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.09510000000135, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000000000042, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000000000001, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170310000884825, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000004372, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000169, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000000000005, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703100001239, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000574, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000021, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000000000005, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000001704, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000074, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.095100000000002, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170310000002305, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000009, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590000000001, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000004, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-2.09-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.68559, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1292673844769805, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -5.049200660776535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -2.08953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.72-4.10-3.44-2.68-1.90\n",
      "-4.10-3.44-2.86-1.90-1.00\n",
      "-3.44-2.71-1.92-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.721951066077654, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.8635267439, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.918953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.25-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.56-2.68-1.90\n",
      "-4.10-3.44-2.74-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2464834635229, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.689226106607766, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.5633566625590003, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.74070534878, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9018953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.12-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.222921492704581, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685953610660777, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.119065030089001, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.71-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217914573905688, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.705038035438168, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.097496503008901, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.232872266095486, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.689475970981026, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0953396503008905, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.22176276310418, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.686172713841825, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.09512396503009, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2179761745222955, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685667683058556, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095102396503009, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21718844072966, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685599709473293, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100239650301, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217054608746333, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685591165064073, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.09510002396503, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217034304576533, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855901359180825, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100002396503, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170314405513, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590015532976, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951000002396505, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170310566368405, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590001747415, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100000023965, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031007079091, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900001941535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100000002397, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000865173, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900000213575, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.09510000000024, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000103817, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559000000233, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100000000024, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703100001227, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900000002535, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.095100000000003, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000001433, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000028, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000166, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000003, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.51-2.71\n",
      "-4.69-4.10-3.48-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000019, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9488290652514015, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.0951, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4763069987677, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7146058023169997, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9001895391899999, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-5.06-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000002, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -5.377110542853636, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -5.377110542853636, 3: -5.381869786704449, 4: -5.064400778337979}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -5.377110542853636, 3: -5.381869786704449, 4: -5.508604708287561}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.52-4.69-4.13-3.51-2.71\n",
      "-4.75-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.523867730453763, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.754742054285364, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.30-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.303727837016521, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.692505205428537, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.231302000098767, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.686281520542854, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.219018231649589, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685659152054286, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217285736328931, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685596915205429, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217062074949291, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590691520543, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703466762657, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590069152054, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031422775821, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590006915206, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031047878899, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000691521, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031005348022, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000069152, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.439, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.4331366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.45-2.68-1.90\n",
      "-4.10-3.93-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000590815, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000006916, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.0951, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.9252766754578023, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7106141069756, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900018953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.20-3.45-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000064683, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000692, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.195828896672791, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.44646139975354, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71007676337195, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000018953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.77-4.11-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170310000070295, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.767180406305029, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.111216623467646, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4398083183066333, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100092116046337, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.90000018953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.28-4.69-4.13-3.51-2.71\n",
      "-4.71-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.283119229107777, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.7068035056392965, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.097366400175138, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390882932304168, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100010746872076, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.900000018953919, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.240822762478608, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.689547134705792, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095398157534151, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.43900969981968, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100001228213952, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000018953918, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.222615455359553, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.686227221073242, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095137672607356, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439001069467298, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000138174067, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000001895392, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.218105594605282, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685684236919283, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095104633529247, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390001181388294, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000015352674, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000189539, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217214791365147, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685603176850619, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100559045377, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000130574494, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000168879, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000018953, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217060052385516, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685591770511817, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100066481072, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000014425373, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000018423, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000001895, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2170353393531235, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559023090085, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100007816562, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000001591763, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000000019957, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000000188, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031620965002, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900294215, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951000009105885, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000175345, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000215, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000000017, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031085927916, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590003679727, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000105262, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439000000001928, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000023, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9000000000000001, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031011573371, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000453235, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000012088, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000002114, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000002, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031001524457, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900000551145, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000001381, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000000227, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000197089, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559000000663, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000156, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.4390000000000023, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000025079, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000789, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000017, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000003147, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000093, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000002, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703100000039, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000011, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.89, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-2.530.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000048, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000001, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -1.9, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -2.5309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-3.02-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000006, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -3.0197359000000006, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.68-1.90\n",
      "-4.10-3.49-3.33-1.90-1.00\n",
      "-3.44-2.71-2.01-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000000001, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.439, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -3.6169860790000006, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -3.6169860790000006, 2: -3.676963015, 3: -4.23276679089, 4: -3.3252237090000003}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -3.6169860790000006, 2: -3.676963015, 3: -4.23276679089, 4: -3.9259535751900003}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -2.01197359, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.72-2.68-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.7192214880000005, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.70742603653, 2: -2.68486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.899999999997299, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.32-3.45-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.322079405280001, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4466604417000006, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.70742603653, 2: -2.7074862089978122, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.87-4.12-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.869443318276802, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.124002898305001, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4376811337593, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709742603653, 2: -2.7074862089978122, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.89999999999973, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.37-4.69-4.13-3.51-2.71\n",
      "-4.73-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.36595218780421, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.727386679454731, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.096922008175533, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.436831942664158, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709742603653, 2: -2.7097486208995627, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.27-4.69-4.13-3.51-2.71\n",
      "-4.69-4.09-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.265778429138753, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.691245494567655, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0935260743755215, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.438574703225346, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.7099742603653, 2: -2.7097486208995627, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8999999999999728, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.13-3.51-2.71\n",
      "-4.68-4.09-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.226486693513676, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.684880669700938, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.094598117050082, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4387538532511805, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.7099742603653, 2: -2.7099748620899344, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.09-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217402011809128, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6851125417806605, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.094850432838464, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.438954536221011, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.70999742603653, 2: -2.7099748620899344, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8999999999999972, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.216681360023248, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685340104777222, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095038217622865, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4389750919149478, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.70999742603653, 2: -2.709997486208991, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.216793620871875, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685514966752243, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095073646213395, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4389954242810843, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709999742603653, 2: -2.709997486208991, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8999999999999997, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.216946485156504, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685561150108075, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095093658289018, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.438997506257391, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709999742603653, 2: -2.709999748620899, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.216999180103191, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685581978224913, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095097345897389, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.4389995421346984, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709999974260365, 2: -2.709999748620899, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.51-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217021320372498, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685587047999376, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095099363718845, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -3.438999750596398, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7598833980000004, 1: -2.709999974260365, 2: -2.70999997486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.5122572615115897, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7145707485970303, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.45-2.71\n",
      "-4.69-4.10-3.72-2.71-1.90\n",
      "-4.10-3.49-2.89-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217027640916744, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685589189412202, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095099734354966, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.9373312042900004, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.125318669001837, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.9373312042900004, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.8913972158, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.911197359, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.33-3.64-2.71-1.90\n",
      "-4.10-3.49-2.74-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217030007515558, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685589703768743, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.325945762164497, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.6357648652270003, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.73720958237, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9011197358999998, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.87-4.28-3.48-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217030660804238, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.872575037730117, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.27756411705032, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4807162482424, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.713627944316, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9001119735899998, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.37-4.69-4.34-3.45-2.71\n",
      "-4.85-4.15-3.45-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.368488846641819, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.852084438583771, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.147136572781377, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4461102597202, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7104534930395, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900011197359, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.37-4.69-4.34-3.45-2.71\n",
      "-4.74-4.11-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.367037279917036, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.7443890678112925, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.1060629676515, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4400783553340153, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100544191647398, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000011197359, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.28-4.69-4.34-3.45-2.71\n",
      "-4.70-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.2796588729188505, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.700349910578844, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.097069764585703, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439151915056841, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710006348902553, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000001119735899, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.24-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.235249314860749, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.688661500372303, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095420027654611, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439020334116752, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000725588863, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900000011197359, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.221340746787641, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.686156372437465, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095148473400029, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439002621138654, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000816287473, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000011197358, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217920736353111, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68568590069777, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951069704623135, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439000328233151, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000009069861, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000001119735, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217197653200506, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685605236144251, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100962915083, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4390000401699026, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000009976846, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000000111972, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217060006596894, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7228408710953, 1: -5.217060006596894, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.8626859950064905}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685592303575643, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100128829129, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4390000048251146, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000108838, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000000011197, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703576655596, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855903347091585, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100016791256, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4390000005706702, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000011791, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000000001118, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031747770014, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590047071833, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100002141369, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439000000066618, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000000012696, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900000000000011, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031112905186, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590006441693, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000268097, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4390000000076903, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000136, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900000000000001, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703101650829, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000861328, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000033039, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439000000000879, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.710000000000014, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031002348505, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000112895, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000004016, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.4390000000000995, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.7100000000000013, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000326295, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.6855900000145425, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000482, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439000000000011, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000044409, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000001845, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000057, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439000000000001, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.217031000005935, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.68559000000023, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000006, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.150.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.21703100000078, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -5.5232655814263545, 2: -4.685590000000027, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.15309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.65-4.69-4.34-3.45-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.646343423576708, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.859497610204591, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.336221735821539, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.450028032514753, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710457074859703, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.26-4.86-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.2599622423576715, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.859497610204591, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.095100000000001, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.36-4.70-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.362189288501487, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.70298076102046, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.25-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.245633345276722, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.6873290761020465, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.221299886170329, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685763907610205, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.217598753781299, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685607390761021, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.217101861894557, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685591739076102, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.2170394948410985, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7228408710953, 1: -5.895548220955425, 2: -5.2170394948410985, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.6855901739076105, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031990349275, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590017390761, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031113121444, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590001739077, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031012720796, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590000173908, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031001412946, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590000017391, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000155381, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590000001739, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-2.71-1.90-1.00\n",
      "-3.44-2.71-2.49-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000016947, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.6855900000001744, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.71, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -2.49049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.90\n",
      "-4.10-3.49-3.19-1.90-1.00\n",
      "-3.44-2.71-1.96-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000001835, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590000000018, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.439, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -3.1882969, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9590489999999998, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.10-3.83-2.71-1.90\n",
      "-4.10-3.49-2.81-1.90-1.00\n",
      "-3.44-2.71-1.91-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2170310000001985, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.685590000000002, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.0951, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.826420489, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.80565938, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9059049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.41-3.56-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000022, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.68559, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.408910596090001, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -3.5552261467, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016624157000001, 1: -2.724348907, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -4.28940552743964, 3: -3.9450863970900003, 4: -4.010783960556001}, Best action: 3, Actual action: 3\n",
      "Action 3, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.220624238436, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -4.28940552743964, 3: -4.71321427284216, 4: -4.010783960556001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -4.28940552743964, 3: -4.71321427284216, 4: -4.010783960556001}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -4.28940552743964, 3: -4.71321427284216, 4: -4.5498134041059615}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.709999974260365, 2: -2.70999997486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.88-4.13-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000002, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.880898606015447, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.1281448799191045, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.90984745599, 2: -3.440473033887835, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999974260367, 2: -2.70999997486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.38-4.73-4.38-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.375230970872512, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.7318872133360195, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.47979092734381, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.47979092734381, 3: -5.123534466141605, 4: -4.377234037014}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.47979092734381, 3: -5.123534466141605, 4: -4.883282973682741}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.440473033887835, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100457074859703, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.27-4.92-4.13-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.270351739889427, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.918748291314943, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.1347622501835275, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.43918432645242, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710004570748597, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.41-4.74-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.411221289954046, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.741032251780152, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0992155294448125, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390221349516055, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100004570748597, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.28-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.281358252937328, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.694467804028314, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095529482255282, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439002583725797, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000457074858, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2306547465566675, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6868256610296095, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095145041043423, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439000295395643, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000045707486, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.219394260089651, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685750049348134, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095104743374813, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390000332418706, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710000000457075, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217396965980954, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685609847068412, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951005012633965, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390000036944177, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000457074, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2170836727235095, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685592390730193, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100053118818, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439000000406465, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000045705, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217038203763807, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855902820992625, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100005641119, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390000000443486, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710000000000457, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031948876784, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590032779232, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000600034, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439000000004805, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000000457, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031121438857, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590003763951, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000063895, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439000000000518, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000000044, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031015192687, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559000042815, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000006809, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390000000000556, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000000004, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.21703100186607, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000048331, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000726, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439000000000006, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000225755, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000005421, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000078, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.4390000000000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000026966, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000605, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000008, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000003187, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000067, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000001, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2170310000003735, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855900000000075, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000043, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-2.47\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000006, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4823900000000005, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4823900000000005, 2: -2.4724800000000005, 3: -3.3044366700000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4823900000000005, 2: -3.1499568000000004, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-3.17\n",
      "-4.69-4.49-3.52-2.71-1.96\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000001, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -3.1737088000000004, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9582389999999998, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.49-2.80\n",
      "-4.69-4.49-3.52-2.71-1.91\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.486084725237293, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999974260367, 2: -2.709999997486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.91\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.133238627442207, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.443708470438819, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999997426036, 2: -2.709999997486209, 3: -3.9899747455848, 4: -3.406702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9058239, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.72-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.716482288228187, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.102727723799664, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439470845007711, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999997426036, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.24-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.242053753464832, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.694857685100547, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.096244156836213, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.43904708429228, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999999742606, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.227040100277926, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.687443535547388, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095252553960368, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390047084083792, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.709999999997426, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2195332738211775, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685898922262636, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095119069206825, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390004708387534, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999999997424, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217531454414853, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685636338283792, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095102288300073, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439000047083667, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.709999999999974, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217118579451357, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685596487351439, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100266967777, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390000047083458, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999999999973, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217045012699801, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855908649790425, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100030510538, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390000004708328, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7099999999999995, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217033101903005, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855901112114395, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100003432428, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439000000047083, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031300271566, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590013901411, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.09510000038138, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390000000047083, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031041287299, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590001699058, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000041951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439000000000471, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031005504967, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000203886, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000004576, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439000000000047, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000715645, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000024096, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000496, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439000000000005, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000091082, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000002812, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000053, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.4390000000000005, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000011386, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000324, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000006, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000001401, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000037, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000001, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.21703100000017, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000005, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -3.439, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.406702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.81-2.80\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000022, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.8146041280000005, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.8035444700000003, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9005823899999998, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.40-3.55-2.72\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000003, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.39933934368, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.5523314335, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7198261829, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000582389999998, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.93-4.22-3.46-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.9320238683808, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.217322395503, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.458292351499, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7110297918799997, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000058239, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.42-4.81-4.12-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.416642433388448, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.80923352719551, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.12294904426449, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.4417633665726997, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7101076965470003, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.90000058239, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.34-4.72-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.337143400367208, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.720512078573789, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.100123231350335, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.4393635708603405, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100112413906, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.900000058239, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.26-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.257329123681489, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.693151025251151, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095896815531909, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.43904546261242, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71000117131265, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000058239, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.227185242821582, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.686991523105962, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095216506269252, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.4390054950244884, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100001218486245, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000005823898, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2191816579979875, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68582452238869, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.09511610159676, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.4390006481998348, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000126565984, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000582389, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217436028934637, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6856264945322454, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095102135201542, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000075071828, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000013128334, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000058237, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217101063464583, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855953789664735, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100274328336, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.4390000085705776, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000001360005, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000005823, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217042363309302, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.6855907601026, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100034375002, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000000967218, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710000000014072, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.900000000000058, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217032752014036, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590103854012, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100004220947, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.43900000010812, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000014544, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000000057, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031259323154, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590013804369, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000509671, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.43900000001199, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71000000000015, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000000006, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031037113854, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590001793271, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000060679, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000000001321, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.710000000000016, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2170310051639355, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000228478, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000007138, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000000000145, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.7100000000000017, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000701461, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559000002863, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000831, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000000000016, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000093336, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000003535, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000096, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439000000000002, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000012197, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000431, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000012, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000001569, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000053, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.095100000000001, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000199, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000007, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000025, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000004, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.842648214993707, 1: -2.71, 2: -3.3251736600000004, 3: -3.1962384900000007, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.0951, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044417119388, 1: -4.00332929473, 2: -3.439, 3: -4.4024629420548, 4: -4.4091250487882}, Best action: 2, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.50-3.44-2.71\n",
      "-4.69-4.49-3.52-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -4.68559, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4952943836465895, 1: -4.501770142375085, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990717889118397, 1: -4.501770142375085, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.5240405318948596, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.94-4.20-3.44-2.71\n",
      "-4.69-4.49-3.45-2.71-1.90\n",
      "-4.10-3.49-2.72-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -4.939776582832901, 2: -5.009747450753738, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.48898410712082, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.4881250941960165, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.724348907, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.90059049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.42-5.01-4.20-3.44-2.71\n",
      "-4.69-4.17-3.45-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.42292213209465, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -5.009747450753738, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.204649845072344, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.447504053189486, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.50-4.81-4.11-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.500187648319993, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.8067411195839735, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.112943267590718, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4398504053189485, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.34-4.71-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.343479071695018, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.712158158706878, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.712158158706878, 3: -5.696789124615154, 4: -5.188937235410424}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09757315506742, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390850405318947, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.64-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.637387067851945, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6902500714752975, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095416198337577, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390085040531897, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.26-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.262841264680185, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.686312127800967, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095138508116841, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000850405319, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2221969499868015, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685693404354738, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095104539639992, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000085040532, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217631352526017, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685604017543867, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09510052284683, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000008504053, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217102389463134, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685591825260319, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000591729665, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000850405, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217039617407172, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855902304561345, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100006606125, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000850405, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217032048410187, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590028396574, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000729495, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000008504, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031127842244, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900034305495, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000079837, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000008505, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.21703101556297, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000407723, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000000086735, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000853, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.2170310018865536, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000047799, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000000009365, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000085, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000227372, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000005539, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000101, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000001, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000027224, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000635, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09510000000001, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000003238, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000072, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000001, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000382, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000008, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000045, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000006, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031000000001, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.0, 3: -3.1880484900000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.070.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.96-1.00\n",
      "-3.44-2.71-1.90-1.010.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9590489999999998, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.00729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7147173587486213, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4428210605863834, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710471735874862, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.098195059074971, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439764212117277, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710047173587486, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217031, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.688096997850727, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.096028517722491, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4391146318175916, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7100047173587485, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.219061668259089, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.686592799140291, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095285703544498, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390152842423456, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7100004717358748, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.218046334129545, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.218046334129545, 3: -6.019632214437074, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685840699785072, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09513095059075, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439001910530293, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7100000471735877, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217335600238863, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685640139957015, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095104642588613, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390002292636352, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710000004717359, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217102073389069, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685598774492478, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100649962405, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000267474243, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710000000471736, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217045214677814, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685591403918796, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100086661654, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000030568486, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710000000047174, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217033558642006, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.69808607793082, 1: -5.895548220955425, 2: -5.217033558642006, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855902105878195, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100011142212, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000003438956, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7100000000047175, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217031426440334, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590030083973, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100001392776, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000038211, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.7100000000004716, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.90\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217031067012051, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590004136546, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000170229, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000042034, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710000000000047, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-2.55\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217031010051807, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559000055154, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000020428, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000004584, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -2.710000000000005, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.614339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.614339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Action 4, Last Action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.614339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.76-1.97\n",
      "-4.10-3.46-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217031001451928, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900000717, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000000024145, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.43900000000005, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.75782969, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9118098, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.48-2.72-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.21703100020327, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000009126, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000282, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.477742048900005, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.724348907, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.90177147, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.13-3.44-2.71\n",
      "-4.69-4.17-3.45-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.21703100002772, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000001141, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.126481059609032, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4544968195600005, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7128697814, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.900236196, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.00000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.71-4.11-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217031000003696, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.711008658283431, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.110790529804504, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.44287420489, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7104782969, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000295245, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.70-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.237620113209949, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.700841194969992, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.099807158941351, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439774840978, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100717445350004, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.90000354294, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.231443379246689, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.690927918239494, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0961983370863155, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.43913559717115, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100100442349, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.900000413343, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.00000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.222795951698659, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.687013444863864, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095319667417263, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439021695547384, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100013392313205, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000472392, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.000000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.218760485509596, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685910275094369, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095139540135107, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439003254332108, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100001721868843, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.90000000531441, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.2174633713773995, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685654055018873, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095106590022518, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390004649045873, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000215233604, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.90000000059049, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.00000000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217126121703028, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685601743420127, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951010355749675, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000639243805, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000002630633, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000649537, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.000000000000729, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.2170500243406055, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685592013157736, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100155336245, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000085232506, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000003156755, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000070858, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000000000000728, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.217034533091827, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590327138132, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100022437458, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000001108022, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000037307, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000007677, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000000000000073, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.17-3.44-2.71-1.97\n",
      "-4.10-3.46-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.895548220955425, 2: -5.21703161829107, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685590000000027, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.174279737010854, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.4555351240896015, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7119131875999996, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900059049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0000000000000007, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.21703161829107, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590050888154, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100003141244, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000141021, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000000043525, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000000827, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.2170311030485115, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590007633222, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000428352, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000176277, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000000005022, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000000081, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031016487762, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590001110287, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000057114, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.43900000000217, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000000057, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9000000000000008, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031002548109, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900001572905, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000007469, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000263, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000000000066, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.2170310003822165, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000021779, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09510000000096, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000316, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000000001, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000055863, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000002955, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000122, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000004, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.21703100000798, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000394, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000000000155, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000005, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000001118, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000052, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000002, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000154, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900000000075, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000022, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000003, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -3.9899747455848, 4: -3.4357702833}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -4.4757795439236885, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.54-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.542677954392369, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.18-3.44-2.71\n",
      "-4.75-4.12-3.45-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.17907914305782, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4493677954392368, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.75-4.11-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.753613105876834, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.111895828611564, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4400367795439237, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.27-4.71-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.272129715760236, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.70599693176305, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.097619374291735, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4391036779543924, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.239070486304094, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68967138635261, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095435916572231, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439010367795439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.222540871576024, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.686270231058768, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095141989571529, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439001036779544, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.218132974315204, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685692034658815, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095105038748583, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390001036779543, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217223845505161, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685604284852234, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100587854001, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000103677956, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217061855280826, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685591904646965, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100067183315, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000010367796, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217035628292124, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590244883182, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000075581225, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000103678, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.21703166118459, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590030610397, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000839792, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000103678, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031090912881, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590003741271, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000092378, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000001037, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031012121717, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000448953, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000010078, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000104, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.2170310015758234, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900000530575, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000001092, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000103, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000200559, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559000000619, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000118, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000001, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-2.46-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.21703100002507, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900000007145, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000012, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.4823900000000005, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -3.1670749000000002, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -2.482389973791001, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.44-3.23-1.97\n",
      "-4.10-3.44-2.71-1.96-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000003086, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000081, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000001, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -3.227443368770711, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9582389973791, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.75-4.12-3.86-2.81-1.97\n",
      "-4.10-3.44-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000374, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000009, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.858129128704276, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.8089179247541423, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.90582389973791, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.43-3.44-2.71\n",
      "-4.75-4.12-3.56-2.72-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000045, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000001, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.434594594250463, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.561036431921283, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.724609151263121, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.900582389973791, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.96-4.23-3.44-2.71\n",
      "-4.75-4.12-3.46-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.217031000000006, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.960580621342875, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.227898969281285, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4630370557152563, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.711932651005083, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.900058238997379, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.28-4.82-4.13-3.44-2.71\n",
      "-4.75-4.12-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.284882722095564, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.749725586978794, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.116411424213663, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.44220319436496, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.71023914845, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000059049000004, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.28-4.82-4.13-3.44-2.71\n",
      "-4.71-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.27576599766238, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.709265812310946, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.099825729856984, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.4395140296809963, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7100286978140002, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.90000059049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.24-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.242081907738104, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.6917854224152515, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095988937027306, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.43907464819744, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7100033480783, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000590489998, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.224554382930164, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.686929581233643, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095249358742657, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.439010176763167, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.71000038263752, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000059048998, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.218868399092266, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685844938704917, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095123179052431, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.439001327612708, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.710000043046721, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000005904898, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217421240260209, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685634268902961, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095103393271537, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.4390001676291146, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7100000047829687, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.900000000059049, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217105881837419, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.6855971754402415, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095100475106737, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.439000020637116, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7100000005261267, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000000059047, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217044300290338, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685591102380481, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095100064226738, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.439000002489874, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.710000000057396, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3481629, 1: -3.140029, 2: -1.9000000000005903, 3: -3.0759939000000003, 4: -3.667681998000001}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-3.44-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217033222957223, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685590162261707, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095100008439472, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -3.4390000002954784, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4971823973429, 1: -2.7100000000062177, 2: -3.676963015, 3: -4.23276679089, 4: -4.222354081509001}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.442969152885643, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710240438688385, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.900005823899738, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.10-3.44-2.71-1.97\n",
      "-4.10-4.02-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-2.02-1.020.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217031353727704, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685590023062143, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.095100001083285, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -4.024740725299001, 2: -4.886617741877297, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.0240028999999997, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.57-3.44-2.71-1.97\n",
      "-4.10-3.50-2.71-1.90-1.00\n",
      "-3.44-2.81-1.90-1.000.00\n",
      "-2.71-1.92-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217031054053106, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -4.685590003183675, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.19021080652514, 1: -4.569549987600519, 2: -4.570797431893961, 3: -5.237593959224205, 4: -4.6480110753339}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1), Last State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.305703858848, 1: -3.4975740725299, 2: -4.886617741877297, 3: -5.059852246933377, 4: -4.0557591030690014}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.8104423489999997, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.92480058, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0015309000000001, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.77-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.74-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217031007984088, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.7693575581426355, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7401327047, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.903720087, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.28-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.46-2.72-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.2848827228939435, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.693966755814264, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.0951, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4634074908070005, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71602654094, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9004960116, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.11-3.53-2.71-1.90-1.00\n",
      "-3.45-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.2306013444989485, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6864276755814265, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.114870067553671, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4463222472421, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7110044234900004, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90006200145, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.70-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.219066551670851, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.701687522276616, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.103008027021469, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4405458077511106, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7101506635234998, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000074401740001, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.23-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.230273548211144, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.6936052541150515, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.0971429069805465, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4392766182291457, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100210928932897, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000008680203, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.224847610654306, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.688046280065748, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.0955283514636625, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390447470664793, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100028123857722, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90000009920232, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.219802247918687, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.686182592692141, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.095179080270214, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390067527391235, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.710000361592457, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000111602613, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.00000000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217788124872503, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685713314288089, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.095113377745711, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390009681638025, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000451990574, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000001240029, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000015309, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217206597060603, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685613167402835, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.095102121987251, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390001334276166, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000055243294, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000001364032, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.000000000001531, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217067325302357, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685594035549957, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.095100320275094, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.439000017817469, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.71000000066292, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000148805, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000001532, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -5.217037901325701, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590662977822, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 4\n",
      "Action 4, Last Action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860173841948279, 1: -4.685590662977822, 2: -5.069894490274788, 3: -5.381869786704449, 4: -5.806320010540201}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0), Last State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.502779273676691, 1: -4.09510004645966, 2: -5.237700490029026, 3: -4.653233282992845, 4: -4.66256648182968}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0), Last State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6143205896907356, 1: -4.2113251062874735, 2: -3.4390000023187124, 3: -4.566883482753751, 4: -4.035215890359}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1), Last State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005877239, 1: -2.7100000000783453, 2: -3.288673639, 3: -4.2333619705674925, 4: -3.43841366979}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1), Last State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000016122, 3: -3.7086409260000006, 4: -3.291605478}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2), Last State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.1522410900000004, 2: -1.0000000000000153, 3: -2.677239, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.44-4.82-4.13-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.439773403287729, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.820656227252128, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.127849912057487, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439591670626156, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710028761227626, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000005823899737, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.35-4.73-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.348708884402997, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.725624051491777, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.098854244412935, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390824636569928, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100033478586414, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000582389973, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.26-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.26262637014864, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.692634343123656, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095542220003457, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390109581311985, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000381959452, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000058238997, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.227296454945026, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.686652632515166, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095153098086617, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439001405200276, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000042913304, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000005823898, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.218918277831787, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685739272701676, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095106448020886, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000175279804, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000047630664, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000000582389, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217340638671537, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6856101501670855, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09510078677873, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000213860645, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71000000052348, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000000058237, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.2170782855024935, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685592652307481, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100096000586, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000025626253, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000057065, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000000005823, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217037876919309, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855903429912225, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100011675785, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000302485, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000006178, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.900000000000058, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031965514821, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590043756509, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100001412591, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000352527, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7100000000006648, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000000000057, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031131994254, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590005519851, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000169814, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000040635, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000000071, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9000000000000006, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031017670505, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000689535, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000020273, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000464, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000000008, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031002325574, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000085375, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000002404, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000053, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.710000000000001, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000301711, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000010484, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000283, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000063, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000038664, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.6855900000012785, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000033, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000005, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000004902, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000155, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000004, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000616, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000018, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000077, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000002, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000009, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000001, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.97\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -3.2333482900000003, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9714339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.86-2.71-1.91\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.8629121149000003, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.820196288, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -1.9, 3: -3.8283902649000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -1.719, 4: -1.8981899999999998}, Best action: 1, Actual action: 3\n",
      "Action 3, Last Action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -2.4823900000000005, 2: -2.4823900000000005, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.69-4.44-3.44-2.71\n",
      "-4.69-4.19-3.48-2.71-1.91\n",
      "-4.10-3.53-2.71-1.96-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.438468813069, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.48139121149, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.71, 2: -2.820196288, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -1.9582389999999998, 2: -2.4823900000000005, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.22-4.96-4.16-3.44-2.71\n",
      "-4.69-4.19-3.44-2.76-1.91\n",
      "-4.10-3.53-2.71-1.91-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.96371873858589, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.1637737626138005, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.443239121149, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7571735900000003, 2: -2.820196288, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -1.9058239, 2: -2.4823900000000005, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.729, 3: -3.1880484900000003, 4: -1.8819}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3), Last State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.899, 1: -0.9999, 2: 0.0, 3: -1.71, 4: 0}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 2\n",
      "V:\n",
      "-5.44-4.77-4.11-3.44-2.71\n",
      "-4.69-4.19-3.48-2.72-1.91\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.442315278254571, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.769028621575767, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.10540106439207, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4776345200149, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -2.7194347180000005, 2: -2.820196288, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7117596690000005, 1: -1.9005823899999998, 2: -2.4823900000000005, 3: -3.8283902649000003, 4: -2.546109}, Best action: 1, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.820196288, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9071433899999999, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.31-4.70-4.13-3.44-2.71\n",
      "-4.69-4.19-3.45-2.73-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.307144711301829, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.702277724315153, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.127424067651276, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4505055735814905, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7268057747, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9007143389999999, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.24-4.71-4.11-3.44-2.71\n",
      "-4.69-4.19-3.45-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.239559427825457, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.713441267229049, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.107651921366135, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.453763234865149, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71225919206, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000714339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.24-4.70-4.11-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.241843369238076, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.698542183029475, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.108313412377385, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.442306269055115, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710283780665, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000071433899999, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.70-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.230003505177683, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.697588082328629, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.099099419172381, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4395604892441614, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100341642124, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000007143389999, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.23-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.228046697203958, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.690029337762492, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0959539382050085, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.43908372193646, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100039950358297, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000714338998, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.221728433308014, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.686725623722306, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095253208589033, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439011608172668, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710000457365042, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000071433898, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.218420598545869, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685827661329347, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095124723478764, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390015312829507, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71000005152265, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.900000000714339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217362465531358, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685633792150734, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095103712687067, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000194861642, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100000057308797, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000714339, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.21709961819523, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685597386491597, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100529106637, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000024128177, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100000006309495, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000071433, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217043844877717, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685591167225536, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100072454486, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000002923887, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710000000068881, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000007142, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217033229940457, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590175410687, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100009613798, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000348182, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710000000007467, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000000714, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031365076702, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590025328246, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100001243408, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000408665, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100000000008047, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.900000000000007, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031057023549, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590003539985, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000001574425, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000047385, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710000000000086, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9000000000000006, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031008569743, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000481526, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000019582, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000005436, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.7100000000000093, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031001247011, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000064015, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951000000023985, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.4390000000000622, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.710000000000001, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000176553, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000008344, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.09510000000029, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000007, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000024415, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000001069, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000035, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439000000000001, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000003308, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000135, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.095100000000004, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000441, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000016, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000057, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.685590000000002, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.2170310000000075, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031000000001, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "V:\n",
      "-5.22-4.69-4.10-3.44-2.71\n",
      "-4.69-4.19-3.44-2.71-1.90\n",
      "-4.10-3.53-2.71-1.90-1.00\n",
      "-3.44-2.71-1.90-1.000.00\n",
      "-2.71-1.90-1.000.000.00\n",
      "\n",
      "Action values: {0: -5.695605790293107, 1: -6.124822998670133, 2: -5.217031, 3: -5.7285807520886385, 4: -5.712087204844133}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1), Last State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.216888433774903, 1: -5.0300547850511546, 2: -4.68559, 3: -5.696789124615154, 4: -5.235741832093614}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2), Last State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.045505604235658, 1: -4.0951, 2: -4.552206728731301, 3: -5.123534466141605, 4: -5.01695894851676}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2), Last State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613907601981489, 1: -4.50898818184, 2: -3.439, 3: -4.71321427284216, 4: -4.829399817636705}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3), Last State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.120916721624388, 1: -4.17846880369, 2: -2.71, 3: -4.924378905136668, 4: -3.4357702833}, Best action: 2, Actual action: 2\n",
      "Action 2, Last Action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4), Last State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.9, 2: -3.2257315800000006, 3: -3.3044366700000003, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4), Last State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6108999978121847, 1: -1.0, 2: -1.88928, 3: -3.0826359000000005, 4: -1.8981899999999998}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4), Last State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7999999999999998, 1: 0.0, 2: -0.9, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Action 1, Last Action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4), Last State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Action 0, Last Action: 1\n",
      "[138, 57, 45, 51, 59, 35, 37, 15, 19, 15, 13, 23, 11, 19, 24, 17, 15, 7, 15, 23, 7, 9, 9, 13, 9, 9, 9, 9, 9, 11, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 9, 7, 7, 7, 9, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 11, 7, 9, 9, 11, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 11, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 8, 7, 9, 7, 7, 7, 7, 8, 7, 7, 7, 8, 9, 15, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 7, 7, 7, 7, 7, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 13, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 15, 9, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 8, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 13, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 8, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 9, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(0.9, 0.01, 0.9, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(1000, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 159)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 50)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m         pygame\u001b[39m.\u001b[39mquit()\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(step)\n\u001b[0;32m---> 39\u001b[0m gameDisplay\u001b[39m.\u001b[39;49mfill(white)\n\u001b[1;32m     40\u001b[0m drawGrid(gridSize,gridSize,terminal)\n\u001b[1;32m     41\u001b[0m text \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mrender(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, black)\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
