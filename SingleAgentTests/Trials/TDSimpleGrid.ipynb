{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: -0.9, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 4\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: -0.9, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: -0.9, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 4\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.90 -0.90 -0.90 -0.90 -0.90 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -1.72 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.90 -0.90 -0.90 \n",
      "-0.90 -0.90 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.8009, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8747, 2: -1.8009, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -1.719, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.87 -1.72 -0.99 -0.99 -0.99 \n",
      "-1.72 -1.72 -1.72 -0.99 -0.99 \n",
      "-0.99 -1.72 -0.99 -0.90 -0.90 \n",
      "-0.99 -0.99 -0.90 -0.90 0.00 \n",
      "-0.90 -0.90 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -1.88199, 1: -1.8747, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4798600000000004, 2: -1.88199, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.6036019, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.8009}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.8009}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.47 -1.80 -1.72 -1.72 -0.99 \n",
      "-2.46 -1.79 -1.72 -1.72 -0.99 \n",
      "-1.72 -1.72 -1.72 -1.72 -0.99 \n",
      "-1.72 -1.72 -0.99 -0.90 0.00 \n",
      "-1.72 -0.99 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.5469280000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.5469280000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4798600000000004, 2: -2.5469280000000003, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.46519, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.55 -1.80 -1.72 -1.72 -0.99 \n",
      "-2.47 -2.46 -1.72 -1.72 -0.99 \n",
      "-2.46 -1.79 -1.72 -1.72 -0.99 \n",
      "-1.72 -1.72 -0.99 -0.90 0.00 \n",
      "-1.72 -0.99 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.5469280000000003, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.5469280000000003, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.5469280000000003, 3: -3.2236822800000002, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.6036019, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -3.0679749000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.546109, 1: -2.46519, 2: -2.46429, 3: -3.0679749000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.61 -2.54 -2.47 -1.80 -0.99 \n",
      "-2.47 -2.47 -2.47 -1.87 -1.72 \n",
      "-2.46 -1.79 -1.72 -1.72 -0.99 \n",
      "-1.72 -1.72 -0.99 -0.90 0.00 \n",
      "-1.72 -0.99 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -2.6134218000000002, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.5396380000000005, 3: -2.6036019, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.8009}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.88199, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.88199, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -1.88199, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.5963119, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.69 -2.60 -2.60 -2.47 -1.80 \n",
      "-2.47 -2.47 -2.47 -1.87 -1.87 \n",
      "-2.46 -1.79 -1.72 -1.72 -1.00 \n",
      "-1.72 -1.72 -0.99 -0.90 0.00 \n",
      "-1.72 -0.99 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -3.2184489600000004, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.1440609000000004, 2: -3.2184489600000004, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3439624209, 1: -3.1440609000000004, 2: -3.2184489600000004, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5389090000000003, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5389090000000003, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5306290000000002, 1: -2.5389090000000003, 2: -2.597868, 3: -3.1499568000000004, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2171148900000004, 2: -3.2184489600000004, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -2.5389090000000003, 2: -2.597868, 3: -3.2648051700000007, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.1499658000000004, 2: -2.597868, 3: -3.2648051700000007, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.1499658000000004, 2: -2.597868, 3: -3.2648051700000007, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.1499658000000004, 2: -2.597868, 3: -3.2648051700000007, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5979579999999998, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.546109, 1: -2.46519, 2: -2.664207, 3: -3.0679749000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.22 -2.60 -2.60 -2.47 -1.80 \n",
      "-3.15 -2.55 -2.54 -1.87 -1.87 \n",
      "-2.47 -2.46 -1.79 -1.72 -1.00 \n",
      "-1.72 -1.72 -1.72 -0.90 0.00 \n",
      "-1.72 -0.99 -0.90 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2782277790000003, 2: -3.2184489600000004, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.1566726000000007, 3: -2.6036019, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.1566726000000007, 3: -2.6036019, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.1566726000000007, 3: -2.6036019, 4: -3.26405988}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2782277790000003, 2: -3.326117976, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2782277790000003, 2: -3.326117976, 3: -3.2236822800000002, 4: -3.2847075990000003}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.2782277790000003, 2: -3.326117976, 3: -3.8335508748000002, 4: -3.2847075990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.1499658000000004, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.46519, 2: -3.1425039000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.719, 3: -1.719, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -1.719, 4: -1.8738000000000001}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -1.719, 4: -1.8738000000000001}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -2.46429, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.5389090000000003, 2: -3.1425039000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.5389090000000003, 2: -3.1425039000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.5389090000000003, 2: -3.1425039000000003, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -1.8738000000000001, 3: -2.664207, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.46429, 4: -2.46429}, Best action: 2, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.4724800000000005, 2: -2.4797700000000003, 3: -2.664207, 4: -3.1632246000000004}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.1499568000000004, 2: -2.4797700000000003, 3: -2.664207, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.28 -3.14 -2.60 -2.47 -1.80 \n",
      "-3.16 -2.55 -2.54 -1.87 -1.87 \n",
      "-2.55 -2.46 -1.79 -1.72 -1.00 \n",
      "-2.47 -1.87 -1.72 -0.90 0.00 \n",
      "-2.55 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7792950759000004, 2: -3.326117976, 3: -3.9387195884700006, 4: -3.2847075990000003}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7792950759000004, 2: -3.326117976, 3: -3.9387195884700006, 4: -3.2847075990000003}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7792950759000004, 2: -3.326117976, 3: -3.9387195884700006, 4: -3.8890839150900005}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.1566726000000007, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.597868, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.78 -3.16 -2.60 -2.47 -1.80 \n",
      "-3.16 -3.08 -2.54 -1.87 -1.87 \n",
      "-2.55 -2.55 -2.46 -1.72 -1.00 \n",
      "-2.47 -2.46 -1.73 -0.90 0.00 \n",
      "-2.55 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7792950759000004, 2: -3.7787033466000004, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.1566726000000007, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.318679899, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.318679899, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2766805800000003, 2: -3.318679899, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1558707, 2: -3.1506858, 3: -3.0759939000000003, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.21180048, 2: -3.1565907, 3: -3.2648051700000007, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1558707, 2: -3.1506858, 3: -3.764437857, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7192231170000003, 2: -3.318679899, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.4724800000000005, 2: -2.5469280000000003, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8747, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.78 -3.34 -3.14 -2.55 -1.80 \n",
      "-3.21 -3.15 -2.54 -2.47 -1.90 \n",
      "-2.55 -2.55 -2.46 -1.72 -1.00 \n",
      "-2.47 -2.46 -1.73 -0.90 0.00 \n",
      "-2.55 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.7792950759000004, 2: -3.8347751406600006, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.21180048, 2: -3.7664606880000004, 3: -3.2648051700000007, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.27151197, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.664297, 2: -2.597868, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.664297, 2: -2.597868, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.664297, 2: -2.597868, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.4798600000000004, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.546109, 1: -2.5389090000000003, 2: -2.664207, 3: -3.0679749000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.4798600000000004, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.78 -3.34 -3.14 -2.55 -1.80 \n",
      "-3.26 -3.15 -2.55 -2.47 -1.90 \n",
      "-3.15 -2.66 -2.48 -1.79 -1.00 \n",
      "-2.47 -2.46 -1.79 -0.99 0.00 \n",
      "-2.55 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.7810855710900007, 1: -3.87948789639, 2: -3.8347751406600006, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7810855710900007, 1: -3.87948789639, 2: -3.8347751406600006, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340787869691901, 1: -3.87948789639, 2: -3.8347751406600006, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7192231170000003, 2: -3.3420459699000005, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7192231170000003, 2: -3.3420459699000005, 3: -3.7715428368000006, 4: -3.335323527}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7192231170000003, 2: -3.3420459699000005, 3: -3.7715428368000006, 4: -3.9351444095700003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.1633065000000005, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.546109, 1: -3.1499658000000004, 2: -2.664207, 3: -3.0679749000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.1633065000000005, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -2.5469280000000003, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -1.8009}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -1.8009}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.538819}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6782938}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6782938}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.897389, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.88 -3.72 -3.16 -2.60 -2.47 \n",
      "-3.26 -3.15 -2.55 -2.47 -1.90 \n",
      "-3.15 -2.66 -2.48 -1.79 -1.00 \n",
      "-2.47 -2.46 -1.79 -0.99 0.00 \n",
      "-2.55 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.440246650903791, 1: -3.87948789639, 2: -3.985089570936, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.283528338, 2: -3.7664606880000004, 3: -3.2648051700000007, 4: -3.325968999}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.283528338, 2: -3.7664606880000004, 3: -3.2648051700000007, 4: -3.325968999}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.283528338, 2: -3.7664606880000004, 3: -3.8709727047000007, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1499658000000004, 2: -3.27659868, 3: -3.27151197, 4: -3.7671240780000006}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.1499568000000004, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.27734397, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -2.597868, 3: -3.27734397, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.664297, 2: -3.1558617, 3: -3.0752649, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8747, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.93 -3.72 -3.16 -2.60 -2.47 \n",
      "-3.33 -3.15 -2.55 -2.47 -1.90 \n",
      "-3.21 -3.08 -2.48 -1.79 -1.00 \n",
      "-2.66 -2.48 -1.79 -0.99 0.00 \n",
      "-2.55 -1.88 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.440246650903791, 1: -3.932440977339001, 2: -3.985089570936, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.7798251318000005, 2: -3.7664606880000004, 3: -3.9467552242500004, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.7798251318000005, 2: -3.7664606880000004, 3: -3.9467552242500004, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7589259609, 1: -3.7798251318000005, 2: -3.7664606880000004, 3: -3.9467552242500004, 4: -3.92663178909}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -3.985089570936, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -3.985089570936, 3: -3.9387195884700006, 4: -3.983063952069}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -3.985089570936, 3: -4.4842348255077, 4: -3.983063952069}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -3.985089570936, 3: -4.57470528372666, 4: -3.983063952069}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -3.985089570936, 3: -4.57470528372666, 4: -4.5245881963827905}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7192231170000003, 2: -3.7802961459900004, 3: -3.7715428368000006, 4: -4.000571676576}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.1558707, 2: -3.1506858, 3: -3.764437857, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.1499658000000004, 2: -2.664207, 3: -3.0679749000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.1499658000000004, 2: -2.664207, 3: -3.0679749000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.1499658000000004, 2: -2.664207, 3: -3.0679749000000003, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -2.46519, 2: -2.605887, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8018, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.4798600000000004, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -1.8747, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.665026, 2: -2.4797700000000003, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -1.8747, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.99 -3.77 -3.16 -2.60 -2.47 \n",
      "-3.77 -3.16 -3.07 -2.48 -1.90 \n",
      "-3.21 -3.08 -2.54 -1.80 -1.00 \n",
      "-2.66 -2.55 -1.88 -1.00 0.00 \n",
      "-2.55 -1.88 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.440246650903791, 1: -3.9872789869239003, 2: -4.3110796818636, 3: -4.57470528372666, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.7798251318000005, 2: -3.7664606880000004, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.1558707, 2: -3.27741687, 3: -3.764437857, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1632336, 2: -3.1558617, 3: -3.0752649, 4: -3.325968999}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.2177053800000004, 2: -3.27659868, 3: -3.27151197, 4: -3.7671240780000006}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.7798251318000005, 2: -3.8329013358, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.2177053800000004, 2: -3.27659868, 3: -3.27151197, 4: -3.7671240780000006}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.664297, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.22360938, 2: -2.547657, 3: -2.664207, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.897389, 3: -2.664207, 4: -3.1425039000000003}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.897389, 3: -2.664207, 4: -3.1425039000000003}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.6126109, 2: -1.897389, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.31 -3.77 -3.16 -2.60 -2.47 \n",
      "-3.83 -3.28 -3.07 -2.48 -1.90 \n",
      "-3.27 -3.16 -2.54 -1.80 -1.00 \n",
      "-3.09 -2.55 -1.88 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.440246650903791, 1: -4.349561055972391, 2: -4.3110796818636, 3: -4.57470528372666, 4: -4.58038137209644}, Best action: 2, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -4.349561055972391, 2: -4.3110796818636, 3: -4.57470528372666, 4: -4.58038137209644}, Best action: 2, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.440246650903791, 1: -4.349561055972391, 2: -4.3110796818636, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.8239778097, 2: -3.7802961459900004, 3: -3.7715428368000006, 4: -4.000571676576}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.835999207399895, 1: -4.349561055972391, 2: -4.38605766599436, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.8843238709800003, 2: -3.8329013358, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.706551639, 2: -3.27741687, 3: -3.764437857, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.1499658000000004, 2: -3.1632246, 3: -3.0679749000000003, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.706551639, 2: -3.712801356, 3: -3.764437857, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.706551639, 2: -3.712801356, 3: -3.764437857, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.706551639, 2: -3.712801356, 3: -3.764437857, 4: -3.92669812809}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1632336, 2: -3.1558617, 3: -3.8066360949, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.599425, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8018, 2: -1.8738000000000001, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.39 -3.78 -3.16 -2.60 -2.47 \n",
      "-3.88 -3.71 -3.15 -2.48 -1.90 \n",
      "-3.27 -3.16 -2.55 -1.87 -1.00 \n",
      "-3.09 -2.55 -1.88 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.439606187595239, 2: -4.38605766599436, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.8239778097, 2: -3.7802961459900004, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2793423300000004, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2793423300000004, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2766805800000003, 2: -3.2793423300000004, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.1499658000000004, 2: -3.1632246, 3: -3.9008914281899996, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.599425, 2: -2.6133399, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.599425, 2: -2.6133399, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.599425, 2: -2.6133399, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -1.88937, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.40 -3.82 -3.28 -2.60 -2.47 \n",
      "-3.88 -3.71 -3.16 -2.48 -1.90 \n",
      "-3.27 -3.16 -2.61 -1.87 -1.00 \n",
      "-3.09 -2.55 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.439606187595239, 2: -4.400645644851337, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.8239778097, 2: -3.8408452254990006, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.8269031409, 2: -3.712801356, 3: -3.764437857, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.2773448700000003, 2: -3.1632246, 3: -3.9008914281899996, 4: -3.3797035890000005}, Best action: 2, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.2773448700000003, 2: -3.1632246, 3: -3.9008914281899996, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4797700000000003, 1: -2.5979579999999998, 2: -2.605887, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -2.6134218000000002, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.2793423300000004, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -2.6134218000000002, 3: -3.8158984773, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -2.6134218000000002, 3: -3.8158984773, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -2.6134218000000002, 3: -3.8158984773, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6782938}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6782938}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -3.1499568000000004, 3: -2.5963119, 4: -2.6782938}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -2.665026, 2: -3.1640509800000007, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.5979579999999998, 2: -2.605887, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.5979579999999998, 2: -2.605887, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.5979579999999998, 2: -2.605887, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.2773448700000003, 2: -3.22493616, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.5979579999999998, 2: -2.605887, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88937, 2: -1.8738000000000001, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.44 -3.84 -3.34 -2.69 -2.68 \n",
      "-3.88 -3.76 -3.28 -2.61 -1.90 \n",
      "-3.27 -3.16 -2.61 -1.89 -1.00 \n",
      "-3.09 -2.55 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.439606187595239, 2: -4.437486590342133, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -4.289766879330001, 2: -3.8408452254990006, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.3381122130000005, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.3381122130000005, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.3381122130000005, 3: -3.7224468009000007, 4: -3.93749878068}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.2288508900000004, 2: -3.1640509800000007, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68567299, 1: -3.2288508900000004, 2: -3.1640509800000007, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3439624209, 1: -3.2288508900000004, 2: -3.1640509800000007, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -3.318008319, 3: -3.3183022500000003, 4: -2.6782938}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -3.318008319, 3: -3.3183022500000003, 4: -2.6782938}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.68413309, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.3372473580000004}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8997308, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.44 -3.93 -3.41 -3.23 -2.71 \n",
      "-3.88 -3.76 -3.28 -2.61 -1.90 \n",
      "-3.27 -3.16 -2.61 -1.89 -1.00 \n",
      "-3.09 -2.55 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.439606187595239, 2: -4.454833291688404, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.8843238709800003, 2: -3.93799779828, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.379851108, 2: -3.27659868, 3: -3.27151197, 4: -3.7671240780000006}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.379851108, 2: -3.27659868, 3: -3.27151197, 4: -3.7671240780000006}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.379851108, 2: -3.27659868, 3: -3.8770758927, 4: -3.7671240780000006}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1632336, 2: -3.27202956, 3: -3.8066360949, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.665026, 2: -2.666484, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8997308, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999998999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.45 -3.93 -3.41 -3.23 -2.71 \n",
      "-3.94 -3.76 -3.28 -2.61 -1.90 \n",
      "-3.38 -3.20 -2.61 -1.89 -1.00 \n",
      "-3.09 -2.67 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.490262954253325, 2: -4.454833291688404, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -4.289766879330001, 2: -3.9877922284299, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -4.289766879330001, 2: -3.9877922284299, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.478149602108901, 1: -4.289766879330001, 2: -3.9877922284299, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.4092063432, 3: -3.7224468009000007, 4: -3.997620770598001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.2288508900000004, 2: -3.3858230760000003, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.6775738000000002, 2: -2.605887, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.899972999, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.49 -4.00 -3.72 -3.33 -2.71 \n",
      "-3.94 -3.76 -3.28 -2.68 -1.90 \n",
      "-3.38 -3.20 -2.61 -1.89 -1.00 \n",
      "-3.09 -2.67 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.490262954253325, 2: -4.5304296782987405, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.9383570827980003, 2: -3.93799779828, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.8269031409, 2: -4.00884004269, 3: -3.764437857, 4: -4.294976640399}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -3.9383570827980003, 2: -4.342994443997999, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.379851108, 2: -3.7898790840000003, 3: -3.94175252007, 4: -3.7671240780000006}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.23003187, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 0, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.23003187, 2: -3.1558617, 3: -3.27734397, 4: -3.325968999}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.8926337265, 2: -3.7898790840000003, 3: -3.94175252007, 4: -3.7671240780000006}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.8926337265, 2: -3.7898790840000003, 3: -3.94175252007, 4: -3.7671240780000006}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.8926337265, 2: -3.7898790840000003, 3: -3.94175252007, 4: -4.328082910980001}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.27867165, 2: -3.27202956, 3: -3.8066360949, 4: -3.325968999}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.8269031409, 2: -4.00884004269, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.27867165, 2: -3.27202956, 3: -3.8066360949, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.6843544, 2: -2.6133399, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88937, 2: -1.89737919, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -0.999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.53 -4.00 -3.72 -3.33 -2.71 \n",
      "-3.95 -3.90 -3.28 -2.68 -1.90 \n",
      "-3.87 -3.28 -2.68 -1.90 -1.00 \n",
      "-3.16 -2.67 -1.89 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.538804512032133, 2: -4.5304296782987405, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.289766879330001, 2: -4.06023636083499, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.289766879330001, 2: -4.06023636083499, 3: -4.800298739017636, 4: -4.000571676576}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.289766879330001, 2: -4.06023636083499, 3: -4.800298739017636, 4: -4.54052022568416}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.85628985522, 3: -3.7224468009000007, 4: -3.997620770598001}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.289766879330001, 2: -4.3212055448125, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90304449819, 1: -3.93303425769, 2: -4.00884004269, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.4904427314669, 2: -4.3212055448125, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.7791403560000005, 2: -3.85628985522, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.2773448700000003, 2: -3.3268395959999997, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.6843544, 2: -2.6917236900000003, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.89819819, 2: -1.88937, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -0.9999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.54 -4.39 -3.86 -3.33 -2.71 \n",
      "-3.95 -3.93 -3.33 -2.68 -1.90 \n",
      "-3.87 -3.28 -2.69 -1.90 -1.00 \n",
      "-3.16 -2.67 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.538804512032133, 2: -4.593506025856434, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.031515105759801, 2: -4.342994443997999, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.031515105759801, 2: -4.342994443997999, 3: -3.9467552242500004, 4: -4.337393207238}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.031515105759801, 2: -4.342994443997999, 3: -4.491547254067501, 4: -4.337393207238}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.8926337265, 2: -3.8733145443000003, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.27867165, 2: -3.344008275, 3: -3.8066360949, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.705284548, 2: -2.666484, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.89819819, 2: -1.8988559999999999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.55 -4.39 -3.86 -3.33 -2.71 \n",
      "-4.34 -3.93 -3.33 -2.68 -1.90 \n",
      "-3.89 -3.33 -2.69 -1.90 -1.00 \n",
      "-3.16 -2.70 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.550752182845714, 2: -4.593506025856434, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.44053629145898, 2: -4.342994443997999, 3: -4.614681961072189, 4: -4.337393207238}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.44053629145898, 2: -4.342994443997999, 3: -4.614681961072189, 4: -4.337393207238}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.44053629145898, 2: -4.342994443997999, 3: -4.614681961072189, 4: -4.84702781858658}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -3.93303425769, 2: -4.00884004269, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.3877192050000002, 2: -3.344008275, 3: -3.8066360949, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.3877192050000002, 2: -3.344008275, 3: -3.8066360949, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.3877192050000002, 2: -3.344008275, 3: -3.8066360949, 4: -3.92663178909}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.6988251400000003, 2: -2.6917236900000003, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8981270000000001, 2: -1.89737919, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.58 -4.39 -3.86 -3.33 -2.71 \n",
      "-4.44 -3.99 -3.33 -2.68 -1.90 \n",
      "-3.89 -3.39 -2.70 -1.90 -1.00 \n",
      "-3.16 -2.70 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.868363716147351, 2: -4.593506025856434, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.835999207399895, 1: -4.868363716147351, 2: -4.593506025856434, 3: -4.954070315604737, 4: -4.58038137209644}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.835999207399895, 1: -4.868363716147351, 2: -4.593506025856434, 3: -4.954070315604737, 4: -5.06814704860776}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.4904427314669, 2: -4.393224242841251, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.9325633803000004, 2: -3.85628985522, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.333653559, 2: -3.3858230760000003, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.6775738000000002, 2: -2.69956682919, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8981270000000001, 2: -1.89973791819, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -0.9999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.84 -4.46 -3.93 -3.34 -2.71 \n",
      "-4.44 -3.99 -3.33 -2.70 -1.90 \n",
      "-3.89 -3.39 -2.70 -1.90 -1.00 \n",
      "-3.16 -2.70 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.835999207399895, 1: -4.868363716147351, 2: -4.917862239287057, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.835999207399895, 1: -4.868363716147351, 2: -4.917862239287057, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.300759278733905, 1: -4.868363716147351, 2: -4.917862239287057, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.44053629145898, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.8926337265, 2: -3.9430554909300004, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.23003187, 2: -3.1558617, 3: -3.7307063250000008, 4: -3.325968999}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.705284548, 2: -2.7041889339000003, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8998198109, 2: -1.8988559999999999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999, 2: -0.99999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.92 -4.46 -3.93 -3.34 -2.71 \n",
      "-4.47 -3.99 -3.33 -2.70 -1.90 \n",
      "-3.85 -3.39 -2.70 -1.90 -1.00 \n",
      "-3.23 -2.71 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -4.98367076769651, 2: -4.917862239287057, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.4904427314669, 2: -4.462917207012325, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.9325633803000004, 2: -3.985888368312, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9320325297900003, 1: -3.9325633803000004, 2: -3.985888368312, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.478149602108901, 1: -3.9325633803000004, 2: -3.985888368312, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4020615510000005, 2: -3.3268395959999997, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.70524025, 2: -2.69956682919, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999972918, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.95 -4.49 -3.99 -3.34 -2.71 \n",
      "-4.47 -3.99 -3.40 -2.71 -1.90 \n",
      "-3.85 -3.39 -2.70 -1.90 -1.00 \n",
      "-3.23 -2.71 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -4.98367076769651, 2: -5.006749161608688, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -4.98367076769651, 2: -5.006749161608688, 3: -4.954070315604737, 4: -5.1275545858044875}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -4.98367076769651, 2: -5.006749161608688, 3: -5.40820398720031, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4662554627507, 1: -4.4970869476108986, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -5.016034001597719, 2: -5.006749161608688, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.4904427314669, 2: -4.531238069831133, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -3.987338314959, 2: -4.00884004269, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.3877192050000002, 2: -3.4146970164000003, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.705284548, 2: -2.70849225339, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899972999, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.02 -4.53 -3.99 -3.34 -2.71 \n",
      "-4.50 -4.01 -3.40 -2.71 -1.90 \n",
      "-3.85 -3.41 -2.70 -1.90 -1.00 \n",
      "-3.23 -2.71 -1.90 -1.00 0.00 \n",
      "-2.61 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.016034001597719, 2: -5.037933528649058, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.4970869476108986, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.84551134965, 2: -3.9430554909300004, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.23003187, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.325968999}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.22360938, 2: -2.6791776, 3: -2.664207, 4: -3.1632246000000004}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.3331811670000002, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.3331811670000002, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.325968999}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.3331811670000002, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.92663178909}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.6791776, 3: -2.664207, 4: -3.1632246000000004}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.6791776, 3: -2.664207, 4: -3.1632246000000004}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.6791776, 3: -3.3244283700000006, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.89999729909, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.04 -4.53 -3.99 -3.34 -2.71 \n",
      "-4.46 -4.01 -3.40 -2.71 -1.90 \n",
      "-3.90 -3.41 -2.70 -1.90 -1.00 \n",
      "-3.39 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.0442438277246, 2: -5.037933528649058, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.57878830826348, 2: -4.531238069831133, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -3.98799641079, 2: -3.985888368312, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4022001339, 2: -3.3858230760000003, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4022001339, 2: -3.3858230760000003, 3: -3.8158984773, 4: -3.3439410360000004}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4022001339, 2: -3.3858230760000003, 3: -3.8158984773, 4: -3.942986342760001}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.707195257, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999997290989998, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.04 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.46 -4.01 -3.40 -2.71 -1.90 \n",
      "-3.90 -3.41 -2.70 -1.90 -1.00 \n",
      "-3.39 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.0442438277246, 2: -5.074096189428124, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.4645728879775906, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -3.900876949665, 2: -3.9430554909300004, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.3913257867000004, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7069155722629, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899999729828, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.02 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.51 -4.01 -3.40 -2.71 -1.90 \n",
      "-3.94 -3.41 -2.70 -1.90 -1.00 \n",
      "-3.41 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.020728422034309, 2: -5.074096189428124, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.506167618026409, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0370615821935, 2: -3.9430554909300004, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0370615821935, 2: -3.9430554909300004, 3: -3.94175252007, 4: -4.4026103491379995}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0370615821935, 2: -3.9430554909300004, 3: -4.4869947932637, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.43005240438, 2: -3.4146970164000003, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.6988251400000003, 2: -2.7060495129, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8998198109, 2: -1.8998774999999999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.05 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.52 -4.01 -3.40 -2.71 -1.90 \n",
      "-4.04 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.41 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.052068612804822, 2: -5.074096189428124, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.57878830826348, 2: -4.581693385315834, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.577926665239109, 1: -4.57878830826348, 2: -4.581693385315834, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0659132653675885, 1: -4.57878830826348, 2: -4.581693385315834, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.042786387545901, 2: -4.00884004269, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4020615510000005, 2: -3.4193330912439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.708736560829, 2: -2.7060495129, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8997317, 2: -1.89973791819, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -0.99999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.05 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.52 -4.04 -3.42 -2.71 -1.90 \n",
      "-4.04 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.41 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.052068612804822, 2: -5.115530217786491, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.543436303059341, 2: -4.5200571931287, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.042786387545901, 2: -4.056553860579, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.43005240438, 2: -3.4275180650400006, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.708736560829, 2: -2.70938762829, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999819810891903, 2: -1.8998774999999999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999, 2: -0.999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.07 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.54 -4.06 -3.42 -2.71 -1.90 \n",
      "-4.04 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.41 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.06645318771473, 2: -5.115530217786491, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.543436303059341, 2: -4.626662693225049, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0370615821935, 2: -4.060210132377001, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.431734192202949, 2: -3.4059792064590004, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.70950658399, 2: -2.70849225339, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999819810891903, 2: -1.89998694, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.09 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.61 -4.06 -3.42 -2.71 -1.90 \n",
      "-4.06 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.086828724249539, 2: -5.115530217786491, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.624363511882669, 2: -4.626662693225049, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.624363511882669, 2: -4.626662693225049, 3: -4.614681961072189, 4: -4.9025282814970375}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.624363511882669, 2: -4.626662693225049, 3: -5.099360584575693, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0625493154511405, 2: -4.060210132377001, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.43005240438, 2: -3.4368284207754902, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.70950658399, 2: -2.709834630021244, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999729747, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.12 -4.58 -3.99 -3.40 -2.71 \n",
      "-4.63 -4.06 -3.42 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.115530217786491, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6050392654052485, 2: -4.581693385315834, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -3.98799641079, 2: -4.007181075991201, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4321062605490003, 2: -3.4193330912439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.70524025, 2: -2.708954489277, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89996507, 2: -1.89973791819, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -0.999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.12 -4.59 -4.00 -3.40 -2.71 \n",
      "-4.63 -4.06 -3.43 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.122724663884475, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6050392654052485, 2: -4.588446431271484, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.068459444986559, 2: -4.007181075991201, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.068459444986559, 2: -4.007181075991201, 3: -4.746955852347301, 4: -3.997620770598001}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.068459444986559, 2: -4.007181075991201, 3: -4.746955852347301, 4: -4.537834901244182}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4022001339, 2: -3.43141046577, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7093117387339003, 2: -2.708954489277, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999729018, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.13 -4.60 -4.06 -3.43 -2.71 \n",
      "-4.63 -4.06 -3.43 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.12891407571835, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.12891407571835, 3: -5.477593720554204, 4: -5.1275545858044875}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.12891407571835, 3: -5.477593720554204, 4: -5.566074673082084}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6050392654052485, 2: -4.596917467311529, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.068459444986559, 2: -4.0565002160581205, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4344731497043703, 2: -3.43141046577, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7097193062701894, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.899999997290099, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.14 -4.61 -4.07 -3.43 -2.71 \n",
      "-4.63 -4.06 -3.43 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.136394556094174, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6050392654052485, 2: -4.645456921738231, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.080568271436991, 2: -4.056553860579, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4321062605490003, 2: -3.4331779116243903, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7097744310829, 2: -2.70938762829, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89996507, 2: -1.8999737918181903, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999998999999999, 2: -0.9999998999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.14 -4.64 -4.07 -3.43 -2.71 \n",
      "-4.63 -4.08 -3.43 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.143721260587669, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.646312553609516, 2: -4.645456921738231, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.646312553609516, 2: -4.645456921738231, 3: -4.800298739017636, 4: -4.642843474844758}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.646312553609516, 2: -4.645456921738231, 3: -4.800298739017636, 4: -5.12498756210873}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.068459444986559, 2: -4.085092498879512, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4378146049698, 2: -3.4331779116243903, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7093117387339003, 2: -2.7098954269781577, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899996426, 2: -1.8999737918181903, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.15 -4.65 -4.09 -3.43 -2.71 \n",
      "-4.63 -4.08 -3.44 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.146575260893427, 2: -5.175075340683021, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.651206558413637, 2: -4.626662693225049, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.080568271436991, 2: -4.08566145710259, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.4377055734699002, 2: -3.4368284207754902, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7097744310829, 2: -2.709910469529, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899998198108838, 2: -1.89998694, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -0.9999998999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.16 -4.65 -4.09 -3.43 -2.71 \n",
      "-4.65 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.06 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.162254307601632, 2: -5.175075340683021, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.651206558413637, 2: -4.667926569186468, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0625493154511405, 2: -4.0843634607855, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.431734192202949, 2: -3.4344766458918, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7096913383869703, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.899999997297462, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.18 -4.65 -4.09 -3.43 -2.71 \n",
      "-4.66 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.08 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.18370274307521, 2: -5.175075340683021, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.646312553609516, 2: -4.6599978426129365, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0918878479718455, 2: -4.08566145710259, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4378146049698, 2: -3.4378602995368985, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.70996686450829, 2: -2.709910469529, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899996426, 2: -1.899997379181818, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999, 2: -0.99999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.18 -4.66 -4.09 -3.43 -2.71 \n",
      "-4.66 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.08 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.18370274307521, 2: -5.18102070249201, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6740170356140505, 2: -4.6599978426129365, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.087720052914412, 2: -4.085092498879512, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4344731497043703, 2: -3.4380136846558536, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709909945246124, 2: -2.7098954269781577, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999997290018, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.18 -4.67 -4.09 -3.44 -2.71 \n",
      "-4.66 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.08 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.18370274307521, 2: -5.192700322765679, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.655785601356787, 2: -4.667926569186468, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.085959627229504, 2: -4.0843634607855, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.4377055734699002, 2: -3.438600131254698, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709950636508507, 2: -2.709834630021244, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899998198108838, 2: -1.899998613, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999999999999999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.19 -4.67 -4.09 -3.44 -2.71 \n",
      "-4.67 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.189556611406519, 2: -5.192700322765679, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.673912963371934, 2: -4.667926569186468, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0918878479718455, 2: -4.093195975735797, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.4387366076641976, 2: -3.438600131254698, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.70996686450829, 2: -2.7099881520129, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999998198108838, 2: -1.899998613, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -0.99999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.19 -4.67 -4.09 -3.44 -2.71 \n",
      "-4.67 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.199976182181691, 2: -5.192700322765679, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6740170356140505, 2: -4.674924708353698, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0944548911134895, 2: -4.093195975735797, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4388089408154703, 2: -3.4378602995368985, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709909945246124, 2: -2.7099895424783074, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999996345, 2: -1.899997379181818, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.20 -4.67 -4.09 -3.44 -2.71 \n",
      "-4.67 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.43 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.199976182181691, 2: -5.2052238311239485, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.673912963371934, 2: -4.681221813775842, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.085959627229504, 2: -4.092977860589169, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438023403313741, 2: -3.4344766458918, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709950636508507, 2: -2.7099820034702833, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999997297454, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.67 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.205867118549436, 2: -5.2052238311239485, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.682890443907401, 2: -4.674924708353698, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.087720052914412, 2: -4.090432501148491, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4388089408154703, 2: -3.4388130856030505, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099955629808288, 2: -2.7099881520129, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999996345, 2: -1.8999997379181817, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999, 2: -0.999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.205867118549436, 2: -5.207211396878891, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6770185943930915, 2: -4.681221813775842, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.090522045895309, 2: -4.092977860589169, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438023403313741, 2: -3.438507680161071, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7099691316496415, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999729744, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.208971773313348, 2: -5.207211396878891, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.682890443907401, 2: -4.678545713696044, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094207247351972, 2: -4.090432501148491, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4384626108227447, 2: -3.4380136846558536, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709971928431999, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999999729, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.208971773313348, 2: -5.210343167781685, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68102471661451, 2: -4.681221813775842, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.093851161273661, 2: -4.092977860589169, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.4387366076641976, 2: -3.4389331733771846, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099950634319447, 2: -2.7099820034702833, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999998198108838, 2: -1.8999998532, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.212527197789088, 2: -5.210343167781685, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.682890443907401, 2: -4.681104897299883, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094207247351972, 2: -4.093834334686091, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4384626108227447, 2: -3.4388786304955046, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709988871661885, 2: -2.7099895424783074, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999626400002, 2: -1.8999997379181817, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 4\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.212527197789088, 2: -5.212729283591074, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6834145387386785, 2: -4.681221813775842, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0944548911134895, 2: -4.093986440198467, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438971297211996, 2: -3.4388130856030505, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709998674879916, 2: -2.7099895424783074, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999999972899, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.213042388937341, 2: -5.212729283591074, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.682890443907401, 2: -4.684116300825721, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0944548911134895, 2: -4.094837243358318, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438959083577349, 2: -3.4389331733771846, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099955629808288, 2: -2.70999851914629, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999819810882, 2: -1.8999998532, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -0.999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.213042388937341, 2: -5.214414187924102, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6834145387386785, 2: -4.684251197938343, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.093851161273661, 2: -4.094674438266917, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438877336967584, 2: -3.438507680161071, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099950634319447, 2: -2.7099980543938442, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999972974, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.214870015272064, 2: -5.214414187924102, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.684797506192667, 2: -4.684116300825721, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094207247351972, 2: -4.094538148235031, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438971297211996, 2: -3.438972837967734, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099994373900826, 2: -2.70999851914629, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999626400002, 2: -1.899999973791818, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999, 2: -0.9999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.214870015272064, 2: -5.215575622461245, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6843608945055335, 2: -4.684251197938343, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.094981359546869, 2: -4.094837243358318, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438995930229695, 2: -3.438972837967734, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709998674879916, 2: -2.7099989542456355, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999961829999, 2: -1.899999973791818, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.215730471857264, 2: -5.215575622461245, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.684797506192667, 2: -4.684719500437669, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094987475476914, 2: -4.094538148235031, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389372471284014, 2: -3.4388786304955046, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709997192821249, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.899999999999729, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.215730471857264, 2: -5.216180357600637, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6843608945055335, 2: -4.685243286914072, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.094576337057834, 2: -4.094674438266917, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438877336967584, 2: -3.4389467693959825, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7099969131430734, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999997297, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.215905371735209, 2: -5.216180357600637, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6850429224673995, 2: -4.685243286914072, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.094948276649526, 2: -4.094674438266917, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438959083577349, 2: -3.4389897233521896, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099995063410054, 2: -2.7099980543938442, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999819810882, 2: -1.89999998451, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.09 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216475304372114, 2: -5.216180357600637, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.684797506192667, 2: -4.685047850114143, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.094981359546869, 2: -4.095051723089696, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438994332416749, 2: -3.4389897233521896, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099994373900826, 2: -2.7099998216530294, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999981981088, 2: -1.89999998451, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -0.9999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216475304372114, 2: -5.2163040157761245, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685414651852231, 2: -4.685047850114143, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094987475476914, 2: -4.094945505524862, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389372471284014, 2: -3.4389855892347625, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999846259364, 2: -2.7099989542456355, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999999999728, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.09 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216475304372114, 2: -5.216519160170068, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685190587242943, 2: -4.685243286914072, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.094948276649526, 2: -4.095024301524345, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438985233342648, 2: -3.4389467693959825, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099995063410054, 2: -2.7099997908440656, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999728, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216651906103995, 2: -5.216519160170068, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685414651852231, 2: -4.685410644486553, 3: -4.800298739017636, 4: -5.175318862818839}, Best action: 2, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -5.216651906103995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68542716281041, 2: -4.685243286914072, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.09507981186996, 2: -4.095051723089696, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438995930229695, 2: -3.4389962104495058, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999931192108, 2: -2.7099998216530294, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999961829999, 2: -1.8999999973791817, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999, 2: -0.99999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216712253010798, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68542716281041, 2: -4.6855162243940605, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095041710875699, 2: -4.095024301524345, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438994332416749, 2: -3.438998516621186, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999506340784, 2: -2.7099997908440656, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999981981088, 2: -1.89999999837, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216867227177512, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68551240051576, 2: -4.6855162243940605, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095041710875699, 2: -4.0950878394100005, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.438985233342648, 2: -3.4389942770758126, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7099996913140885, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7099996913140885, 3: -3.4025766930000003, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999972, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216951767135518, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685535025860892, 2: -4.6855162243940605, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.09507981186996, 2: -4.095091875795022, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999263825368, 2: -3.438998516621186, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999931192108, 2: -2.7099999790735327, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999998198107, 2: -1.89999999837, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -0.99999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216963318472741, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685535025860892, 2: -4.685566270054073, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095082210095114, 2: -4.0950878394100005, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389942770758126, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999506340784, 2: -2.7099999776248747, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.8999999999999997, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.216979702794596, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685570092763132, 2: -4.685566270054073, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095096779650157, 2: -4.095091875795022, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438999448561923, 2: -3.4389962104495058, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999846259364, 2: -2.7099998954245414, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999996102, 2: -1.8999999973791817, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217006649023259, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685570092763132, 2: -4.685581046399376, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095093585440919, 2: -4.0950878394100005, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999263825368, 2: -3.4389997959277263, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999995063408, 2: -2.7099999776248747, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999998198107, 2: -1.8999999998288999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217012440040463, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685578159198414, 2: -4.685581046399376, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095093585440919, 2: -4.0950981876395485, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.438999387721185, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999995063408, 2: -2.709999997616534, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217019552954762, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685583620126986, 2: -4.685581046399376, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095096779650157, 2: -4.095096118043602, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438999448561923, 2: -3.4389994965150352, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999991798911, 2: -2.7099999790735327, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999996102, 2: -1.899999999737918, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999, 2: -0.999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217022602878971, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685583620126986, 2: -4.685585960255255, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095098862598252, 2: -4.0950981876395485, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999908258685, 2: -3.4389997959277263, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999991798911, 2: -2.7099999975916154, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999981981, 2: -1.8999999998288999, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -0.999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217024992590755, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685587894000733, 2: -4.685585960255255, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095096779650157, 2: -4.095099165139517, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999908258685, 2: -3.4389999729498903, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999995063406, 2: -2.709999997616534, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999981981, 2: -1.8999999999820802, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217027127065832, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685587894000733, 2: -4.685586987542153, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950996036545515, 2: -4.095099165139517, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438999927905754, 2: -3.4389994965150352, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999982503074, 2: -2.7099998954245414, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999999999972, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217028172615727, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685587894000733, 2: -4.685589022517225, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095098862598252, 2: -4.095099653465413, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.438999934773479, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999995063406, 2: -2.709999999747058, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.2170290114021665, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685588868104657, 2: -4.685589022517225, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099833426343, 2: -4.095099653465413, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999988895261, 2: -3.4389999729498903, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999990413, 2: -2.7099999975916154, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999602102, 2: -1.899999999737918, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.2170298843049885, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558960611745, 2: -4.685589022517225, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950996036545515, 2: -4.09509950869113, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438999927905754, 2: -3.4389998649453823, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999982503074, 2: -2.709999989542452, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999602102, 2: -1.8999999999737918, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999, 2: -0.9999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030096669451, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558960611745, 2: -4.685589504291538, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950996036545515, 2: -4.095099841474872, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999988895261, 2: -3.4389999953441976, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999950634, 2: -2.709999999747058, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999998198, 2: -1.8999999999820802, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -0.9999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.2170305081430906, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558960611745, 2: -4.685589629389341, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099833426343, 2: -4.095099943435953, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999930774837, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999950634, 2: -2.709999999960191, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030631769443, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855898256870825, 2: -4.685589629389341, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099951370617, 2: -4.095099841474872, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.438999927905754, 2: -3.438999972322028, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999990413, 2: -2.7099999995468753, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999998198, 2: -1.899999999998127, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99999999999999, 2: -0.99999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030662982311, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855898256870825, 2: -4.685589834533581, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099977735396, 2: -4.095099943435953, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.320078783129, 1: -3.438999998684643, 2: -3.4389999953441976, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099951370617, 2: -4.095099925751148, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999920140286, 2: -3.438999972322028, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999998218078, 2: -2.709999989542452, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.8999999999999997, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030825104768, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589936751829, 2: -4.685589834533581, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099951370617, 2: -4.095099970155958, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.438999998684643, 2: -3.4389999953441976, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999902613, 2: -2.7099999995468753, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89999999999594, 2: -1.8999999999737918, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030848482678, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.373450537952745, 1: -5.217030848482678, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589936751829, 2: -4.685589944063558, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099977735396, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.438999999267762, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999950635, 2: -2.709999999960191, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999998198, 2: -1.8999999999998045, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703093361725, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589975640854, 2: -4.685589944063558, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099991365862, 2: -4.095099970155958, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999920140286, 2: -3.4389999887615885, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999998218078, 2: -2.7099999989542454, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.89999999999594, 2: -1.8999999999973791, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -0.99999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030948053208, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589975640854, 2: -4.685589970232681, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099991365862, 2: -4.095099987912483, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999920140286, 2: -3.438999997432802, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999902613, 2: -2.709999999933459, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999999998196, 2: -1.8999999999998045, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999999999999999, 2: -0.999999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030970693792, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589975640854, 2: -4.68558998723238, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099997180427, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999998945306, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999950635, 2: -2.7099999999945594, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999999998196, 2: -1.8999999999999795, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030977338471, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589995280232, 2: -4.68558998723238, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099991365862, 2: -4.095099992322612, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.438999998684643, 2: -3.438999999167389, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999950635, 2: -2.70999999999931, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030987392074, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589995280232, 2: -4.685589991729586, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099998071147, 2: -4.095099992322612, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999991225197, 2: -3.438999997432802, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999998185194, 2: -2.7099999989542454, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030992040172, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589995280232, 2: -4.685589992954274, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099998071147, 2: -4.095099997152831, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999991225197, 2: -3.438999998896219, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999998185194, 2: -2.7099999998954245, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899999999999586, 2: -1.8999999999973791, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030993496978, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589995280232, 2: -4.68558999698922, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0950999996326125, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999999850462, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999999506, 2: -2.70999999999931, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999999982, 2: -1.8999999999999795, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -0.999999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030995526686, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558999923044, 2: -4.68558999698922, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099998071147, 2: -4.095099998821221, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.438999999864466, 2: -3.438999999167389, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999990103, 2: -2.709999999933459, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.899999999999586, 2: -1.899999999999738, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999999999999999, 2: -0.9999999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309971139375, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558999923044, 2: -4.6855899981365505, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999991327, 2: -4.095099998821221, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.4389999991225197, 2: -3.438999999742623, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999990103, 2: -2.7099999999930104, 3: -3.0759939000000003, 4: -3.3272301690000003}, Best action: 1, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.438999999864466, 2: -3.438999999862841, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999990103, 2: -2.7099999999930104, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.899999999999982, 2: -1.899999999999997, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030998202, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558999923044, 2: -4.685589998858844, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999991327, 2: -4.095099999171363, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.438999999864466, 2: -3.4389999999782677, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999999506, 2: -2.7099999999999143, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030998895864, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558999923044, 2: -4.685589999183373, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999803487, 2: -4.095099999171363, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999742623, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999797286, 2: -2.7099999998954245, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999228118, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68558999923044, 2: -4.685589999247141, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999951149, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999999979457, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999999507, 2: -2.7099999999999143, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999999999981, 2: -1.899999999999997, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -0.9999999999999999, 3: -2.3896800000000002, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999299468, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999883475, 2: -4.685589999247141, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999803487, 2: -4.095099999708661, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999889556, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999797286, 2: -2.7099999999895426, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999586, 2: -1.899999999999738, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999320131, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999883475, 2: -4.685589999688729, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999803487, 2: -4.095099999881407, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999860468, 2: -3.4389999999782677, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999998996, 2: -2.7099999999930104, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999586, 2: -1.8999999999999737, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999679884, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999883475, 2: -4.6855899998096975, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999962746, 2: -4.095099999881407, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999972536, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999977604, 2: -2.7099999999895426, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309998138436, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999883475, 2: -4.68558999988491, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999993451, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.438999999999725, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999999507, 2: -2.709999999999989, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999886999, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999983042, 2: -4.68558999988491, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999962746, 2: -4.095099999965895, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999860468, 2: -3.4389999999921654, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999999995, 2: -2.709999999999989, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999999999981, 2: -1.8999999999999997, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999895477, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999983042, 2: -4.685589999958315, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999984972, 2: -4.095099999965895, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.4389999999887833, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999977604, 2: -2.709999999998954, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999957, 2: -1.8999999999999737, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999557825, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999983042, 2: -4.685589999968206, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999984972, 2: -4.095099999987505, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999985954, 2: -3.4389999999921654, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999998996, 2: -2.709999999999267, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8999999999999997, 2: -1.8999999999999997, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999698254, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999983042, 2: -4.685589999984648, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999999123, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999999999326, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.709999999999995, 2: -2.7099999999999973, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999983247, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999997594, 2: -4.685589999984648, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999992152, 2: -4.095099999987505, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999997064, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999999999755, 2: -2.709999999998954, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703099998589, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999997594, 2: -4.685589999988344, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999992152, 2: -4.095099999996372, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999985954, 2: -3.438999999998403, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999999998996, 2: -2.709999999999267, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999957, 2: -1.8999999999999972, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999989147, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999997594, 2: -4.6855899999924775, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999997922, 2: -4.095099999996372, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999998859, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999999999755, 2: -2.709999999999895, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999995, 2: -1.8999999999999972, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999992821, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999997594, 2: -4.685589999996309, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999997922, 2: -4.095099999998713, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999985954, 2: -3.438999999999247, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999999995, 2: -2.7099999999999973, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.8999999999999997, 3: -3.0878037000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999996293, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999997594, 2: -4.685589999997948, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999999858, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999999999894, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.7099999999999995, 2: -2.7099999999999995, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999976805, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.685589999997948, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999998654, 2: -4.095099999998713, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999998575, 2: -3.438999999999247, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999999998996, 2: -2.7099999999999236, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999998106, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.685589999998704, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999255, 2: -4.095099999998713, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.4389999999996874, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999999999973, 2: -2.709999999999895, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999987605, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.685589999998828, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999255, 2: -4.0950999999996185, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999998575, 2: -3.4389999999998437, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999999999898, 2: -2.7099999999999236, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8999999999999995, 2: -1.8999999999999997, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999998927, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.68558999999928, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999999998, 2: -4.0950999999996185, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999999884, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.709999999999973, 2: -2.7099999999999893, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.8999999999999997, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999309, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.685589999999619, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999999998, 2: -4.095099999999868, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999998575, 2: -3.4389999999999223, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.7099999999999995, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999623, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999644, 2: -4.6855899999998, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999999977, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4389999999999987, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999996745, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999946, 2: -4.6855899999998, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999999998645, 2: -4.095099999999868, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999854, 2: -3.4389999999999223, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.7099999999999898, 2: -2.709999999999992, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999806, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999946, 2: -4.685589999999871, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999924, 2: -4.095099999999868, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.4389999999999663, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999999973, 2: -2.7099999999999893, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999876, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999946, 2: -4.6855899999998805, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999924, 2: -4.0950999999999596, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999854, 2: -3.438999999999984, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999999999, 2: -2.709999999999992, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999891, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999946, 2: -4.685589999999927, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.09509999999998, 2: -4.0950999999999596, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999999988, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999999973, 2: -2.709999999999999, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999929, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999946, 2: -4.68558999999996, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.095099999999997, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999949, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999992, 2: -4.68558999999996, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.09509999999998, 2: -4.095099999999987, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999854, 2: -3.438999999999992, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999963, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999992, 2: -4.68558999999998, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999986, 2: -4.095099999999987, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999987, 2: -3.438999999999992, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.709999999999999, 2: -2.709999999999999, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703099999998, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999992, 2: -4.685589999999986, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999992, 2: -4.095099999999987, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999999997, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999999995, 2: -2.709999999999999, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999987, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999992, 2: -4.685589999999989, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999992, 2: -4.095099999999996, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999987, 2: -3.4389999999999983, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.71, 2: -2.709999999999999, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703099999999, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685589999999992, 2: -4.685589999999992, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.46 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999993, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855899999999995, 2: -4.685589999999992, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999998, 2: -4.095099999999996, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.438999999999999, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.7099999999999995, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.46 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999993, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855899999999995, 2: -4.685589999999996, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999998, 2: -4.0950999999999995, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.4389999999999987, 2: -3.438999999999999, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -2.71, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.69814618, 2: -2.4823900000000005, 3: -2.664207, 4: -3.1425039000000003}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999997, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855899999999995, 2: -4.685589999999998, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.095099999999999, 2: -4.0950999999999995, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.438999999999999, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217030999999998, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855899999999995, 2: -4.6855899999999995, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999999995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.6855899999999995, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0950999999999995, 2: -4.0950999999999995, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999999995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.6855899999999995, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0950999999999995, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.4389999999999996, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999999995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.6855899999999995, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0950999999999995, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999999995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.6855899999999995, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170309999999995, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.0951, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -3.9925399241790003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.28 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.282536085758, 1: -4.54346733858499, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.40 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.40 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.439, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.30450957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.40 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20294529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.40 -3.81 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.0951, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.8382856849, 3: -3.8066360949, 4: -4.001309881659001}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.54346733858499, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.54346733858499, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.4026103491379995}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.54346733858499, 2: -4.808773808678086, 3: -4.54257442697967, 4: -4.90637541771558}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.54346733858499, 2: -4.808773808678086, 3: -4.54257442697967, 4: -5.070122827625091}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.54346733858499, 2: -4.808773808678086, 3: -5.0337427285515, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.439, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.250989639, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438992877651805, 2: -3.4389855892347625, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7099997192819054, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.72 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7168891650000004, 1: -3.7354550589122524, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.094987475476914, 2: -4.095033720726492, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.7354550589122524, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.29 -3.47 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.32019022365, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.32019022365, 3: -4.466513022766381, 4: -4.294976640399}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.32019022365, 3: -4.466513022766381, 4: -4.808428742763089}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4686455058912253, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.84 -4.14 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.837413229463981, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.1399367338585, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.31 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.14 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.309893894621292, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685414651852231, 2: -4.685410644486553, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095033720726492, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438992877651805, 2: -3.4389983315418196, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.14 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.226172011496237, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685414651852231, 2: -4.685518378237114, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.141621882136893, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4419645505891228, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.21780306914993, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685518378237114, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095087602970611, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389992877651805, 2: -3.4389983315418196, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7099999719281906, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217050193287055, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855727962299065, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095097408845934, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389992877651805, 2: -3.4389998104160164, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.21701898427493, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855861807881976, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099163974389, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999287765183, 2: -3.4389998104160164, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709999997192819, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217026704865933, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685588940898075, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099762834412, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999287765183, 2: -3.438999978767785, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217029712614035, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855897019856805, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099918592422, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999992877652, 2: -3.438999978767785, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709999999719282, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.2170306298698055, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589904258429, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0950999746611485, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999992877652, 2: -3.438999997649397, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.2170308854363086, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589969901373, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099991697014, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999992877653, 2: -3.438999997649397, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709999999971928, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030964163743, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855899902647185, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099997265713, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999992877653, 2: -3.4389999997422014, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030988530796, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589996811699, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999149661, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999287766, 2: -3.4389999997422014, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709999999997193, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030996270556, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589998992396, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999706149, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999287766, 2: -3.4389999999719465, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.2170309988108965, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999661221, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999912923, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999928778, 2: -3.4389999999719465, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7099999999997193, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999606679, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999606679, 3: -5.477593720554204, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68558999989559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999968569, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999928778, 2: -3.4389999999969674, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999876096, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999964099, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0950999999910875, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999992877, 2: -3.4389999999969674, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.709999999999972, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.21703099995853, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999989191, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999996652, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.4389999999992877, 2: -3.438999999999674, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999987098, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999996207, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999999088, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999929, 2: -3.438999999999674, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7099999999999973, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999995638, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999998882, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999999645, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999929, 2: -3.4389999999999654, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999998658, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999999601, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999999907, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999993, 2: -3.4389999999999654, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7099999999999995, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999999542, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999999884, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999999962, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999993, 2: -3.438999999999996, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.21703099999986, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999999958, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.09509999999999, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999999, 2: -3.438999999999996, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.2170309999999525, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999999987, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095099999999996, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.438999999999999, 2: -3.4389999999999996, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999999985, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.685589999999995, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0950999999999995, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.4389999999999996, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999999995, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855899999999995, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0950999999999995, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217030999999999, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.6855899999999995, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.2170309999999995, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 3\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.611027868640072}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -3.439, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -3.7711660896, 4: -3.3193350990000003}, Best action: 1, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4392964550589125, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.217031, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.605517917846, 4: -5.175318862818839}, Best action: 2, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.663140041066244, 1: -5.340007815865825, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.737090077371783, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.09958367338585, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.271043744257726, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.694371783179717, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095548367338585, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.229545518801344, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.686831355862226, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.0951448367338585, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.219287950128537, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685750453340648, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095104483673386, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217386662218779, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6856096771095075, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100448367339, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170825046805795, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685592330888496, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100044836734, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703803848774, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590269406604, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100004483673, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031922068124, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855900305724365, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000448368, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031116970486, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590003420422, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000044837, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.21703101446759, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000378361, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000004484, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031001753231, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000041468, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000000449, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.2170310002089115, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855900000045105, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000000045, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031000024544, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000487, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.123581508575801, 1: -4.095100000000005, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.518660021946448, 2: -4.84749007872319, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.102153474190879, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439029645505891, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.71 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.217031000002849, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.518660021946448, 2: -4.707493321966932, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000005, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.66 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.71 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.663140041066244, 1: -5.891817717776908, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.663140041066244, 1: -5.891817717776908, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.053457437370282, 1: -5.891817717776908, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -5.891817717776908, 2: -5.96217261345526, 3: -5.67355448173683, 4: -5.686897896864008}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -5.891817717776908, 2: -5.96217261345526, 3: -6.062934578380515, 4: -5.686897896864008}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -5.891817717776908, 2: -5.96217261345526, 3: -6.112680754297898, 4: -5.686897896864008}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -5.891817717776908, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.075077086146248}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.707493321966932, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095829360278859, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439002964550589, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.30 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.302251362570906, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.688371114022569, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095175337313862, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000296455059, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.227805738615372, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685929134626486, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095107773859984, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000029645506, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2183831729089905, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.6856302102892355, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100801398859, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000029645504, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21719878762518, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685594670161999, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100082541172, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000296455, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217051561593737, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.6855905338745485, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100008494246, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000296457, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170334885977585, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590060267794, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100000873438, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000002965, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031297676689, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590006734264, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951000000897455, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000002967, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031035222423, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559000074612, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100000009214, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.43900000000003, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031004126599, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000082076, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100000000945, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000000003, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000479142, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000008973, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100000000097, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000000005, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000055182, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000000976, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.09510000000001, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000006308, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000000106, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100000000001, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000716, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000000012, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000081, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.685590000000001, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000009, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000001, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.9, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.3896800000000002, 4: -1.719}, Best action: 1, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.84 -3.17 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -3.1670749000000002, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.68559, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -4.466513022766381, 4: -4.880196955432809}, Best action: 2, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.768897002194649, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.693920700219465, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.223778867177766, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.686423070021947, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.218380573435554, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685673307002195, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217233436015333, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559833070022, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217057991468711, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590833070022, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217034373933589, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855900833070026, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170314048720305, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590008330701, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031047235071, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559000083307, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031005398294, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000083307, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000607308, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000008331, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000067479, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855900000008335, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000007423, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000084, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21703100000081, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000008, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310000000875, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000001, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21703100000001, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000001, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.155670503082531, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.60 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.597796207496851, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.255107520749686, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.220838652074969, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217411765207498, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21706907652075, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217034807652075, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031380765208, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031038076521, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031003807652, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000380766, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000038077, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000003808, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310000003814, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000039, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000004, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.48 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -2.71, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.0878037000000003, 4: -2.546109}, Best action: 1, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -3.6721209970000004, 3: -3.0759939000000003, 4: -3.380366979}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.1670749000000002, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -2.4823900000000005, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.10 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.73 -3.23 -1.90 -1.00 0.00 \n",
      "-2.71 -1.96 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.8092306690000006, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.8092306690000006, 3: -3.7307063250000008, 4: -4.0848439924179}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.8092306690000006, 3: -4.29494275575, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.227443390000001, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9582389999999998, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.33 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.90 -2.81 -1.90 -1.00 0.00 \n",
      "-2.71 -1.91 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.68559, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.331382123250001, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.8951522128000007, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.808917929, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9058239, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.88 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.49 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.56 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.876978519832501, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.488211504693001, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.5647387437700004, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7246091519, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9005823899999998, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.37 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.90 -4.10 -3.80 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.76 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.372055701064326, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.986434548440769, 3: -5.210894950308253, 4: -4.9025282814970375}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.986434548440769, 3: -5.210894950308253, 4: -5.361300736162304}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.8092306690000006, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.8092306690000006, 2: -3.87720160759, 3: -3.9008914281899996, 4: -3.8001822849}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.8092306690000006, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.358165879259}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.75570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.41 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.72 -4.39 -3.51 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.4082534781190335, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.715674454844077, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.387657650769, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.5130461338, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.714570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.93 -4.18 -3.45 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.260521656235605, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.925570142607298, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.1843331334549, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.45010692007, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7104570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.42 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.11 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.415763981135472, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.781866852359199, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.11301991860219, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.440480922676, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71004570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.31 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.71 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.3148885485244985, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.709732819303694, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.098091539227779, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4391851153345, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710004570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.25 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.246372438488442, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.69042742870487, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095549097343723, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.43902221384014, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100004570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.223883461099789, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.686437511718903, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095162902944886, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439002591614683, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71000004570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.218402730602291, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.6857257025572485, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095108389502381, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000296184535, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000004570749, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.71 -2.48 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2172780921316, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.6856103657526535, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095101078859711, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000333207604, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000000457075, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -2.4823900000000005, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.84 -3.18 -1.96 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21707220547281, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685592910451631, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.0951001348757865, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000003702307, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -3.181735900045708, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9582389999999998, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.82 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.80 -1.91 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217037478013102, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559040029455, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.095100016486447, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.821106079407254, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.8043471800045707, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9058239, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.39 -3.55 -2.71 -1.90 \n",
      "-4.24 -3.84 -2.72 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031972039895, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590053383478, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.392885236869, 2: -4.40460592596852, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.8382856849, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7241520770004573, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9005823899999998, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.93 -4.40 -3.55 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031140444607, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.926796047202237, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.40460592596852, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.553631823744428, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.711886943600046, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000582389999998, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.41 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.96 -4.22 -3.45 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.4124079122782724, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.960410404754725, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.218902369829839, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.45199160669048, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7102358679500043, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000058239, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.46 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.81 -4.12 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.459173219079155, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.813351960037642, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.118003438402273, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.440490213708552, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100283041540005, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.90000058239, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.34 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.72 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.3447324095384054, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.716917981109606, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.098597416944154, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4391719477355953, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100033021513, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.900000058239, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.255176805652622, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.691555705835725, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095589019360248, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390198695161125, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71000037738872, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000058239, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2256778022922, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.686582676265374, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095164996244076, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390022926364745, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100000424562314, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000005823898, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.218699748004173, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685741914584239, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095108356659953, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390002636531953, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000004717359, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000000582389, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217320925613651, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685611960352986, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095101049225084, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.43900003018638, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100000005189093, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000000058237, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217077780447284, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685593045907616, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100129373477, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000034389545, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000000056608, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000000005823, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217038145229898, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590409383278, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100015722901, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000389748, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100000000061324, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.900000000000058, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217032046123445, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590053673877, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100001887986, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000439422, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.7100000000006603, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000000000057, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031148088186, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590006896657, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000224392, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000004929, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000000000071, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9000000000000006, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031020395111, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000871423, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000026432, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000005507, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000000000008, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031002745364, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000108552, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951000000030895, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4390000000000613, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.710000000000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000362463, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000013359, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000359, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000000007, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000047067, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000001627, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000042, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000000000001, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000006024, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.6855900000001975, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000005, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310000007625, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000000024, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310000000955, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.685590000000003, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000012, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000001, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.00 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.70999919, 4: -0.9}, Best action: 1, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -1.90 -1.72 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -1.9, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -1.88928, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -2.4823900000000005, 3: -3.0878766000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -1.88928, 3: -3.089925900000001, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -1.88928, 3: -3.089925900000001, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.3850993439, 2: -2.6192448, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -2.71 -2.55 -1.14 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -2.71, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.0256408000000006, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 4, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.24 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.46 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -4.68559, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.209457874054304, 4: -4.880196955432809}, Best action: 2, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.023149170784581, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.236259532923, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4634072874160005, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71193265109, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000582389999998, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.83 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.13 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.833685138746088, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.12898585609926, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4430061761245003, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710240438699, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000058239, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.34 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.336988062384331, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.727847057315009, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.101733588270771, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.43959537295864, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100287612289002, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.90000058239, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.263254922663591, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.695188912230826, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.096245610923575, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390828338912733, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71000334785879, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000058239, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.229428511173328, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.687477836071179, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095281656544289, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390109951547476, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000381959469, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000058239, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.219799898334988, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685925925407992, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095127071729775, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439001408902645, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000042913306, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000005823898, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217579989413973, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685645520641917, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095103848384119, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390001756500426, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000047630664, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000582389, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21713087066135, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685598669255328, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100527114947, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000214230882, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71000000052348, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000058237, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170480091629505, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685591293888639, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100070064197, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000025663277, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000057065, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000005823, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170337489660925, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590186140863, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951000090851455, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000003028556, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000006178, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.900000000000058, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031425670708, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590025973053, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100001153828, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.43900000003529, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000006648, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000057, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031063605244, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590003531906, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000143968, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000040675, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000071, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9000000000000006, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031009221368, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000469805, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000017691, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000004646, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000008, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031001302679, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000061311, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000002145, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000053, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000001, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21703100017993, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000007869, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000257, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000000063, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.69814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -3.36 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000024367, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000995, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000031, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000000005, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.3564984058000005, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.96 -2.77 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000003243, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000000125, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000003, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.9626637086980008, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.77464984058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.52 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000425, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855900000000155, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.519267604045382, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.5437327417396, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7164649840579997, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.03 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.22 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.45 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000055, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.029165759276761, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.029165759276761, 2: -5.5882198779839864, 3: -5.210894950308253, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.222350281213615, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.45470991126094, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7106464984058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.64 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.82 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.12 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.64252800974969, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.823020303710703, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.120550056242723, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.441094654834792, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71006464984058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.37 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.72 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.370899246980639, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.7199475759276766, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.099341676040454, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439261831854349, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710006464984058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.260247461199482, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.692461515185536, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095736251406068, 2: -4.808773808678086, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4903917508603706, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -3.26922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.26 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.226918573420233, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.264352936547803, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095736251406068, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390314198225216, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000646498406, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.69 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.686817735945744, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.743981657293696, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095189075196849, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439003665645961, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000646498406, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "-5.31 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.311306916002468, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.691501316638818, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095111876692913, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000418930967, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000006464984, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.23124675807769, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.686190751785141, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095101527003374, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000047129734, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000006464984, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.218939184753733, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685651312051247, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100190875422, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000005236637, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000646496, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2172714812368834, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685596285814216, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100023329218, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.43900000057603, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000006465, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217060139633204, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.6855906474780875, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100002799506, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000628396, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000006466, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217034438420571, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590067015409, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000330851, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000068075, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000065, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031398124538, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590006969531, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951000000386, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000007332, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000000066, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031045457775, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -4.685590000728219, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000004454, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000004454, 2: -4.208094699064708, 3: -5.083582817108992, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000000787, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000001, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.40 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031005135635, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.402092367178107, 1: -5.486261081931105, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -5.79739791792783, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -5.486261081931105, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -5.486261081931105, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.475142057853254}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -5.486261081931105, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.882379272646461}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000509, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000009, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.91 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.77 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.914604858653918, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.7656571081935235, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000057, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000001, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.35 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.351642743502145, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.693596710819398, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000006, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.236977610113927, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.686390671081944, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000001, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2196742045877675, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.6856700671081954, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217360174816415, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.68559800671082, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217070402917406, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590800671083, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170355888353175, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590080067109, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21703152373789, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590008006711, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.725389281714507, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.20 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310588592255, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -5.196124318989421, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.63 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.630563804267354, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.736643431898942, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.30 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.299737560264879, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.690695343189894, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.229436984010302, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.68610053431899, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.218685131199412, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685641053431899, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21723776639978, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.68559510534319, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217055811967962, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590510534319, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217033894729595, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590051053432, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.21703133082624, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590005105343, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031037217953, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000510535, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031004135329, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000051054, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000454886, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000005106, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000049624, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000000511, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000005377, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000000051, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000579, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000000006, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.217031000000063, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.685590000000001, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.14 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -5.2170310000000075, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.136101550239354, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -5.96217261345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.785958122635918, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.13850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.29 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -2.01 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.01 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -5.291545161345526, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.785958122635918, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.71, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -2.0121930468559004, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.013850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.80 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.92 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -5.224482416134553, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.785958122635918, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.8008763679532795, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9224386093711803, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0013850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.51 -2.74 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -5.217776141613456, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.785958122635918, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.0951, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.5126098580421563, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.737262910385984, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9033657914056772, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00013850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.47 -2.72 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -5.217105514161346, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -5.785958122635918, 4: -5.175318862818839}, Best action: 2, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -6.108336630751229, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10092487394386, 1: -6.391945355693878, 2: -6.108336630751229, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.451841635288913, 1: -6.391945355693878, 2: -6.108336630751229, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.68559, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.154723985014146, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.4684439432168626, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7154525820771966, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9004487721874237, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000013850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.31 -4.72 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.77 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.306161563075123, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.723255189716107, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.765922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.48 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.72 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.256452859977559, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.689356518971611, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.48429760327, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.7155922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.13 -3.45 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.224024066364761, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685966651897162, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.1317910586487, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.448059520654, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71055922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.11 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.218035394673176, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.715347422695163, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.106107317594611, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.4403589280981, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.710055922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.70 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.2412349518504, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.697481669521151, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.097301463518922, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.43918119041308, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.7100055922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.2290836474971725, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.688562352402442, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095466910586486, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439022648801635, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.71000055922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.220643870195695, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.686184432815297, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095155036587974, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439002717856196, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.710000055922967, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -2.01 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.21787377759996, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685694022917788, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095107705122317, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -3.439000317083223, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.005884529, 1: -2.710000005592297, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.87720160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.0125640799999998, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.48 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217199536323404, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685606643440856, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095101027349642, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.482820160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000560965234279, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000013850993439, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.13 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217061334819434, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6855924964972955, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.130594432949755, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4433820160759, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100454381839767, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000067315828113, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000001385099344, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.71 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217036055644753, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.714340740339031, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.1021988763164545, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439475006536611, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100099964004745, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000007853513279, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000138509935, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.24031960523909, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.694215163850232, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.096194642926301, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390555977380455, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.710001635774623, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000897544373, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000013850994, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.226346243242597, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6873391771553266, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095254498460447, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439006884751249, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100002362785567, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000100973742, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000001385099, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.219379357820075, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685890061468494, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095121026494556, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439000879860756, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000318067288, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000011219305, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000000013851, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217508885571488, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68563703760744, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095102815336667, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439000113749526, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000040894363, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000001234123, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000013851, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.2171168890191755, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685596984183444, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100373670783, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000146873962, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000005089075, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000000134631, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000001386, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217045246090508, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685591001091678, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.09510004926387, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000018809546, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.710000000061796, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000000014585, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000138, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.21703323549331, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590140012902, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100006449961, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000002381504, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.710000000007361, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.900000000000157, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000013, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031336959782, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590019225758, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000837898, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000000297776, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000000008633, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000000000168, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000002, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031049268843, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590002601273, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951000001079105, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439000000003677, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000000001, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.900000000000002, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031007033916, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000347536, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.09510000001377, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000000004486, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000000000115, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9000000000000001, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000984895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000045908, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.09510000000174, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000000000542, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.7100000000000013, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000135675, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000006, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000217, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390000000000067, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000018428, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000000776, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000027, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439000000000001, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000002471, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.6855900000001, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.095100000000003, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000000328, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000000013, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000000044, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.685590000000001, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000000006, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031000000001, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.12 -3.45 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -4.68559, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.790480941117125, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.733885427861459, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.124911992507073, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.4463609858042155, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.710908763679533, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.71 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.714567256716875, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.1040435977521215, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.440472197160843, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7100908763679534, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.70 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.240502577940669, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.695732039850906, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.097186839475495, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.4392208295741264, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7100090876367955, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.227593210073301, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.688294543960241, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095487555902592, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439029443943217, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7100009087636794, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.73 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.220277901615125, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.686174374677123, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095162605184265, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439003680492902, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.7100000908763677, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -1.9, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -2.38 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.07 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217829033649982, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685699147666967, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095109241717678, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.439000441659148, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.710000009087637, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3823900000000005, 1: -2.49049, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.100735900908764, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -2.49049, 2: -2.4724800000000005, 3: -2.46429, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -2.49049, 2: -2.4724800000000005, 3: -3.341529, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -2.49049, 2: -2.4724800000000005, 3: -3.341529, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -2.49049, 2: -3.1499568000000004, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -3.16 \n",
      "-4.69 -4.10 -3.44 -2.80 -2.02 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.01 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217199212975242, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685608400558015, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095101281915678, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.4390000515269006, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2061484900908765, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2061484900908765, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2061484900908765, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -2.0180979999999997, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.80 -2.86 \n",
      "-4.69 -4.10 -3.44 -2.80 -1.92 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217062725749517, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685592878407501, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.095100169928357, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.8067156160526907, 3: -3.8158984773, 4: -4.036815325836}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7972775358900006, 1: -4.298544532576, 2: -3.8067156160526907, 3: -3.8158984773, 4: -4.036815325836}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3555225576599, 1: -4.298544532576, 2: -3.8067156160526907, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.8552742290090873, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9177146999999999, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.34 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.44 -2.80 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.91 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217036504085027, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.68559042548272, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.335217345266615, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.8011769047999997, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9112564079999999, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.88 -4.12 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.51 -2.73 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.217031895049506, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.88008509221423, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.119111734526662, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.512853292888, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7282353809599997, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9011256408, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.37 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -6.391945355693878, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.33 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.334522435569388, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.228780143556939, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2182059143556945, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2171484914355695, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217042749143557, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170321749143564, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031117491436, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031011749144, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031001174915, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000117492, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000011749, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310000011755, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000118, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000012, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000001, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -2.664207, 4: -3.1425039000000003}, Best action: 2, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.85455068919, 1: -3.22360938, 2: -2.7099999691314065, 3: -3.435357419264412, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.44 -3.33 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.32900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.10 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.94 -2.77 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.9403962127000005, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.771900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.69 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.21 -3.90 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.208094699064708, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.897115207786037, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.710000005592297, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.48 -3.48 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.777115706242414, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.477472788213161, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4848115253083645, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.7100000005592295, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.29 -4.72 -4.16 -3.59 -2.74 \n",
      "-5.00 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.17 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.291166822056356, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.004464529076902, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.170444614321092, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4435811529838127, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.710000000055923, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.37 -4.72 -4.16 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.46 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.374572114198477, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.72448901418802, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.157322340691946, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4611559878663996, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.712735307144, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9001125640799998, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.74 -4.12 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.264293312912144, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.739879997379279, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.119268584240978, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.44343119757328, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7103647076192, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000112564079998, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.71 -4.10 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.2657321291684305, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.710595552973119, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.101106128458454, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4397385329288803, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100455884524, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000011256407998, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.24215561082507, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.6929555193486605, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.096298824518239, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.439110779939332, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100054706142878, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.90000011256408, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.59 -2.74 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.2255095317549225, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.68729759979464, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -4.095309614202683, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.588628771636301, 1: -4.488666500198322, 2: -3.4390155091915067, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.385304821063736, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.59344368710263, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7388763299009087, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90236196, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.25 -3.48 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.21926200900915, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685930547483637, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.249219868659504, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.477834195929999, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.714800820590091, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.900295245, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.81 -4.14 -3.45 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.217529944362662, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.810461148362562, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.1419676855692495, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.4467720842709735, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.710719230509009, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000354294000001, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.32 -4.74 -4.11 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.318226524609941, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.736039940147349, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.106082156816414, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.4403597851393948, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7101006208649014, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90000413343, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.70 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.268015003980347, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.69953054103603, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.097299641644551, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.43921748141451, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.71001341016479, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.900000472392, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.233421238637219, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.68876576383569, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.095496124110207, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.439032610374931, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.710001723653999, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000531441001, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.22124239257063, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.686228436912836, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.095166026814715, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.4390046571972324, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7100002154121214, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000059049, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.21796927315646, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685707325411203, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.095110375011229, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.4390006402035413, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7100000263241815, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.900000000649539, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.21721986089872, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685610136300216, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.095101556065991, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -4.298544532576, 2: -3.439000085342941, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100006382383337, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000011256408, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.53 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.217066196493047, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -4.685593274043475, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.791331226993159, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53319129825389, 1: -5.026320266445672, 2: -4.791331226993159, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.025204081411039, 1: -5.026320266445672, 2: -4.791331226993159, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.791331226993159, 3: -4.746955852347301, 4: -4.599600161677291}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.791331226993159, 3: -4.746955852347301, 4: -5.085636147126334}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -5.040444278989998, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.791331226993159, 3: -5.457455451216629, 4: -5.253597855113948}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -3.5249549702306506, 2: -3.439000085342941, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.710000003158545, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000708588, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -5.12 -4.16 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.217037171624519, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.115409856230177, 1: -5.248848562304871, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.555022969169461, 1: -5.248848562304871, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.248848562304871, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.175318862818839}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.248848562304871, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.609540165165145}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390155091915067, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.710000072941524, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000011256408, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.48 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.78 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.482732950757926, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.778506590507774, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.106345195348998, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4394581153436787, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.7100000000055924, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.32 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.31886363338709, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.703990267283466, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.09659559296328, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439045811538898, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.710000000000559, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.242118479838316, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.688641457028604, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095286666642836, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390045811543426, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.710000000000056, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.222011428177001, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6860463456835575, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095122377399301, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390004581154794, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.7100000000000057, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2178986828213825, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68565376026179, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095102608813469, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439000045811553, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.7100000000000004, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217169414094188, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685598489165089, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100297988704, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439000004581156, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217051717633141, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685591090287359, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100033509606, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439000000458116, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217033954896075, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590136171517, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100003722035, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390000000458114, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170314057885365, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590016632, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000409311, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390000000045813, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031054050773, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900019947425, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000044642, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390000000004584, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031007020819, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000235634, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000004836, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439000000000046, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000892946, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559000002748, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000000521, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390000000000045, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000111553, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000003169, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951000000000555, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.4390000000000005, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000013723, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000362, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000000006, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000001665, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559000000004, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.095100000000001, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000199, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000005, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000024, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000001, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000004, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -4.0951, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.64903881817133, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.09511256244512, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390016100017853, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000082059212, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000000112564, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.50 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.54 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.501230932287, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.53927924254, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7161900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-5.01 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.22 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.45 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.01455605515247, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.2169392796861, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.454041886381, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71061900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.48 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.82 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.12 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.4834935046735005, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.817176422060988, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.11946785593722, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4410055848508, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710061900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.35 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.72 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.3502622523367505, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.718486605515247, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.09916130932287, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.43925069810635, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100061900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2570003757010255, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.69216932110305, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.09570919639843, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390300837727623, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71000061900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.226357187663573, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686741381193033, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095185287495781, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439003509773489, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000061900767, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.218896237532714, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685774220990886, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095111371666104, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390004011169704, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000006190077, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217366742755889, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685617633148634, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095101462071356, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000451256597, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000006190075, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217086957125982, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685593947592662, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951001827589195, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000005013962, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000619007, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217039793262654, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590542793991, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100022337201, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000005515358, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71000000000619, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217032318989398, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590072372532, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100002680464, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000601675, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000619, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031190520691, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559000940843, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000316783, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000065184, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000000617, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031026672897, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590001197437, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000036958, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000007017, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710000000000006, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310036372145, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559000014968, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000004264, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000000756, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100000000000004, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000484963, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000018421, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000487, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000008, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000063417, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000002237, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951000000000555, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000001, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000008154, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000269, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000006, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000001033, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900000000315, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000001, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000129, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000004, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.0, 3: -2.3823900000000005, 4: -1.8819}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.71, 4: -0.9}, Best action: 2, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -1.8819}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -1.8819}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -1.8819}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -2.6125290000000003}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.88199, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -2.6856648}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.6126109, 2: -2.3850999999999996, 3: -2.3823900000000005, 4: -2.6856648}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -1.9, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -2.3850999999999996, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -2.71 -1.14 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000016, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -5.075231442718778, 3: -4.689569928171451, 4: -5.070122827625091}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.71, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -3.021931, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.708814618, 2: -3.021931, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.36502130238, 2: -3.021931, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.13851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.74 -4.16 -3.44 -2.71 \n",
      "-5.48 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -3.37 -1.90 -1.00 0.00 \n",
      "-2.71 -2.12 -1.01 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000002, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.4753584903763235, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.3651398405800004, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -2.1243862, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.57 -4.74 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.565185700708895, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.741915856230487, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095102560345959, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000167646975, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000009117693, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000112562, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.30 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.297470413617583, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.691224659503276, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951003918286455, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000017503231, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000001002944, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000011255, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.229639015559412, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68615378333153, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100053360482, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000018315616, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.710000000010941, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000001125, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.218748466054481, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685646421555143, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100006819613, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000001920185, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000000011852, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000000112, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217248448065114, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685595647679401, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000837497, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000201617, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.710000000000128, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000000000001, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217057319426826, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590565446312, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000100081, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000021197, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000000000137, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217034089954196, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590056625697, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000011725, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000000000223, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.7100000000000013, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031354862234, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590005672068, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000001354, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000000236, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031040080598, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000568303, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000155, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000000023, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031004468385, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000056957, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000017, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000492973, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559000000571, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000002, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000053922, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000573, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000005857, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000058, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000633, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000007, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000069, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000001, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000008, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000001, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -2.71, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.0878766000000004, 4: -2.546109}, Best action: 1, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -3.17 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -3.1737088000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000076764, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000728, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.81 -2.76 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.8146041280000005, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.756370880006218, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000008268, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000073, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.40 -3.51 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.39933934368, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.514120825605037, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7146370880012918, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000885, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000007, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.93 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.19 -3.45 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.9320238683808, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.18637180310808, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4502681238415502, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710463708800201, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000095, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.42 -4.78 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.11 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.416642433388448, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.784163547355625, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.113354360622464, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.440502416512318, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710046370880028, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000008, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.32 -4.71 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.316836716696901, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.710233386839758, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.098142393437224, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4391878020640547, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100046370880038, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.25 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.246972715009894, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.690518677368128, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095556359015608, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390225362476885, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100004637088, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.224017400169173, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.686452518539455, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095163890262189, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439002629228897, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71000004637088, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.218428280033876, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685728002966318, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951085187016245, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390003004833023, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000004637088, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217282510406106, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685610700444948, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095101095261638, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000033804372, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000004637086, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217072918401018, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685592957206422, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100136907705, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000037560413, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000000046371, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170375871773045, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855904066158836, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100016733165, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000004131647, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000000004637, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031988076597, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590054215451, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.09510000200798, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000000045073, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000004636, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031142722175, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590007048009, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000237307, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000048833, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000000000046, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031019981105, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559000089702, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000027687, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000000000526, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000000044, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031002724697, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900001121285, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000003194, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000000000056, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000000004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000363294, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000013801, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000365, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000000063, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000047508, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900000016755, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000041, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000000005, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170310000061075, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900000002, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.095100000000005, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000773, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000024, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000097, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000003, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000013, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000001, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.4482999284559, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.97 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.971681942049279, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.45 -4.71 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.4487654730599155, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.714199194204928, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.263377894611984, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.688450919420493, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.223983034191797, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68587609194205, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2179579378922405, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685618609194205, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.21714686723653, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685592860919421, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217044904068384, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855902860919425, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217032622141312, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900286091945, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031185387579, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559000286092, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031020856103, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000286092, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031002317345, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900000286095, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170310002549085, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000002861, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000027808, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000286, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000003013, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000029, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000325, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000000003, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000035, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000000004, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.07 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.96 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.01 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.71, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9590489999999998, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.76 -1.91 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.75782969, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9118098, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.48 -2.72 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4777420489, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.724348907, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90177147, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.13 -3.45 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.68559, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.1264810596090005, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.45449681956, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7128697814, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.900236196, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.71 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.11 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.711008658283291, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.1107905298044995, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.44287420489, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7104782969, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000295245, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.70 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2376201132094655, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.700841194969973, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.09980715894135, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439774840978, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100717445350004, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90000354294, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.231443379246625, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.690927918239491, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0961983370863155, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.43913559717115, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100100442349, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.900000413343, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.22279595169865, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.687013444863864, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095319667417263, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439021695547384, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100013392313205, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000472392, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.218760485509595, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685910275094369, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095139540135107, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439003254332108, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100001721868843, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90000000531441, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217463371377399, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685654055018873, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095106590022518, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390004649045873, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000215233604, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.90000000059049, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.00000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217126121703028, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685601743420127, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.0951010355749675, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000639243805, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000002630633, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000649537, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.000000000000729, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170500243406055, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685592013157736, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100155336245, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000085232506, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000003156755, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000070858, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000728, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217034533091827, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590327138132, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100022437458, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000001108022, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000000037307, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000007677, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000073, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.21703161829107, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590050888154, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100003141244, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.439000000141021, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000043525, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000827, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0000000000000007, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170311030485115, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590007633222, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100000428352, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000176277, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000005022, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000088, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031016487762, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590001110287, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100000057114, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.43900000000217, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000000573, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9000000000000008, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031002548109, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.6855900001572905, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.095100000007469, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000002634, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.7100000000000066, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.2170310003822165, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -4.685590000021779, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.09510000000096, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213495290679495, 1: -4.1304199928455905, 2: -4.09510000000096, 3: -5.489696615740941, 4: -4.880196955432809}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.910959782225256, 1: -4.488666500198322, 2: -3.4390000000000316, 3: -3.9008914281899996, 4: -4.421293429815901}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.010677291180158, 1: -3.6721800460000003, 2: -2.710000000000001, 3: -4.062946737557719, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -5.29 -4.16 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.217031000055863, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.321518533902753, 2: -5.285022721763458, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.164723191827099, 3: -5.457455451216629, 4: -5.253597855113948}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -3.5249549702306506, 2: -3.4390000110927157, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7100000003732503, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.70 -4.80 -4.10 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.702571504633988, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.321518533902753, 2: -4.801928057556296, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.1020623281678095, 3: -5.457455451216629, 4: -5.253597855113948}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -3.5249549702306506, 2: -3.4390000014116042, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7100000000373248, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.36 -4.70 -4.10 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.359818877083999, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.321518533902753, 2: -4.702863291571555, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.09579623396018, 3: -5.457455451216629, 4: -5.253597855113948}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -3.5249549702306506, 2: -3.4390000001713936, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.7100000000037325, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.25 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.24530115388136, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.321518533902753, 2: -4.687881278664902, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 2, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.647510575800206, 1: -5.321518533902753, 2: -4.687881278664902, 3: -6.420344960158118, 4: -5.71252135198346}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.12819653909971, 1: -5.026320266445672, 2: -4.095169623534846, 3: -5.457455451216629, 4: -5.253597855113948}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.41899190476867, 1: -3.5249549702306506, 2: -3.4390000000201626, 3: -3.8158984773, 4: -4.036815325836}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8749015369636104, 1: -2.710000000000373, 2: -3.318008319, 3: -3.3183022500000003, 4: -3.4078725387}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.649835079736099, 1: -1.9, 2: -3.23229258, 3: -3.341529, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -1.0, 2: -3.0938549485589997, 3: -3.089925900000001, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.86 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.97 -2.96 -1.90 -1.00 0.00 \n",
      "-2.71 -1.93 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.856743477204822, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.7645668490376325, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.9696632708698, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.957266806058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.9336579299999999, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.0013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.34 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.52 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.69 -2.76 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.344973495440965, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.693487684903763, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.5249372494045375, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.69235243999396, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7619896039058, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.904487724, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.00013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.03 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.34 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.51 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.236222374316145, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.034547940508052, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.343299201335562, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.506446823163094, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7188340168305802, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.9005609655, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.50 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.92 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.17 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.45 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.501606069243136, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.92152714713261, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.174551846895662, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4529002359490795, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7113377837380583, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.90006731586, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.0000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.44 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.77 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.436597596101728, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.773539710698747, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.114304375808321, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4414736284227354, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.710188304220406, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.900007853517, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.00000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.31 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.71 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.310226925276159, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.709940515474615, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.099024076603247, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439399889260802, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -2.7100251917708107, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -3.684266240238, 2: -1.9000008975448, 3: -3.3615206749964393, 4: -3.1425039000000003}, Best action: 2, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.380366979}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -3.6721209970000004, 3: -3.9931893900000004, 4: -3.97613395089}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.0, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -2.4633900000000004, 4: -0.9}, Best action: 2, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.000000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.9563390112193098, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.25 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.81 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.246074510062053, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.691203553596091, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0958163179615745, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390603942604367, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.8062120996999997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.52 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.22448232941904, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686731572908484, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095220551147111, 2: -5.075231442718778, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.48 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.52 -2.72 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.218700806997776, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.479610625893058, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095220551147111, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.5169378401830436, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71962120997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.86 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.77 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.16 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.45 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.860354687673155, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.765089709018466, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.158241705662977, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4545869640940046, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.710962120997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.35 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.345758133072272, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.744684752488858, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.114039611482442, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4413380144169703, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100962120997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.28 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.71 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.277770462823202, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.706840560549664, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.09888775282599, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4393117332424543, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71000962120997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.240317900327549, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.690783135844019, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095731279208987, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439038966504321, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.710000962120997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.99}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.72 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.223566130066411, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6866206497436815, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095194690789398, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.43900467596844, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000962120996, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.9953459000000002, 2: -1.8019, 3: -2.677968, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.8019, 3: -2.677968, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.8019, 3: -2.677968, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.8019, 3: -2.677968, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.44 -2.71 -2.48 -1.08 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.218519339299023, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685769764513781, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095113256613376, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390005455286445, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71000000962121, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -2.4823900000000005, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.08019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.44 -3.18 -2.02 -1.01 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2173254431860645, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685618714308213, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095101767539539, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000062346045, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -3.1817359009621216, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -2.0231928999999997, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.82 -2.86 -1.92 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217083702908259, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685594303137848, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951002272542505, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.821106086013923, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.856959839096212, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9188146799999999, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.19 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.60 -2.74 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170397558324835, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590614389728, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.193113144271878, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9025310069999999, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.76 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.60 -2.74 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217032373238927, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.764980708299194, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.104901314427188, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71205011567, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9003180546, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.28 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.60 -2.74 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.28133761104624, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.701468135515942, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.0960801314427195, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.4406605936926997, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.710462635793, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000383008500001, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.60 -2.74 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2363229508725375, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.687971720020197, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.096543094035359, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.4395407943616, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.7100772872678003, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.900004479624, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.48 -1.00 \n",
      "-3.60 -2.74 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.220889388303614, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68699707817066, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.095682352836432, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.4391166821230783, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -2.71001135722222, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000005129163, 3: -3.7003354290000003, 4: -2.546109}, Best action: 2, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7399358747096207, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000005129163, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.33 -2.48 -1.00 \n",
      "-3.60 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.218556572148596, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686202413614576, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.095252747803337, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.439020867562306, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.3272301690000003}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -3.621769048000001, 3: -3.9931893898889013, 4: -3.9277794537900004}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.4823900000000005, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000008018999, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.92 -3.27 -1.96 -1.00 \n",
      "-3.60 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217679612242666, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685774967082161, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.095132177505802, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.9205527517, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.712994002933165, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.90000005778702, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00000000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.40 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.60 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217245684560818, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685634560487915, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.404605952396703, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.596248078269324, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7102994471008026, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.900000005843656, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000000008019, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.94 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.25 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.45 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217088562451293, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.936294277490122, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.253421538637823, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4549673599785824, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100299494434417, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000005908608, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000008018, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.42 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.84 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.12 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.420107221012128, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.838900874045649, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.123865715446435, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.440620995047046, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.710002995422941, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000597355, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000000802, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.36 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.72 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.361520430078189, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.724221316916177, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.099289577532751, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439164525797287, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71000029959068, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000060386, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000000000008, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.26 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2627713097099225, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.692846689493146, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095652223649077, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439016695248179, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000299639593, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000006103, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000000009, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.227482949460441, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686762970105067, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095168745515933, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390016937956247, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000029968903, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000000616, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.219026300731149, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685762980878412, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095108246526049, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390001718070433, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.710000000299739, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000000061, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217370644584628, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685613977773941, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.09510096381631, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000017423493, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000000299787, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9000000000000006, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217084386455355, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685593178468605, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100110494661, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000001766632, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000000029985, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217038913205105, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590407347536, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.0951000124804375, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000179092, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000000002997, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217032121272014, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590050843908, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100001393108, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000181518, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71000000000003, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031153310767, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590006212808, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000154014, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000018395, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.710000000000003, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031020363452, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000746032, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000016892, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.4390000000001866, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.7100000000000004, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031002640631, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000088286, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.09510000000184, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000019, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.49 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310003355755, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000010319, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.095100000000199, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.260379383180001, 1: -3.9999856446642656, 2: -3.439000000000002, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.48516094662758, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.489580417545864, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.18 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000041916, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000001193, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.175076232874908, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4440580417545865, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.75 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000005158, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.750370748628795, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.107194637108706, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4395058041754587, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.26950340638984, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.701864730920932, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.096719165092992, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.439050580417546, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.24 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.235460772684939, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.688528996817417, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095302886647511, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.439005058041755, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.221254564690602, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686048237866226, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095124385678573, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390005058041755, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217824529140704, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685655576186267, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951028482692395, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390000505804177, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217163469624947, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685598864716711, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100325797062, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.439000005058042, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217051427383031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685591150367292, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100036676721, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390000005058043, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217033974535809, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590144744873, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000040773735, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390000000505805, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031414696928, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900177771606, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000448708, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390000000050582, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031055869193, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590002141169, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000000489675, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.439000000000506, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -1.9, 3: -3.489381601414793, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -2.6059680000000003}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.71 -2.55 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031007321267, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900002537805, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000005306, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.4390000000000507, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.71, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -3.20083408, 3: -3.489381601414793, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -3.20083408, 3: -3.489381601414793, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -2.614339, 2: -3.20083408, 3: -3.489381601414793, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.0000000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.9563390112193098, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.27 -1.96 -1.00 \n",
      "-3.44 -3.23 -1.97 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310009376895, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000029676, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000000005715, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.439000000000005, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -3.2333482900000003, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.971433901121931, 2: -3.20083408, 3: -3.489381601414793, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.00000000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.9563390112193098, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.86 -3.27 -1.96 -1.00 \n",
      "-3.44 -2.82 -1.91 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000117807, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900000034305, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000000061, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -3.862912114900001, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.8201962889087646, 3: -3.9931893900000004, 4: -4.2720314026590005}, Best action: 2, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.95901830508634, 1: -3.9999856446642656, 2: -3.439000000000002, 3: -4.414971117465, 4: -4.0848439924179}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.016040957, 1: -3.877641009177081, 2: -2.8201962889087646, 3: -4.084908939000002, 4: -4.2720314026590005}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3541407000000003, 1: -1.9071433902243862, 2: -3.20083408, 3: -3.489381601414793, 4: -3.339310509}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -3.0909969900000003, 2: -1.000000000013851, 3: -2.677239, 4: -2.6856648}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: -1.9563390112193098, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.44 -3.94 -3.27 -1.96 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000014559, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000392, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.438468813069007, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.938958523646231, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -3.2729128048000007, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.958239000649539, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.96 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.53 -3.94 -2.81 -1.91 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000001773, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.963718738585935, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.534403285460348, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.944955224252624, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.8134648710061265, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9058239000649537, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.44 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.07 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.55 -3.57 -2.73 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.442315278254784, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.0692385350814755, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.54885406019066, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.573402067940225, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7250638461532253, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9005823900064953, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.55 -4.69 -4.10 -3.44 -2.71 \n",
      "-5.09 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.25 -3.46 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.550314741241474, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -5.091495642262583, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.249341081050649, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.464641922178135, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7119781205205835, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000582390006495, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.58 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.85 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.13 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.579142944356839, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.851115839877284, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.131294065069355, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.443166469839486, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7102449856425848, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000058239000648, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.39 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.387318124736284, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.731459776693906, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.10209424707692, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4396150853544425, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710029215923311, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000005823900064, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2712142315956925, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.695842317801697, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.096297643844791, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439085173433326, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710003393328236, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000582390006, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.230753700578944, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68758532329445, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095288754865473, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439011265939204, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100003865064144, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000058239, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.220019481926399, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685942423770479, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095128000897303, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439001439664116, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000433680007, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000005823898, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217615311446728, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685647923103862, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095103966217664, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439000179094492, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000048085358, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000582389, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217136348858801, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855990049466945, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100541688304, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000218043633, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000528027, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000058237, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217048828892703, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685591339262196, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100071830364, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439000002608138, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000000575197, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000005823, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217033867691649, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855901921088146, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100009295629, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439000000307405, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000000062234, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000000000058, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031442377304, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590026740341, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100001178561, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000357817, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000000006697, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000000057, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031065897406, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590003628668, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000146839, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000041208, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000000072, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000000006, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031009528962, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000481806, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000000180215, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000004703, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000000008, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.21703100134316, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000062778, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000002183, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000000533, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000000001, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000185166, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000185166, 2: -5.999013681786304, 3: -6.112680754297898, 4: -6.27988006001392}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900000080455, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000000002615, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000000063, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000025034, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000001016, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000000000315, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000000005, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310000033275, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900000001265, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100000000004, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000436, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6855900000000155, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310000000555, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590000000002, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2170310000000075, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031000000001, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.9, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.73 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -2.49 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.07 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.49049, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -3.19 -2.02 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.01 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -3.1882969, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -2.0180979999999997, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.83 -2.85 -1.92 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.826420489, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.8534890699999997, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9177146999999999, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.41 -3.59 -2.74 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68559, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.408910596090001, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.5939681956, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.738697814, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.90236196, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.94 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.25 -3.48 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.939776582832901, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.252005298045, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4777420489, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.714782969, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900295245, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.42 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.84 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.14 -3.45 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.42292213209465, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.83810194969974, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.1421715894135005, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.44674840978, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71071744535, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000354294000001, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.36 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.74 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.11 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.361154792466255, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.73896918239491, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.10608337086315, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4403559717115, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7101004423490003, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.90000413343, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.70 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2746805169865025, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.699824448638643, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.097296674172631, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.43921695547384, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100133923132, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000472392, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.2343258550959515, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.688792750943695, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095495401351073, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439032543321076, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.71000172186884, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000531441001, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.221354713773988, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.686230550188739, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951659002251795, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390046490458683, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000215233605, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000059049, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217982217030277, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.6857074342012695, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095110355749671, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390006392438073, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000263063295, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.900000000649539, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.00000000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217221243406056, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.68561013157736, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095101553362451, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000852325078, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000031567597, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000708588, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.000000000000729, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217066330918268, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685593271381322, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100224374576, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439000011080226, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.7100000003730718, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000076764, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000000728, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217037182910698, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590508881539, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.09510003141244, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.439000001410211, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000043525, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000008268, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000000073, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217032030485116, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590076332231, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.095100004283514, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000001762764, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000005022, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000000885, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0000000000000007, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.71 -1.90 \n",
      "-4.10 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.53 -2.73 -1.90 -1.00 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6.492936834437387, 1: -5.217031164877619, 2: -5.999013681786304, 3: -6.112680754297898, 4: -5.753783116151377}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342969971922696, 1: -4.685590011102869, 2: -5.5882198779839864, 3: -5.494713760045002, 4: -5.932109403628842}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.338825114623365, 1: -4.760417300375821, 2: -4.0951000005711355, 3: -4.689569928171451, 4: -4.724043282762509}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.68194505739768, 1: -4.520774617390001, 2: -3.4390000000216956, 3: -4.846777992291781, 4: -4.001309881659001}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4411217550479005, 1: -4.168272833212223, 2: -2.710000000000574, 3: -3.9931893898889013, 4: -4.226410874259001}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.341529, 1: -1.9000000000000095, 2: -2.6785558000000003, 3: -3.40388766, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6109, 1: -2.9953459000000002, 2: -1.0, 3: -2.677968, 4: -1.9705968}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.39049, 1: 0.0, 2: -0.99, 3: -1.880999919, 4: -0.999}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "[161, 33, 47, 53, 17, 41, 17, 23, 45, 17, 17, 17, 17, 15, 21, 13, 15, 11, 22, 13, 11, 9, 16, 13, 9, 11, 9, 9, 9, 11, 13, 9, 7, 9, 9, 7, 7, 9, 9, 9, 9, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 9, 9, 13, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 13, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 9, 7, 7, 11, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 13, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 11, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 9, 7, 7, 7, 11, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 8, 7, 13, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 13, 11, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 17, 10, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 8, 7, 7, 7, 7, 7, 13, 7, 7, 7, 7, 7, 7, 8, 11, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(0.9, 0.01, 0.9, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(1000, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 159)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 50)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m         pygame\u001b[39m.\u001b[39mquit()\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(step)\n\u001b[0;32m---> 39\u001b[0m gameDisplay\u001b[39m.\u001b[39;49mfill(white)\n\u001b[1;32m     40\u001b[0m drawGrid(gridSize,gridSize,terminal)\n\u001b[1;32m     41\u001b[0m text \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mrender(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, black)\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
