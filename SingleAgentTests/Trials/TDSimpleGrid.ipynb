{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: -0.9, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: -0.9, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: -0.9, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 1\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.9 -0.9 -0.9 -0.9 -0.9 \n",
      "-0.9 0 0 0 0 \n",
      "0 0 0 0 0.0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.7919, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.9 -0.9 -0.9 \n",
      "-0.9 -0.9 0 0 0.0 \n",
      "0 0 0 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.8009, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -1.629, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-1.8009 -0.99 -0.99 -0.99 -0.99 \n",
      "-1.7919 -1.719 -0.99 -0.99 -0.99 \n",
      "-1.719 -1.719 -0.9 -0.9 -0.9 \n",
      "-0.99 -0.99 -0.9 -0.9 0.0 \n",
      "-0.99 -0.9 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -1.7019, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-1.8009 -1.7919 -1.719 -0.99 -0.99 \n",
      "-1.7919 -1.719 -1.719 -1.719 -0.99 \n",
      "-1.7919 -1.719 -1.719 -0.99 -0.9 \n",
      "-1.719 -1.719 -0.99 -0.9 0.0 \n",
      "-1.719 -0.99 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.531529, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.531529, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.46519, 2: -2.531529, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -1.7919, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -2.4715800000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.531529, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.531529, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.531529, 3: -3.1499568000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -2.6036019, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.46519, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -2.3823900000000005, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -1.7019, 3: -2.3587290000000003, 4: 0}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-2.546109 -2.4724800000000005 -1.719 -1.719 -0.99 \n",
      "-1.8747 -2.46429 -1.719 -1.719 -0.99 \n",
      "-1.7919 -1.719 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -0.99 -0.9 0.0 \n",
      "-1.719 -0.99 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.6118819, 3: -3.26553417, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.6118819, 3: -3.26553417, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5979579999999998, 2: -2.6118819, 3: -3.26553417, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8747, 2: -2.4715800000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.46519, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538909, 2: -2.4715800000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.4724800000000005, 3: -2.6036019, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.46429, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -2.46519, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -2.596968, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.46429, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0687039, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0687039, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0687039, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -3.0687039, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.46429, 3: -3.0687039, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -1.7019, 3: -2.3587290000000003, 4: -2.96234829}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.6118819 -2.5389090000000003 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.4724800000000005 -2.538819 -2.46519 -1.8738000000000001 -1.719 \n",
      "-2.46519 -2.46429 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -0.99 -0.9 0 \n",
      "-1.719 -0.99 -0.9 0.0 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.6783028, 2: -2.6118819, 3: -3.26553417, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.5396380000000005, 3: -2.6036019, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.538819, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.538819, 3: -3.0687039, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.3823900000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -1.7019, 2: -1.7019, 3: -2.3587290000000003, 4: -2.96234829}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-2.6783028 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.4724800000000005 -2.5389090000000003 -2.538819 -1.8738000000000001 -1.719 \n",
      "-2.46519 -2.46429 -1.8747 -1.719 -0.99 \n",
      "-1.719 -1.719 -1.719 -0.99 0 \n",
      "-1.719 -0.99 -0.9 0 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538909, 2: -3.1432329, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538909, 2: -3.1432329, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.538909, 2: -3.1432329, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -2.46519, 2: -3.0834549000000004, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -2.3913900000000003, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.8009, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.3913900000000003, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.3913900000000003, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.3913900000000003, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.46519, 2: -1.8009, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -2.5389090000000003, 2: -3.0834549000000004, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -2.5389090000000003, 2: -3.0834549000000004, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -2.5389090000000003, 2: -3.0834549000000004, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.3913900000000003, 3: -2.4715800000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.3913900000000003, 3: -2.4715800000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.6126109, 2: -2.3913900000000003, 3: -2.4715800000000003, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.8009}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -2.3823900000000005, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -2.3823900000000005, 4: -1.8009}, Best action: 2, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -2.3823900000000005, 4: -1.8009}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -2.3587290000000003, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -2.3587290000000003, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -2.3587290000000003, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.378539, 2: -1.8009, 3: -1.7019, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.072898800000001, 2: -1.7019, 3: -2.3587290000000003, 4: -2.96234829}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-2.6783028 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.546109 -2.5389090000000003 -2.538819 -1.8738000000000001 -1.719 \n",
      "-2.546109 -2.46429 -1.8747 -1.719 -1.719 \n",
      "-2.4724800000000005 -1.8009 -1.719 -0.999 -1.5163928999999998 \n",
      "-1.88199 -1.941039 -0.9999 -0.99 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -2.5396380000000005, 3: -2.6036019, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8018, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.8018, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.8018, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.8018, 2: -1.88928, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.999, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -1.378539, 3: -2.3587290000000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -1.378539, 3: -2.3587290000000003, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.8009, 2: -1.378539, 3: -2.3587290000000003, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.072898800000001, 2: -3.12729678, 3: -2.3587290000000003, 4: -2.96234829}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-2.6783028 -2.546109 -2.5963119 -2.5306290000000002 -2.4724800000000005 \n",
      "-2.546109 -2.5389090000000003 -2.538819 -2.46519 -2.4724800000000005 \n",
      "-2.546109 -2.46429 -1.8747 -1.7919 -1.8018 \n",
      "-2.4724800000000005 -1.8009 -1.719 -0.999 -1.5163928999999998 \n",
      "-1.88199 -1.941039 -0.9999 -1.719 -2.3587290000000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.6783028, 2: -3.21770448, 3: -3.26553417, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1506948, 2: -3.1432329, 3: -3.2715119699999997, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1506948, 2: -3.1432329, 3: -3.2715119699999997, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1506948, 2: -3.1432329, 3: -3.2715119699999997, 4: -3.21695919}, Best action: 0, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1506948, 2: -3.1432329, 3: -3.2715119699999997, 4: -3.8274328629000003}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.23017857, 2: -3.21770448, 3: -3.26553417, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.23017857, 2: -3.21770448, 3: -3.26553417, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7738391409000003, 1: -3.23017857, 2: -3.21770448, 3: -3.26553417, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.1566726000000007, 3: -2.6036019, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.1566726000000007, 3: -2.6036019, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.1566726000000007, 3: -2.6036019, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.23017857, 2: -3.284118738, 3: -3.26553417, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.1506948, 2: -3.1432329, 3: -3.2715119699999997, 4: -3.7857152142900006}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.46519, 2: -2.46429, 3: -2.596968, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -2.3823900000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.4798600000000004, 2: -2.46429, 3: -2.3823900000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.46519, 2: -2.664936, 3: -2.596968, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.46519, 2: -1.8009, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999, 3: -2.3823900000000005, 4: -1.88928}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -2.04842439, 3: -2.3587290000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -2.04842439, 3: -2.3587290000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -2.04842439, 3: -2.3587290000000003, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8018, 2: -0.999, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.5163928999999998, 2: -2.1967065900000002, 3: -1.7019, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.072898800000001, 2: -3.12729678, 3: -3.305298168, 4: -2.96234829}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-3.26553417 -3.1566726000000007 -2.5963119 -2.5306290000000002 -2.4724800000000005 \n",
      "-3.1506948 -2.546109 -2.538819 -2.46519 -2.4724800000000005 \n",
      "-2.546109 -2.546109 -2.46429 -1.7919 -1.8018 \n",
      "-2.4724800000000005 -2.46519 -1.7280000000000002 -1.629 -1.7019 \n",
      "-1.88199 -1.941039 -1.719 -1.88838 -2.96234829 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.284118738, 3: -3.26553417, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.284118738, 3: -3.26553417, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.284118738, 3: -3.8716360947, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.1566726000000007, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.318679899, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.21033429, 2: -3.318679899, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7738391409000003, 1: -3.21033429, 2: -3.318679899, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1499658000000004, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1499658000000004, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1499658000000004, 2: -3.1506858, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.1506948, 2: -3.27083958, 3: -3.2715119699999997, 4: -3.7857152142900006}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -3.1506948, 2: -3.0834549000000004, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -3.1506948, 2: -3.0834549000000004, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0811698000000005, 1: -3.1506948, 2: -3.0834549000000004, 3: -3.27151197, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.27741777, 2: -3.27083958, 3: -3.2715119699999997, 4: -3.7857152142900006}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.1499658000000004, 2: -3.1506858, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.2833817190000003, 2: -3.318679899, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.1499658000000004, 2: -3.1506858, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.605248, 2: -2.664936, 3: -2.596968, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.605248, 2: -2.664936, 3: -2.596968, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.605248, 2: -2.664936, 3: -2.596968, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.1506948, 2: -3.0834549000000004, 3: -3.27151197, 4: -3.717443457000001}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.605248, 2: -2.664936, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.46519, 2: -2.4724800000000005, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0982869900000005, 2: -1.941039, 3: -2.4715800000000003, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -2.39238, 3: -2.3823900000000005, 4: -1.88928}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.882719, 2: -1.7280000000000002, 3: -1.7919, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8018, 2: -2.228178249, 3: -1.629, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.882719, 2: -2.39229, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.71876059, 2: -2.4724800000000005, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -1.882719, 2: -2.39229, 3: -3.0818988000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -2.39238, 3: -2.3823900000000005, 4: -1.88928}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -2.39238, 3: -2.3823900000000005, 4: -1.88928}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.6126109, 2: -2.39238, 3: -2.3823900000000005, 4: -1.88928}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.69157789, 2: -2.39238, 3: -2.3823900000000005, 4: -1.88928}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.69157789, 2: -2.39238, 3: -2.3823900000000005, 4: -2.6192448}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0982869900000005, 2: -2.4864939, 3: -2.4715800000000003, 4: -2.597868}, Best action: 0, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -3.0982869900000005, 2: -2.4864939, 3: -2.4715800000000003, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.71876059, 2: -2.6722503900000003, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -3.1573287, 2: -2.664936, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.4798600000000004, 2: -2.46429, 3: -3.1350429, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.538819, 3: -3.0687039, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.4798600000000004, 2: -2.46429, 3: -3.1350429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8738000000000001, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.8018, 2: -1.88928, 3: -2.4715800000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.5511414049, 2: -2.1967065900000002, 3: -1.7019, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8018, 2: -2.228178249, 3: -2.5143389999999997, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.546838, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -1.8018, 2: -2.228178249, 3: -2.5143389999999997, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -1.8018, 2: -2.228178249, 3: -2.5143389999999997, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -1.8018, 2: -2.228178249, 3: -2.5143389999999997, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88838, 1: -2.1967065900000002, 2: -2.04842439, 3: -2.3587290000000003, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -2.6097678, 2: -2.228178249, 3: -2.5143389999999997, 4: -2.605887}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.5511414049, 2: -2.1967065900000002, 3: -2.4625800000000004, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.5511414049, 2: -2.1967065900000002, 3: -2.4625800000000004, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.5511414049, 2: -2.1967065900000002, 3: -2.4625800000000004, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.458719, 2: -1.88928, 3: -2.4715800000000003, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.458719, 2: -1.88928, 3: -2.4715800000000003, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.458719, 2: -2.6192448, 3: -2.4715800000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.5511414049, 2: -2.1967065900000002, 3: -2.4625800000000004, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.5511414049, 2: -2.1967065900000002, 3: -2.4625800000000004, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.5511414049, 2: -2.8990029969000006, 3: -2.4625800000000004, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -2.6097678, 2: -2.5152078249000005, 3: -2.5143389999999997, 4: -2.605887}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -2.6126838, 2: -2.39229, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -2.6097678, 2: -2.5152078249000005, 3: -3.0891888, 4: -2.605887}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.5511414049, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.072898800000001, 2: -3.12729678, 3: -3.305298168, 4: -3.8413175067000003}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-3.326041899 -3.318679899 -2.6051580000000003 -2.5306290000000002 -2.4724800000000005 \n",
      "-3.2715119699999997 -3.1506858 -2.5389090000000003 -2.4797700000000003 -2.4724800000000005 \n",
      "-3.1506948 -3.1425039000000003 -2.4798600000000004 -2.46429 -2.4715800000000003 \n",
      "-2.4724800000000005 -2.546109 -2.546109 -2.5963119 -2.597868 \n",
      "-1.88199 -2.4715800000000003 -2.39238 -2.04842439 -3.072898800000001 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.27741777, 2: -3.7778855760000005, 3: -3.2715119699999997, 4: -3.7857152142900006}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.27741777, 2: -3.7778855760000005, 3: -3.2715119699999997, 4: -3.7857152142900006}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.27741777, 2: -3.7778855760000005, 3: -3.8770758926999997, 4: -3.7857152142900006}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.1506948, 2: -3.3185963700000003, 3: -3.27151197, 4: -3.717443457000001}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -2.538819, 3: -3.1499568000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -2.71876059, 2: -2.6722503900000003, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -2.71876059, 2: -2.6722503900000003, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -2.71876059, 2: -2.6722503900000003, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -2.6126838, 2: -3.1765473381690006, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -2.6126838, 2: -3.1765473381690006, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -2.6126838, 2: -3.1765473381690006, 3: -3.0818988000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.69157789, 2: -2.39238, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -2.1967065900000002, 2: -2.04842439, 3: -2.3587290000000003, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.8572145756999996, 2: -3.12729678, 3: -3.305298168, 4: -3.8413175067000003}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-3.326041899 -3.318679899 -2.6051580000000003 -2.5306290000000002 -2.4724800000000005 \n",
      "-3.7670415219000004 -3.1506858 -2.5389090000000003 -2.4797700000000003 -2.4724800000000005 \n",
      "-3.2177782800000005 -3.1425039000000003 -2.4798600000000004 -2.46429 -2.4715800000000003 \n",
      "-2.546109 -2.71876059 -3.0016359 -2.5963119 -2.597868 \n",
      "-1.88199 -2.4715800000000003 -2.4715800000000003 -2.1967065900000002 -3.12729678 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.318679899, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7176638319000004, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7176638319000004, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7176638319000004, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.2104071900000006, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -3.1506858, 3: -3.0687039, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.4798600000000004, 2: -2.664207, 3: -3.1350429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0016359, 1: -3.09909618, 2: -3.1765473381690006, 3: -3.0818988000000003, 4: -3.3379697970000004}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -2.664207, 3: -3.1350429, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -2.664207, 3: -3.1350429, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -2.664207, 3: -3.1350429, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.480589, 2: -2.546838, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5979579999999998, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -3.1499568000000004, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.9252042379000005, 2: -3.15348687, 3: -2.4715800000000003, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -2.480589, 2: -2.546838, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963119, 1: -2.6097678, 2: -3.217945320459, 3: -3.0891888, 4: -2.605887}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.251071539, 2: -2.546838, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.251071539, 2: -2.546838, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.251071539, 2: -2.546838, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.9252042379000005, 2: -3.15348687, 3: -3.1564350900000004, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1558707000000004, 2: -3.27151197, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1558707000000004, 2: -3.27151197, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1558707000000004, 2: -3.27151197, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5979579999999998, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5979579999999998, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5979579999999998, 2: -3.1506858000000006, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.0687039, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.0687039, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.0687039, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2708485800000004, 2: -3.2104071900000006, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2708485800000004, 2: -3.2104071900000006, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2708485800000004, 2: -3.2104071900000006, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5979579999999998, 2: -3.1506858000000006, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.251071539, 2: -3.2523229800000006, 3: -3.0752649, 4: -3.284634699}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -3.1624956, 3: -3.1350429, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -3.1573287, 2: -3.1625685, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.2773448700000003, 2: -3.1506858, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.0687039, 4: -3.337247358}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.2773448700000003, 2: -3.700718739, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.1573287, 2: -3.1625685, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -2.71876059, 2: -3.229573329, 3: -3.0752649, 4: -3.3862187349000004}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.0982869900000005, 2: -2.4864939, 3: -2.4715800000000003, 4: -3.1558617}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -1.88199, 2: -2.6117919, 3: -2.4724800000000005, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -1.88199, 2: -2.6117919, 3: -2.4724800000000005, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -2.6126109, 2: -2.6117919, 3: -2.4724800000000005, 4: -2.664207}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.1639698900000006, 2: -2.6117919, 3: -2.4724800000000005, 4: -2.664207}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6051580000000003, 1: -3.1639698900000006, 2: -2.6117919, 3: -3.1499568000000004, 4: -2.664207}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -3.21623019, 3: -3.27143907, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -3.21623019, 3: -3.27143907, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.664297, 2: -3.21623019, 3: -3.27143907, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.1639698900000006, 2: -2.6117919, 3: -3.3251736600000004, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.0982869900000005, 2: -2.4864939, 3: -2.6715699, 4: -3.1558617}, Best action: 2, Actual action: 2\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.69157789, 2: -2.7984617559, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 0, Actual action: 0\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.26251188, 1: -3.09909618, 2: -3.1765473381690006, 3: -3.0818988000000003, 4: -3.3379697970000004}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -3.1738558590000006, 2: -3.229573329, 3: -3.0752649, 4: -3.3862187349000004}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.281981139, 2: -3.21623019, 3: -3.27143907, 4: -3.379776489}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.2177782800000005, 2: -3.3185963700000003, 3: -3.27151197, 4: -3.717443457000001}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.281981139, 2: -3.21623019, 3: -3.27143907, 4: -3.379776489}, Best action: 2, Actual action: 2\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -3.1738558590000006, 2: -3.229573329, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 1, Actual action: 1\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.0982869900000005, 2: -3.1506291900000005, 3: -2.6715699, 4: -3.1558617}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.1639698900000006, 2: -3.1752392490000005, 3: -3.3251736600000004, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.1639698900000006, 2: -3.1752392490000005, 3: -3.3251736600000004, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.1639698900000006, 2: -3.1752392490000005, 3: -3.3251736600000004, 4: -3.3244283700000006}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.1639698900000006, 2: -3.1752392490000005, 3: -3.3251736600000004, 4: -3.7952584479000007}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.779212599900001, 2: -3.1752392490000005, 3: -3.3251736600000004, 4: -3.7952584479000007}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.0982869900000005, 2: -3.1506291900000005, 3: -3.3251646600000004, 4: -3.1558617}, Best action: 1, Actual action: 1\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.0982869900000005, 2: -3.1506291900000005, 3: -3.3251646600000004, 4: -3.1558617}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.7194411609000007, 2: -3.1506291900000005, 3: -3.3251646600000004, 4: -3.1558617}, Best action: 2, Actual action: 2\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -2.69157789, 2: -2.7984617559, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 1, Actual action: 1\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -2.69157789, 2: -2.7984617559, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.3493358799, 2: -2.7984617559, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 2, Actual action: 2\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -2.1967065900000002, 2: -2.7379528308000003, 3: -2.3587290000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -2.1967065900000002, 2: -2.7379528308000003, 3: -2.3587290000000003, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -2.8990029969000006, 2: -2.7379528308000003, 3: -2.3587290000000003, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -2.9591785134900004, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 2, Actual action: 2\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -3.1004707896900006, 2: -2.7379528308000003, 3: -3.5328074959269005, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -3.1004707896900006, 2: -2.7379528308000003, 3: -3.5328074959269005, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -3.1004707896900006, 2: -2.7379528308000003, 3: -3.5328074959269005, 4: -3.26405988}, Best action: 2, Actual action: 2\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.185814339, 1: -3.8572145756999996, 2: -3.90086039619, 3: -3.305298168, 4: -3.8413175067000003}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.326041899 -3.330613458 -3.2708485800000004 -3.1499568000000004 -2.4724800000000005 \n",
      "-3.7670415219000004 -3.3193350990000003 -3.1506858 -2.6117919 -2.6117919 \n",
      "-3.27151197 -3.1625685 -3.1624956 -3.1550427 -2.597868 \n",
      "-3.27143907 -3.229573329 -3.09909618 -2.605887 -2.597868 \n",
      "-3.2228640900000003 -3.1558617 -3.0916603800000004 -2.8543048976700005 -3.185814339 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.7853166798000006, 3: -3.94729978725, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.7853166798000006, 3: -3.94729978725, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -3.769036506, 2: -3.7853166798000006, 3: -3.94729978725, 4: -3.92669812809}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7670415219000004, 1: -3.779804565, 2: -3.7778855760000005, 3: -3.94241598297, 4: -3.7857152142900006}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -4.328207283339, 2: -3.7853166798000006, 3: -3.94729978725, 4: -4.345589382669}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.3420459699000005, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.3420459699000005, 3: -3.7768048317000003, 4: -3.330613458}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.3420459699000005, 3: -3.7768048317000003, 4: -3.93085824678}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.2708485800000004, 2: -3.3312186990000003, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.8615197347000003, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.6507603690000003, 2: -3.1506858000000006, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.27084858, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.1440519, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.1440519, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.1440519, 2: -3.1499568000000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.1440519, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.1440519, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1558707000000004, 2: -3.27151197, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.3299566290000002, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.773751417}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.27084858, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.27084858, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.27084858, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.3299566290000002, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.3299566290000002, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7731757509, 1: -3.3299566290000002, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.3299566290000002, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.3299566290000002, 2: -3.9259080306000005, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.1558707000000004, 2: -3.27151197, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.9252042379000005, 2: -3.15348687, 3: -3.1564350900000004, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.9252042379000005, 2: -3.15348687, 3: -3.1564350900000004, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.9252042379000005, 2: -3.15348687, 3: -3.1564350900000004, 4: -3.26405988}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.744162168490001, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.744162168490001, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6095068, 1: -2.744162168490001, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -3.26405988}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.29679350379, 2: -3.15348687, 3: -3.1564350900000004, 4: -3.5958214206990005}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.29679350379, 2: -3.15348687, 3: -3.1564350900000004, 4: -3.5958214206990005}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.29679350379, 2: -3.7696730517000003, 3: -3.1564350900000004, 4: -3.5958214206990005}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.251071539, 2: -3.2523229800000006, 3: -3.746911239, 4: -3.284634699}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.6507603690000003, 2: -3.1506858000000006, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.27151197, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.6507603690000003, 2: -3.8243346129000004, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.1625775000000003, 2: -3.330620019, 3: -3.8615197347000003, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -3.1624956, 3: -3.7589324490000005, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.251071539, 2: -3.2523229800000006, 3: -3.746911239, 4: -3.284634699}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -2.6097678, 2: -3.217945320459, 3: -3.0891888, 4: -2.605887}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -2.6097678, 2: -3.217945320459, 3: -3.0891888, 4: -2.605887}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -2.6097678, 2: -3.217945320459, 3: -3.0891888, 4: -3.27135717}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -3.1004707896900006, 2: -2.8543048976700005, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91267537209, 1: -3.8572145756999996, 2: -3.90086039619, 3: -3.305298168, 4: -3.8413175067000003}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-3.88372454289 -3.7768048317000003 -3.3312186990000003 -3.27084858 -3.773751417 \n",
      "-3.7778855760000005 -3.3193350990000003 -3.330620019 -3.3193350990000003 -3.27151197 \n",
      "-3.27151197 -3.1625685 -3.20287239 -3.2523229800000006 -3.22131609 \n",
      "-3.27143907 -3.229573329 -3.09909618 -3.0891888 -2.744162168490001 \n",
      "-3.2228640900000003 -3.1558617 -3.0916603800000004 -2.89366238169 -3.305298168 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -4.328207283339, 2: -3.97632856896, 3: -3.94729978725, 4: -4.345589382669}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88372454289, 1: -4.328207283339, 2: -3.97632856896, 3: -3.94729978725, 4: -4.345589382669}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4341893340299, 1: -4.328207283339, 2: -3.97632856896, 3: -3.94729978725, 4: -4.345589382669}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.328207283339, 2: -3.97632856896, 3: -3.94729978725, 4: -4.345589382669}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.328207283339, 2: -3.97632856896, 3: -4.4920428063974995, 4: -4.345589382669}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.88359194679, 3: -3.7768048317000003, 4: -4.000143060297001}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.328207283339, 2: -4.356844770573, 3: -4.57003042149735, 4: -4.345589382669}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -3.779804565, 2: -3.7778855760000005, 3: -3.94241598297, 4: -3.7857152142900006}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.7851707340000003, 2: -3.700718739, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.7851707340000003, 2: -3.700718739, 3: -3.711030588, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.7851707340000003, 2: -3.700718739, 3: -3.711030588, 4: -3.9205949400900004}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.777879186, 2: -3.330620019, 3: -3.8615197347000003, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.6507603690000003, 2: -3.8243346129000004, 3: -3.783819384, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.6507603690000003, 2: -3.8243346129000004, 3: -3.783819384, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.6507603690000003, 2: -3.8243346129000004, 3: -3.783819384, 4: -3.9205949400900004}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3358756239, 2: -3.2523229800000006, 3: -3.746911239, 4: -3.284634699}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.29679350379, 2: -3.8336797280700003, 3: -3.771228096, 4: -3.5958214206990005}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.27151197, 3: -3.8313976419, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.27151197, 3: -3.8313976419, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.8770758927, 3: -3.8313976419, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.9763690194600003, 3: -3.8313976419, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.3198601500000002, 2: -3.9763690194600003, 3: -3.8313976419, 4: -3.9205949400900004}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.29679350379, 2: -3.8336797280700003, 3: -3.771228096, 4: -3.5958214206990005}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -2.744162168490001, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -3.340106496}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91267537209, 1: -3.8572145756999996, 2: -3.90086039619, 3: -4.3763466965408995, 4: -3.8413175067000003}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-4.345589382669 -3.7798104699000006 -3.3312186990000003 -3.27084858 -3.773751417 \n",
      "-3.779804565 -3.711030588 -3.337247358 -3.7126441980000005 -3.7119808080000007 \n",
      "-3.27151197 -3.1625685 -3.20287239 -3.284634699 -3.4524507068559007 \n",
      "-3.27143907 -3.229573329 -3.09909618 -3.0891888 -3.1828725899999997 \n",
      "-3.2228640900000003 -3.1558617 -3.0916603800000004 -2.89366238169 -3.8413175067000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.3929080448939, 2: -4.356844770573, 3: -4.57003042149735, 4: -4.345589382669}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.3929080448939, 2: -4.356844770573, 3: -4.57003042149735, 4: -4.345589382669}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.3929080448939, 2: -4.356844770573, 3: -4.57003042149735, 4: -4.85448633822879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -3.7798104699000006, 2: -3.88359194679, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.7851707340000003, 2: -3.96787408929, 3: -3.711030588, 4: -4.289641672599}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -3.779804565, 2: -3.9664499877900004, 3: -3.94241598297, 4: -3.7857152142900006}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.3185963700000003, 3: -3.27151197, 4: -3.717443457000001}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.3185963700000003, 3: -3.27151197, 4: -3.717443457000001}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.3185963700000003, 3: -3.8770758927, 4: -3.717443457000001}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.4179289479, 2: -3.1625685, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.579311079, 2: -3.84961750659, 3: -3.7589324490000005, 4: -3.3797035890000005}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.777879186, 2: -3.9217234320900003, 3: -3.8615197347000003, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.777879186, 2: -3.9217234320900003, 3: -3.8615197347000003, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.777879186, 2: -3.9217234320900003, 3: -3.8615197347000003, 4: -3.93689509578}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.779140356, 2: -3.3312186990000003, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.27084858, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.8994576507000005, 2: -3.8243346129000004, 3: -3.783819384, 4: -4.249175392899001}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.98102379858}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.779140356, 2: -3.8825092197, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.779140356, 2: -3.8825092197, 3: -3.7176638319000004, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.779140356, 2: -3.8825092197, 3: -3.7176638319000004, 4: -3.93749878068}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -4.283915823270001, 2: -3.88359194679, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.87775468899, 1: -4.283915823270001, 2: -3.88359194679, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4287567669809, 1: -4.283915823270001, 2: -3.88359194679, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.779140356, 2: -3.8825092197, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -3.777879186, 2: -3.9217234320900003, 3: -3.8615197347000003, 4: -4.310125298307001}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.579311079, 2: -3.84961750659, 3: -3.7589324490000005, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.579311079, 2: -3.84961750659, 3: -3.7589324490000005, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.579311079, 2: -3.84961750659, 3: -3.7589324490000005, 4: -3.9755302659900003}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.26251188, 1: -3.09909618, 2: -3.1765473381690006, 3: -3.6991544490000003, 4: -3.3379697970000004}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.300190931349, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.300190931349, 3: -3.24251208, 4: -3.0916603800000004}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.300190931349, 3: -3.24251208, 4: -3.7134109458000006}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.8239537599900006, 2: -3.3952410099000003, 3: -3.3251646600000004, 4: -3.1558617}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.8239537599900006, 2: -3.3952410099000003, 3: -3.3251646600000004, 4: -3.1558617}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19033359, 1: -3.8239537599900006, 2: -3.3952410099000003, 3: -3.3251646600000004, 4: -3.771834147}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -3.3813572049, 2: -3.229573329, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.26251188, 1: -3.7141545258000006, 2: -3.1765473381690006, 3: -3.6991544490000003, 4: -3.3379697970000004}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -3.4729637471127006, 2: -3.217945320459, 3: -3.0891888, 4: -3.3410476350000002}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.26251188, 1: -3.7141545258000006, 2: -3.7198976618169004, 3: -3.6991544490000003, 4: -3.3379697970000004}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.7681990137000003, 2: -3.84961750659, 3: -3.7589324490000005, 4: -4.196795000589}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.4179289479, 2: -3.8105834859, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.4179289479, 2: -3.8105834859, 3: -3.6572952690000005, 4: -3.325239999}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.4179289479, 2: -3.8105834859, 3: -3.6572952690000005, 4: -3.9259683990900003}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.31093206, 1: -3.3813572049, 2: -3.7959606768168905, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.9236478633900003, 2: -3.8105834859, 3: -3.6572952690000005, 4: -4.061119287708}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.793540122, 3: -3.97577064897, 4: -3.717443457000001}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.793540122, 3: -3.97577064897, 4: -3.717443457000001}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -3.793540122, 3: -3.97577064897, 4: -4.282873545870001}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.766305888, 1: -3.9236478633900003, 2: -3.8105834859, 3: -4.276858727070001, 4: -4.061119287708}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -3.7851707340000003, 2: -3.96787408929, 3: -4.3327447564499995, 4: -4.289641672599}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -3.9236478633900003, 2: -3.8105834859, 3: -4.276858727070001, 4: -4.061119287708}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.7681990137000003, 2: -3.84961750659, 3: -3.9693376440900003, 4: -4.196795000589}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -3.7141545258000006, 2: -3.7198976618169004, 3: -3.6991544490000003, 4: -3.3379697970000004}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -3.7141545258000006, 2: -3.7198976618169004, 3: -3.6991544490000003, 4: -3.3379697970000004}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -3.7141545258000006, 2: -3.7198976618169004, 3: -3.6991544490000003, 4: -3.9375525152700006}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.3813572049, 2: -3.7959606768168905, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8349877554900003, 1: -3.8239537599900006, 2: -3.3952410099000003, 3: -3.3251646600000004, 4: -3.8613536226}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2228640900000003, 1: -3.8498650516800006, 2: -3.7271363868000007, 3: -3.3251736600000004, 4: -3.7952584479000007}, Best action: 0, Actual action: 0\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.281981139, 2: -3.7924462647900006, 3: -3.27143907, 4: -3.379776489}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.281981139, 2: -3.7924462647900006, 3: -3.27143907, 4: -3.379776489}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.281981139, 2: -3.7924462647900006, 3: -3.8770095537, 4: -3.379776489}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -3.7271363868000007, 3: -3.3251736600000004, 4: -3.7952584479000007}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -3.7271363868000007, 3: -3.3251736600000004, 4: -3.7952584479000007}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -3.7271363868000007, 3: -3.9259080306000005, 4: -3.7952584479000007}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8349877554900003, 1: -3.8239537599900006, 2: -3.3952410099000003, 3: -3.8430363789, 4: -3.8613536226}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.300190931349, 3: -3.780499185, 4: -3.89777587938}, Best action: 2, Actual action: 2\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.89366238169, 1: -3.1004707896900006, 2: -2.9627220058470005, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -3.4729637471127006, 2: -3.217945320459, 3: -3.8515535028, 4: -3.3410476350000002}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.1845900996900003, 3: -3.1828725899999997, 4: -3.340106496}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22197948, 1: -3.4729637471127006, 2: -3.7999213299459, 3: -3.8515535028, 4: -3.3410476350000002}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3358756239, 2: -3.8344983309000003, 3: -3.746911239, 4: -3.284634699}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3358756239, 2: -3.8344983309000003, 3: -3.746911239, 4: -3.284634699}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3358756239, 2: -3.8344983309000003, 3: -3.746911239, 4: -3.88901757609}, Best action: 1, Actual action: 1\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -3.4729637471127006, 2: -3.7999213299459, 3: -3.8515535028, 4: -3.3410476350000002}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -3.4729637471127006, 2: -3.7999213299459, 3: -3.8515535028, 4: -3.3410476350000002}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -3.4729637471127006, 2: -3.7999213299459, 3: -3.8515535028, 4: -3.94035334785}, Best action: 1, Actual action: 1\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -3.1004707896900006, 2: -2.9627220058470005, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 2, Actual action: 2\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91267537209, 1: -3.8572145756999996, 2: -3.90086039619, 3: -4.3763466965408995, 4: -4.804059150631891}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-4.3929080448939 -4.000143060297001 -3.8783510838900006 -3.7792125999 -3.773751417 \n",
      "-3.7857152142900006 -3.8744529723900003 -3.8615197347000003 -3.783819384 -3.7119808080000007 \n",
      "-3.8269242819000002 -3.9236478633900003 -3.84961750659 -3.746911239 -3.4524507068559007 \n",
      "-3.379776489 -3.3862187349000004 -3.7141545258000006 -3.6471011994473406 -3.1845900996900003 \n",
      "-3.7952584479000007 -3.8239537599900006 -3.501687610269 -3.1004707896900006 -3.8572145756999996 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -3.9279051522, 2: -3.9664499877900004, 3: -3.94241598297, 4: -3.7857152142900006}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -3.9279051522, 2: -3.9664499877900004, 3: -3.94241598297, 4: -3.7857152142900006}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -3.9279051522, 2: -3.9664499877900004, 3: -3.94241598297, 4: -4.3450008450039}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -3.8269242819000002, 2: -4.33006178148, 3: -3.97577064897, 4: -4.401054853407}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.9215887785000003, 2: -3.7924462647900006, 3: -3.94610567796, 4: -3.379776489}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.9215887785000003, 2: -3.7924462647900006, 3: -3.94610567796, 4: -3.379776489}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.9215887785000003, 2: -3.7924462647900006, 3: -3.94610567796, 4: -3.9755966049900002}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.9315190950900005, 2: -3.7959606768168905, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.9315190950900005, 2: -3.7959606768168905, 3: -3.7583281080000006, 4: -3.3862187349000004}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.9315190950900005, 2: -3.7959606768168905, 3: -3.7583281080000006, 4: -3.9814590487589996}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8213141868000005, 1: -3.9215887785000003, 2: -4.022081801748, 3: -3.94610567796, 4: -4.3694411349789}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8574970398, 1: -4.02031138428, 2: -4.33006178148, 3: -3.97577064897, 4: -4.401054853407}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -4.392599183559001, 2: -3.9664499877900004, 3: -3.94241598297, 4: -4.51610325778239}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -4.392599183559001, 2: -3.9664499877900004, 3: -3.94241598297, 4: -4.51610325778239}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -4.392599183559001, 2: -3.9664499877900004, 3: -4.487598544502701, 4: -4.51610325778239}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8744529723900003, 1: -4.365089696979, 2: -3.96787408929, 3: -4.3327447564499995, 4: -4.289641672599}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.283915823270001, 2: -4.349462883039, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.283915823270001, 2: -4.349462883039, 3: -4.78352838267459, 4: -4.000143060297001}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.283915823270001, 2: -4.349462883039, 3: -4.78352838267459, 4: -4.540130184870271}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.365089696979, 2: -3.96787408929, 3: -4.3327447564499995, 4: -4.289641672599}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.01534782569, 2: -3.9217234320900003, 3: -3.8615197347000003, 4: -4.310125298307001}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.365089696979, 2: -4.424618394036, 3: -4.3327447564499995, 4: -4.289641672599}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.365089696979, 2: -4.424618394036, 3: -4.3327447564499995, 4: -4.289641672599}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.365089696979, 2: -4.424618394036, 3: -4.3327447564499995, 4: -4.80357392206509}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3428106628280005, 1: -4.392599183559001, 2: -4.4349519064149, 3: -4.5615843445601705, 4: -4.51610325778239}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.3929080448939, 2: -4.3973309576763, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.392599183559001, 2: -4.4349519064149, 3: -4.5615843445601705, 4: -4.51610325778239}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.02031138428, 2: -4.33006178148, 3: -3.97577064897, 4: -4.401054853407}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.02031138428, 2: -4.33006178148, 3: -3.97577064897, 4: -4.401054853407}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.02031138428, 2: -4.33006178148, 3: -4.5179512905627, 4: -4.401054853407}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -3.9215887785000003, 2: -4.022081801748, 3: -3.94610567796, 4: -4.3694411349789}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -4.022858856699, 3: -4.311571276368001, 4: -3.7952584479000007}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -4.022858856699, 3: -4.311571276368001, 4: -3.7952584479000007}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -4.022858856699, 3: -4.311571276368001, 4: -4.353685187589001}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -3.8498650516800006, 2: -4.022858856699, 3: -4.311571276368001, 4: -4.453759210619701}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8721520557, 1: -4.403377197028801, 2: -4.022858856699, 3: -4.311571276368001, 4: -4.453759210619701}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.366318220649001, 2: -4.022081801748, 3: -3.94610567796, 4: -4.3694411349789}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.366318220649001, 2: -4.022081801748, 3: -3.94610567796, 4: -4.3694411349789}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.366318220649001, 2: -4.022081801748, 3: -4.4909561669436, 4: -4.3694411349789}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.9315190950900005, 2: -3.7959606768168905, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -3.7141545258000006, 2: -3.7198976618169004, 3: -4.008814780869, 4: -4.290070355217}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.5738856223038002, 3: -3.780499185, 4: -3.89777587938}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -3.501687610269, 2: -3.5738856223038002, 3: -3.780499185, 4: -3.89777587938}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -4.08653572534479, 2: -3.5738856223038002, 3: -3.780499185, 4: -3.89777587938}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -3.1004707896900006, 2: -3.4206160069017, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -3.1004707896900006, 2: -3.4206160069017, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -3.7214284186179003, 2: -3.4206160069017, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91267537209, 1: -4.3521507811449, 2: -3.90086039619, 3: -4.3763466965408995, 4: -4.804059150631891}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-4.3973309576763 -4.349462883039 -3.8783510838900006 -3.7792125999 -3.773751417 \n",
      "-4.4349519064149 -4.365089696979 -3.9217234320900003 -3.783819384 -3.7119808080000007 \n",
      "-4.33006178148 -3.9236478633900003 -3.84961750659 -3.746911239 -3.4524507068559007 \n",
      "-4.366318220649001 -3.9315190950900005 -3.7198976618169004 -3.6471011994473406 -3.1845900996900003 \n",
      "-4.022858856699 -3.8239537599900006 -3.6434960280000004 -3.444147780948 -3.90086039619 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.542369594651901, 2: -4.349462883039, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.337996176260001, 2: -3.8825092197, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.337996176260001, 2: -3.8825092197, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.429299486339901, 1: -4.337996176260001, 2: -3.8825092197, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -3.7792125999, 3: -3.97362315078, 4: -4.294417483548}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.7892509299000006, 2: -3.98985567255, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.7892509299000006, 2: -3.98985567255, 3: -3.7777293909000007, 4: -3.773751417}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.7892509299000006, 2: -3.98985567255, 3: -3.7777293909000007, 4: -4.33411378947}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -4.33465990776, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.2343266583800006, 2: -4.33465990776, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.434678318798901, 1: -4.2343266583800006, 2: -4.33465990776, 3: -3.97362315078, 4: -4.294417483548}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.337996176260001, 2: -4.349413127889, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.337996176260001, 2: -4.349413127889, 3: -4.4127476812719, 4: -4.3050575819070005}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.337996176260001, 2: -4.349413127889, 3: -4.4127476812719, 4: -4.817602399535371}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.01534782569, 2: -3.9217234320900003, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.8994576507000005, 2: -3.8243346129000004, 3: -3.783819384, 4: -4.249175392899001}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.01534782569, 2: -4.357066044249001, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.5103955976189, 2: -4.349413127889, 3: -4.4127476812719, 4: -4.895537142724137}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.2343266583800006, 2: -4.33465990776, 3: -4.784458956422671, 4: -4.294417483548}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.8994576507000005, 2: -3.8243346129000004, 3: -4.494638105686801, 4: -4.249175392899001}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.9023887530699, 2: -3.9763690194600003, 3: -3.8313976419, 4: -3.9811462155090003}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -3.7892509299000006, 2: -3.98985567255, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -3.9023887530699, 2: -3.9763690194600003, 3: -3.8313976419, 4: -3.9811462155090003}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.8994576507000005, 2: -4.2891379157700005, 3: -4.494638105686801, 4: -4.249175392899001}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.93983614674, 2: -3.8344983309000003, 3: -3.746911239, 4: -3.990961012968}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.9805754369400006, 2: -3.84961750659, 3: -3.9693376440900003, 4: -4.196795000589}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.93983614674, 2: -3.8344983309000003, 3: -4.3928813042379, 4: -3.990961012968}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -4.32494386866, 2: -4.2891379157700005, 3: -4.494638105686801, 4: -4.249175392899001}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.421143702287001, 2: -4.33465990776, 3: -4.784458956422671, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.421143702287001, 2: -4.33465990776, 3: -4.784458956422671, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.421143702287001, 2: -4.33465990776, 3: -4.784458956422671, 4: -4.80791991002868}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -4.382357182929001, 2: -3.98985567255, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9707082396900004, 1: -4.382357182929001, 2: -3.98985567255, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.513344498117901, 1: -4.382357182929001, 2: -3.98985567255, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.382357182929001, 2: -3.98985567255, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.382357182929001, 2: -4.5307686620205, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -3.9023887530699, 2: -3.9763690194600003, 3: -4.4417004612570015, 4: -3.9811462155090003}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.4524507068559007, 2: -3.8336797280700003, 3: -3.771228096, 4: -3.5958214206990005}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.1845900996900003, 3: -3.8280906378, 4: -3.340106496}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.1845900996900003, 3: -3.8280906378, 4: -3.340106496}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.7979769907179, 3: -3.8280906378, 4: -3.340106496}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.98528396083179, 3: -3.8280906378, 4: -3.340106496}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7152750447000003, 1: -3.3858833972760003, 2: -3.98528396083179, 3: -3.8280906378, 4: -3.93949691136}, Best action: 1, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.8247630514344904, 2: -3.8336797280700003, 3: -3.771228096, 4: -3.5958214206990005}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.8247630514344904, 2: -3.8336797280700003, 3: -3.771228096, 4: -3.5958214206990005}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.8247630514344904, 2: -3.8336797280700003, 3: -3.771228096, 4: -4.172197492836091}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -3.93983614674, 2: -3.8344983309000003, 3: -4.3928813042379, 4: -3.990961012968}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -3.8247630514344904, 2: -3.8336797280700003, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -3.3858833972760003, 2: -3.98528396083179, 3: -3.8280906378, 4: -4.303322477343}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91267537209, 1: -4.3521507811449, 2: -4.81315097488059, 3: -4.3763466965408995, 4: -4.804059150631891}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.3973309576763 -4.476410666254801 -4.4127476812719 -4.421143702287001 -4.393372185576 \n",
      "-4.4349519064149 -4.365089696979 -4.01534782569 -4.249175392899001 -3.9763690194600003 \n",
      "-4.33006178148 -3.9236478633900003 -3.9234575989800002 -3.93983614674 -3.8336797280700003 \n",
      "-4.366318220649001 -3.9315190950900005 -3.7198976618169004 -3.6471011994473406 -3.5078553911204997 \n",
      "-4.022858856699 -3.8239537599900006 -3.6434960280000004 -3.444147780948 -3.91267537209 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.89729614317218, 2: -4.3973309576763, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.542369594651901, 2: -4.476410666254801, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.5103955976189, 2: -4.7647459060767, 3: -4.4127476812719, 4: -4.895537142724137}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.542369594651901, 2: -4.921966688455719, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.488585153597991, 1: -4.542369594651901, 2: -4.921966688455719, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.984612489774172, 1: -4.542369594651901, 2: -4.921966688455719, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.365089696979, 2: -4.424618394036, 3: -4.850951112535681, 4: -4.889880644931009}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -3.9236478633900003, 2: -4.333299549687, 3: -4.276858727070001, 4: -4.061119287708}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -3.9315190950900005, 2: -4.28806123357969, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8349877554900003, 1: -3.8239537599900006, 2: -3.9126787553826903, 3: -3.8430363789, 4: -3.8613536226}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8349877554900003, 1: -3.8239537599900006, 2: -3.9126787553826903, 3: -3.8430363789, 4: -3.8613536226}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8349877554900003, 1: -4.3797979215909, 2: -3.9126787553826903, 3: -3.8430363789, 4: -3.8613536226}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.19350237389, 1: -4.390554455100901, 2: -4.28806123357969, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -4.4768952533619, 2: -4.333299549687, 3: -4.276858727070001, 4: -4.061119287708}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -4.4768952533619, 2: -4.333299549687, 3: -4.276858727070001, 4: -4.061119287708}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -4.4768952533619, 2: -4.333299549687, 3: -4.276858727070001, 4: -4.5956185518142805}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.478518049013, 2: -4.33006178148, 3: -4.6082473503230705, 4: -4.401054853407}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -4.4768952533619, 2: -4.333299549687, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9234575989800002, 1: -3.9805754369400006, 2: -4.336685162739, 3: -3.9693376440900003, 4: -4.196795000589}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -4.01534782569, 2: -4.357066044249001, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -3.9805754369400006, 2: -4.336685162739, 3: -3.9693376440900003, 4: -4.196795000589}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.34261888334, 1: -4.4768952533619, 2: -4.5113306101425, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.5146637390438, 2: -4.424618394036, 3: -4.850951112535681, 4: -4.889880644931009}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -4.5166982742819, 2: -4.357066044249001, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 4, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.32494386866, 2: -4.2891379157700005, 3: -4.494638105686801, 4: -4.249175392899001}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.32494386866, 2: -4.2891379157700005, 3: -4.494638105686801, 4: -4.249175392899001}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.32494386866, 2: -4.2891379157700005, 3: -4.494638105686801, 4: -4.766749607538091}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.0867239478602695, 2: -3.9763690194600003, 3: -4.4417004612570015, 4: -3.9811462155090003}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.0867239478602695, 2: -3.9763690194600003, 3: -4.4417004612570015, 4: -3.9811462155090003}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.0867239478602695, 2: -4.518495807708601, 3: -4.4417004612570015, 4: -3.9811462155090003}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.0867239478602695, 2: -4.57657801533315, 3: -4.4417004612570015, 4: -3.9811462155090003}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.0867239478602695, 2: -4.57657801533315, 3: -4.4417004612570015, 4: -4.5228430561131905}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -4.025041856937009, 2: -3.8336797280700003, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -4.025041856937009, 2: -3.8336797280700003, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8720563047, 1: -4.025041856937009, 2: -4.3886485525437, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.340491334019001, 1: -4.413952974522727, 2: -4.57657801533315, 3: -4.4417004612570015, 4: -4.662530703378137}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.4991706082795195, 2: -4.902786184374541, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.4991706082795195, 2: -4.902786184374541, 3: -4.4240250690099, 4: -4.393372185576}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.4991706082795195, 2: -4.902786184374541, 3: -4.4240250690099, 4: -4.89796868887416}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.421143702287001, 2: -4.549739664924901, 3: -4.784458956422671, 4: -4.891866516288468}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.32494386866, 2: -4.549772697339601, 3: -4.494638105686801, 4: -4.85087667252751}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -3.93983614674, 2: -4.381507904751937, 3: -4.3928813042379, 4: -3.990961012968}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -3.6471011994473406, 2: -3.7999213299459, 3: -3.8515535028, 4: -4.107135969946287}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -4.0428418074521675, 2: -3.5017585216040703, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -4.0428418074521675, 2: -3.5017585216040703, 3: -3.5328074959269005, 4: -3.444147780948}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -4.0428418074521675, 2: -3.5017585216040703, 3: -3.5328074959269005, 4: -4.03417448066268}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853105612926804, 1: -4.3521507811449, 2: -4.81315097488059, 3: -4.3763466965408995, 4: -4.804059150631891}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-4.54073176107549 -4.78352838267459 -4.48776241659099 -4.549739664924901 -4.4991706082795195 \n",
      "-4.4349519064149 -4.5146637390438 -4.310125298307001 -4.494638105686801 -4.413952974522727 \n",
      "-4.401054853407 -4.4768952533619 -3.9805754369400006 -3.990961012968 -4.025041856937009 \n",
      "-4.366318220649001 -4.28806123357969 -3.7198976618169004 -3.7999213299459 -3.5078553911204997 \n",
      "-4.022858856699 -3.8430363789 -3.6434960280000004 -3.5328074959269005 -4.3521507811449 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.559634144021601, 2: -4.4349519064149, 3: -4.5615843445601705, 4: -4.51610325778239}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.5146637390438, 2: -4.8716853352452905, 3: -4.850951112535681, 4: -4.889880644931009}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.4768952533619, 2: -4.5113306101425, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.28806123357969, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -4.10778241689789, 2: -3.7198976618169004, 3: -4.008814780869, 4: -4.290070355217}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -4.054469822512614, 2: -3.7999213299459, 3: -3.8515535028, 4: -4.107135969946287}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -3.5078553911204997, 2: -3.98528396083179, 3: -3.8280906378, 4: -4.303322477343}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853105612926804, 1: -4.927526122310558, 2: -4.81315097488059, 3: -4.3763466965408995, 4: -4.804059150631891}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-4.54073176107549 -4.78352838267459 -4.48776241659099 -4.549739664924901 -4.4991706082795195 \n",
      "-4.51610325778239 -4.527561176079571 -4.310125298307001 -4.494638105686801 -4.413952974522727 \n",
      "-4.401054853407 -4.5113306101425 -3.9805754369400006 -3.990961012968 -4.025041856937009 \n",
      "-4.366318220649001 -4.341923229429659 -4.008814780869 -3.8515535028 -3.8280906378 \n",
      "-4.022858856699 -3.8430363789 -3.6434960280000004 -3.5328074959269005 -4.3763466965408995 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.89729614317218, 2: -4.965625735434019, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.54073176107549, 1: -4.89729614317218, 2: -4.965625735434019, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.032065902578696, 1: -4.89729614317218, 2: -4.965625735434019, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -4.89729614317218, 2: -4.965625735434019, 3: -4.57003042149735, 4: -4.914492897987008}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -4.89729614317218, 2: -4.965625735434019, 3: -5.058727683562589, 4: -4.914492897987008}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.559634144021601, 2: -5.000372819266968, 3: -4.5615843445601705, 4: -4.51610325778239}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.559634144021601, 2: -5.000372819266968, 3: -4.5615843445601705, 4: -4.51610325778239}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.559634144021601, 2: -5.000372819266968, 3: -4.5615843445601705, 4: -5.009653964581975}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.478518049013, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -4.401054853407}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.478518049013, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -4.401054853407}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.478518049013, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -4.904959916600371}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.366318220649001, 2: -4.376936328396481, 3: -4.60698187611024, 4: -4.3694411349789}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.022858856699, 3: -4.311571276368001, 4: -4.453759210619701}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -3.9126787553826903, 3: -3.8430363789, 4: -3.8613536226}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.415145352578899, 3: -4.311571276368001, 4: -4.453759210619701}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.415145352578899, 3: -4.311571276368001, 4: -4.453759210619701}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.415145352578899, 3: -4.823529861494881, 4: -4.453759210619701}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -3.9126787553826903, 3: -4.776676371748081, 4: -3.8613536226}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -3.9126787553826903, 3: -4.776676371748081, 4: -3.8613536226}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -3.9126787553826903, 3: -4.776676371748081, 4: -4.413831796566}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6434960280000004, 1: -4.203500926600557, 2: -3.7687699018792804, 3: -3.780499185, 4: -3.89777587938}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -4.10778241689789, 2: -4.349926043437869, 3: -4.008814780869, 4: -4.290070355217}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.341923229429659, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -4.10778241689789, 2: -4.349926043437869, 3: -4.817839293924924, 4: -4.290070355217}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -3.7687699018792804, 3: -3.780499185, 4: -3.89777587938}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -4.0428418074521675, 2: -3.875417984887776, 3: -3.5328074959269005, 4: -4.139841850565565}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.138451061888717, 3: -3.780499185, 4: -3.89777587938}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -4.24249965821827, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.138451061888717, 3: -4.714474641656798, 4: -3.89777587938}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.138451061888717, 3: -4.714474641656798, 4: -3.89777587938}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.138451061888717, 3: -4.714474641656798, 4: -4.4469760502358}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79590194774079, 1: -4.0428418074521675, 2: -3.875417984887776, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -4.054469822512614, 2: -4.121354999802194, 3: -3.8515535028, 4: -4.107135969946287}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2709864716900015, 1: -4.363481862212006, 2: -4.349926043437869, 3: -4.817839293924924, 4: -4.290070355217}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -3.9805754369400006, 2: -4.336685162739, 3: -4.8144550599144, 4: -4.196795000589}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.363481862212006, 2: -4.349926043437869, 3: -4.817839293924924, 4: -4.290070355217}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.363481862212006, 2: -4.349926043437869, 3: -4.817839293924924, 4: -4.290070355217}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.363481862212006, 2: -4.349926043437869, 3: -4.817839293924924, 4: -4.80396402324747}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.88275205419, 1: -4.054469822512614, 2: -4.121354999802194, 3: -4.7446543923489015, 4: -4.107135969946287}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.248135586226346, 2: -4.381507904751937, 3: -4.3928813042379, 4: -3.990961012968}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.248135586226346, 2: -4.381507904751937, 3: -4.3928813042379, 4: -3.990961012968}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.248135586226346, 2: -4.381507904751937, 3: -4.3928813042379, 4: -4.53177452180088}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.054469822512614, 2: -4.121354999802194, 3: -4.7446543923489015, 4: -4.107135969946287}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.0428418074521675, 2: -3.875417984887776, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853105612926804, 1: -4.927526122310558, 2: -4.81315097488059, 3: -5.015627396125237, 4: -4.804059150631891}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-4.914492897987008 -4.78352838267459 -4.48776241659099 -4.549739664924901 -4.4991706082795195 \n",
      "-4.5615843445601705 -4.527561176079571 -4.310125298307001 -4.494638105686801 -4.413952974522727 \n",
      "-4.479106650185701 -4.5113306101425 -4.196795000589 -4.381507904751937 -4.025041856937009 \n",
      "-4.3694411349789 -4.3423916723559 -4.363481862212006 -4.107135969946287 -3.8280906378 \n",
      "-4.453759210619701 -4.44431987410599 -4.203500926600557 -4.0428418074521675 -4.804059150631891 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.047773253120955, 2: -4.965625735434019, 3: -5.3726826443257245, 4: -4.914492897987008}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.047773253120955, 2: -4.965625735434019, 3: -5.3726826443257245, 4: -4.914492897987008}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.047773253120955, 2: -4.965625735434019, 3: -5.3726826443257245, 4: -5.372188537168178}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -4.88995961401818, 2: -4.921966688455719, 3: -4.78352838267459, 4: -4.823984835335729}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.047773253120955, 2: -5.27122056350982, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.920817845661831, 2: -5.000372819266968, 3: -4.5615843445601705, 4: -5.094269053115694}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.920817845661831, 2: -5.000372819266968, 3: -4.5615843445601705, 4: -5.094269053115694}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.892536582646859, 1: -4.920817845661831, 2: -5.000372819266968, 3: -5.051041753549755, 4: -5.094269053115694}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.099660644405834, 2: -5.27122056350982, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -4.920817845661831, 2: -5.000372819266968, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.479106650185701, 1: -4.884569563626991, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -5.018095611360567}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.0201581712166, 2: -5.000372819266968, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.527561176079571, 1: -4.977751529127519, 2: -4.8716853352452905, 3: -4.850951112535681, 4: -4.889880644931009}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -4.88995961401818, 2: -4.921966688455719, 3: -5.4670491732954325, 4: -4.823984835335729}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -4.88995961401818, 2: -4.921966688455719, 3: -5.4670491732954325, 4: -4.823984835335729}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -4.88995961401818, 2: -4.921966688455719, 3: -5.4670491732954325, 4: -5.289826200155513}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -4.977751529127519, 2: -4.8716853352452905, 3: -4.850951112535681, 4: -4.889880644931009}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.0201581712166, 2: -5.067361834551149, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -4.884569563626991, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -5.018095611360567}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -4.884569563626991, 2: -4.8429788133944704, 3: -4.6082473503230705, 4: -5.018095611360567}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -4.884569563626991, 2: -4.8429788133944704, 3: -5.093505088793995, 4: -5.018095611360567}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.821019124535739, 2: -4.5113306101425, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -4.77301453141977, 2: -4.336685162739, 3: -4.8144550599144, 4: -4.196795000589}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -4.77301453141977, 2: -4.336685162739, 3: -4.8144550599144, 4: -4.196795000589}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -4.77301453141977, 2: -4.336685162739, 3: -4.8144550599144, 4: -4.719083450535989}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.608934114857852, 2: -4.381507904751937, 3: -4.3928813042379, 4: -4.794167277023428}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.025041856937009, 2: -4.475230462061369, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -3.8956263633101784, 2: -3.98528396083179, 3: -3.8280906378, 4: -4.303322477343}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.44453555001036, 2: -4.121354999802194, 3: -4.7446543923489015, 4: -4.107135969946287}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.44453555001036, 2: -4.121354999802194, 3: -4.7446543923489015, 4: -4.107135969946287}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.44453555001036, 2: -4.121354999802194, 3: -4.7446543923489015, 4: -4.637493732651122}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -3.8956263633101784, 2: -3.98528396083179, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853105612926804, 1: -4.927526122310558, 2: -4.81315097488059, 3: -5.015627396125237, 4: -5.361145162432666}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.104931231670723 -4.921966688455719 -4.48776241659099 -4.549739664924901 -4.4991706082795195 \n",
      "-5.067361834551149 -4.8716853352452905 -4.310125298307001 -4.494638105686801 -4.413952974522727 \n",
      "-4.884569563626991 -4.750537011491339 -4.5447774987069005 -4.3928813042379 -4.371914507043609 \n",
      "-4.3694411349789 -4.3423916723559 -4.363481862212006 -4.44453555001036 -3.98528396083179 \n",
      "-4.453759210619701 -4.44431987410599 -4.203500926600557 -4.0428418074521675 -4.81315097488059 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -5.31826636255572, 2: -4.921966688455719, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.5103955976189, 2: -4.7647459060767, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.48776241659099, 1: -4.5103955976189, 2: -4.7647459060767, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.983863799097802, 1: -4.5103955976189, 2: -4.7647459060767, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -4.5166982742819, 2: -4.777538672673091, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -4.5166982742819, 2: -4.777538672673091, 3: -4.76076172827519, 4: -4.310125298307001}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -4.5166982742819, 2: -4.777538672673091, 3: -4.76076172827519, 4: -4.82221402145937}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5447774987069005, 1: -4.77301453141977, 2: -4.882689919122969, 3: -4.8144550599144, 4: -4.884623326872189}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -5.03293960138078, 2: -4.777538672673091, 3: -4.76076172827519, 4: -5.040747004314277}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -4.977751529127519, 2: -4.8716853352452905, 3: -5.451423229939014, 4: -4.889880644931009}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -5.03293960138078, 2: -4.777538672673091, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.5237616657254005, 2: -4.549772697339601, 3: -4.494638105686801, 4: -4.85087667252751}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.82009329621809, 1: -5.03293960138078, 2: -5.018410732873617, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -4.842241051390561, 2: -4.7647459060767, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.8453189038433, 2: -4.549739664924901, 3: -4.784458956422671, 4: -4.891866516288468}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.4991706082795195, 2: -4.902786184374541, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.413952974522727, 2: -4.57657801533315, 3: -4.4417004612570015, 4: -4.662530703378137}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.403257602311701, 2: -4.475230462061369, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.403257602311701, 2: -4.475230462061369, 3: -4.383066457629001, 4: -4.371914507043609}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.403257602311701, 2: -4.475230462061369, 3: -4.383066457629001, 4: -4.878442201409684}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.608934114857852, 2: -4.598434694594172, 3: -4.3928813042379, 4: -4.794167277023428}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.77301453141977, 2: -4.882689919122969, 3: -4.8144550599144, 4: -4.884623326872189}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.363481862212006, 2: -4.4800217682376875, 3: -4.817839293924924, 4: -4.903836497509421}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.388525683858912, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.203500926600557, 2: -4.388525683858912, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.725185843206507, 2: -4.388525683858912, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.0428418074521675, 2: -4.2788297105006095, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.0428418074521675, 2: -4.2788297105006095, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.578986044781472, 2: -4.2788297105006095, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.711170503436255, 2: -4.2788297105006095, 3: -4.3154850894426895, 4: -4.139841850565565}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.711170503436255, 2: -4.2788297105006095, 3: -4.3154850894426895, 4: -4.667256084014665}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853105612926804, 1: -4.927526122310558, 2: -5.368108115137192, 3: -5.015627396125237, 4: -5.361145162432666}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.104931231670723 -5.027284226284275 -4.842241051390561 -4.56210258401169 -4.5831175445772905 \n",
      "-5.067361834551149 -4.889880644931009 -5.018410732873617 -4.5237616657254005 -4.4417004612570015 \n",
      "-4.884569563626991 -4.750537011491339 -4.8144550599144 -4.5278644582098 -4.403257602311701 \n",
      "-4.3694411349789 -4.3423916723559 -4.4800217682376875 -4.44453555001036 -3.98528396083179 \n",
      "-4.453759210619701 -4.44431987410599 -4.51148957530389 -4.3154850894426895 -4.853105612926804 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.395828519426666, 2: -5.27122056350982, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.104931231670723, 1: -5.395828519426666, 2: -5.27122056350982, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.545487420820358, 1: -5.395828519426666, 2: -5.27122056350982, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -5.31826636255572, 2: -5.027284226284275, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -4.842241051390561, 2: -5.061763719196839, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.03293960138078, 2: -5.018410732873617, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.5237616657254005, 2: -4.549772697339601, 3: -5.253739380505333, 4: -4.85087667252751}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5278644582098, 1: -4.608934114857852, 2: -4.598434694594172, 3: -5.205429900873804, 4: -4.794167277023428}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -5.019946377722478, 2: -4.549772697339601, 3: -5.253739380505333, 4: -4.85087667252751}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -4.57657801533315, 3: -4.4417004612570015, 4: -4.662530703378137}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -5.019946377722478, 2: -4.952754643352131, 3: -5.253739380505333, 4: -4.85087667252751}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.8453189038433, 2: -4.999302159198901, 3: -4.784458956422671, 4: -4.891866516288468}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.8453189038433, 2: -4.999302159198901, 3: -4.784458956422671, 4: -4.891866516288468}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051513351450638, 1: -4.8453189038433, 2: -4.999302159198901, 3: -4.784458956422671, 4: -4.891866516288468}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -5.449136798766686, 2: -5.061763719196839, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -5.449136798766686, 2: -5.061763719196839, 3: -4.977028742541563, 4: -4.895537142724137}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -5.449136798766686, 2: -5.061763719196839, 3: -4.977028742541563, 4: -5.3549387998789655}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -5.31826636255572, 2: -5.324943674254782, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.077780620645457, 1: -5.31826636255572, 2: -5.324943674254782, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.520780364787367, 1: -5.31826636255572, 2: -5.324943674254782, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -4.977751529127519, 2: -5.256974858389733, 3: -5.451423229939014, 4: -4.889880644931009}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -4.977751529127519, 2: -5.256974858389733, 3: -5.451423229939014, 4: -4.889880644931009}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -4.977751529127519, 2: -5.256974858389733, 3: -5.451423229939014, 4: -5.349791386887218}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.821019124535739, 2: -4.750537011491339, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.911721761533703, 2: -4.882689919122969, 3: -4.8144550599144, 4: -4.884623326872189}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.821019124535739, 2: -5.274762299679798, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.661496080630257, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.661496080630257, 3: -4.371097302108001, 4: -4.3423916723559}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.661496080630257, 3: -4.371097302108001, 4: -4.851576421843869}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.59514749599109, 2: -4.376936328396481, 3: -4.60698187611024, 4: -4.3694411349789}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.59514749599109, 2: -4.376936328396481, 3: -4.60698187611024, 4: -4.3694411349789}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.59514749599109, 2: -4.376936328396481, 3: -4.60698187611024, 4: -4.876191432830799}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.390554455100901, 2: -4.661496080630257, 3: -4.876357049543709, 4: -4.925746456891868}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -4.481448428119627, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.44431987410599, 2: -4.481448428119627, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -4.944331085436452, 2: -4.481448428119627, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51148957530389, 1: -4.92722438824637, 2: -4.613554432422147, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.741183936767652, 2: -4.4800217682376875, 3: -4.817839293924924, 4: -4.903836497509421}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.44453555001036, 2: -4.467592854261464, 3: -4.7446543923489015, 4: -4.70204692310489}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.711170503436255, 2: -4.358898517520772, 3: -4.3154850894426895, 4: -4.832577673906961}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.613554432422147, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.711170503436255, 2: -4.358898517520772, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -4.927526122310558, 2: -5.368108115137192, 3: -5.015627396125237, 4: -5.361145162432666}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.3726826443257245 -5.324943674254782 -5.05180681398109 -4.8453189038433 -4.5831175445772905 \n",
      "-5.067361834551149 -5.245710132220737 -5.03293960138078 -4.85087667252751 -4.57657801533315 \n",
      "-4.884569563626991 -4.823817424108129 -4.882689919122969 -4.598434694594172 -4.403257602311701 \n",
      "-4.406704020918 -4.60885686043248 -4.551364751090401 -4.467592854261464 -3.98528396083179 \n",
      "-4.453759210619701 -4.510652971516579 -4.69684296515344 -4.3993485320420795 -4.927526122310558 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.134696170883347, 2: -5.067361834551149, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -5.245710132220737, 2: -5.256974858389733, 3: -5.451423229939014, 4: -5.466957877282012}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.8994391670618525, 2: -5.274762299679798, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.8994391670618525, 2: -5.274762299679798, 3: -4.8350359157058005, 4: -4.823817424108129}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.8994391670618525, 2: -5.274762299679798, 3: -4.8350359157058005, 4: -5.289673855938397}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -4.884569563626991, 2: -5.0384756755548725, 3: -5.332163347728921, 4: -5.018095611360567}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.406704020918, 1: -4.59514749599109, 2: -4.894042741471378, 3: -4.60698187611024, 4: -4.93293756928423}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -4.95788721330628, 2: -5.0384756755548725, 3: -5.332163347728921, 4: -5.018095611360567}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.59514749599109, 2: -4.894042741471378, 3: -4.60698187611024, 4: -4.93293756928423}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.46921096956389, 3: -4.958620721738396, 4: -4.453759210619701}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.46921096956389, 3: -4.958620721738396, 4: -4.453759210619701}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -4.46921096956389, 3: -4.958620721738396, 4: -4.952920881663928}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -5.024406335320544, 2: -5.002451398808113, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -5.024406335320544, 2: -5.002451398808113, 3: -4.776676371748081, 4: -4.510652971516579}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.680235698399899, 1: -5.024406335320544, 2: -5.002451398808113, 3: -4.776676371748081, 4: -5.004694204080087}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.60885686043248, 1: -4.938954543535943, 2: -4.661496080630257, 3: -4.876357049543709, 4: -4.925746456891868}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -4.8994391670618525, 2: -5.274762299679798, 3: -5.340004938108444, 4: -5.345346477315538}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -4.938954543535943, 2: -4.661496080630257, 3: -4.876357049543709, 4: -4.925746456891868}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.551364751090401, 1: -4.741183936767652, 2: -4.948075972332161, 3: -4.817839293924924, 4: -4.903836497509421}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.911721761533703, 2: -4.882689919122969, 3: -5.286470996865388, 4: -4.884623326872189}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -4.608934114857852, 2: -4.598434694594172, 3: -5.205429900873804, 4: -4.794167277023428}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.403257602311701, 2: -4.475230462061369, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -4.288214925984295, 2: -3.98528396083179, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -4.288214925984295, 2: -3.98528396083179, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.184142855236191, 1: -4.288214925984295, 2: -4.526608404356929, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.5684057685049195, 2: -4.475230462061369, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.5684057685049195, 2: -4.475230462061369, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.5684057685049195, 2: -4.972459720475846, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.288214925984295, 2: -4.741816553177007, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -5.497315698217486, 2: -5.368108115137192, 3: -5.015627396125237, 4: -5.361145162432666}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-5.3726826443257245 -5.324943674254782 -5.05180681398109 -4.8453189038433 -4.5831175445772905 \n",
      "-5.094269053115694 -5.256974858389733 -5.03293960138078 -4.85087667252751 -4.57657801533315 \n",
      "-5.018095611360567 -4.91820278750316 -4.884623326872189 -4.608934114857852 -4.803003611025391 \n",
      "-4.60698187611024 -4.876357049543709 -4.741183936767652 -4.467592854261464 -4.303322477343 \n",
      "-4.476780884819879 -4.776676371748081 -4.69684296515344 -4.3993485320420795 -5.015627396125237 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.395828519426666, 2: -5.499222279641244, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.395828519426666, 2: -5.499222279641244, 3: -5.3726826443257245, 4: -5.459375699418373}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.395828519426666, 2: -5.499222279641244, 3: -5.78914120633641, 4: -5.459375699418373}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.134696170883347, 2: -5.655761390553912, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.134696170883347, 2: -5.655761390553912, 3: -5.368058807298931, 4: -5.094269053115694}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.134696170883347, 2: -5.655761390553912, 3: -5.368058807298931, 4: -5.535784838335282}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.1178581930834115, 2: -5.0384756755548725, 3: -5.332163347728921, 4: -5.018095611360567}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.1178581930834115, 2: -5.0384756755548725, 3: -5.332163347728921, 4: -5.018095611360567}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.1178581930834115, 2: -5.0384756755548725, 3: -5.332163347728921, 4: -5.466467006338116}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.91820278750316, 1: -5.165755742016693, 2: -5.274762299679798, 3: -5.340004938108444, 4: -5.345346477315538}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -5.331863126749658, 2: -5.256974858389733, 3: -5.451423229939014, 4: -5.466957877282012}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.03293960138078, 2: -5.066088022524936, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.911721761533703, 2: -5.113001094533576, 3: -5.286470996865388, 4: -4.884623326872189}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.911721761533703, 2: -5.113001094533576, 3: -5.286470996865388, 4: -4.884623326872189}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -4.911721761533703, 2: -5.113001094533576, 3: -5.286470996865388, 4: -5.345007227453693}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -4.741183936767652, 2: -4.948075972332161, 3: -4.817839293924924, 4: -4.903836497509421}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.89206324243404, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.89206324243404, 3: -4.714474641656798, 4: -4.69684296515344}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.89206324243404, 3: -4.714474641656798, 4: -5.174127098289631}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.024406335320544, 2: -5.002451398808113, 3: -4.776676371748081, 4: -5.191460336111927}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -5.000550003884817, 3: -4.958620721738396, 4: -5.015352973513144}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.476780884819879, 2: -5.000550003884817, 3: -4.958620721738396, 4: -5.015352973513144}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4835608047176, 1: -4.97387060518609, 2: -5.000550003884817, 3: -4.958620721738396, 4: -5.015352973513144}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -4.894042741471378, 3: -4.60698187611024, 4: -4.93293756928423}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -4.894042741471378, 3: -4.60698187611024, 4: -4.93293756928423}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -4.894042741471378, 3: -5.092353507260318, 4: -4.93293756928423}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -4.938954543535943, 2: -5.052755056446251, 3: -4.876357049543709, 4: -4.925746456891868}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -5.339253484277543, 3: -5.373409971317849, 4: -4.93293756928423}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -5.339253484277543, 3: -5.373409971317849, 4: -4.93293756928423}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -4.967059710201067, 2: -5.339253484277543, 3: -5.373409971317849, 4: -5.38897318804865}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.000550003884817, 3: -4.958620721738396, 4: -5.015352973513144}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.000550003884817, 3: -4.958620721738396, 4: -5.015352973513144}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.000550003884817, 3: -5.4123448567819405, 4: -5.015352973513144}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.024406335320544, 2: -5.002451398808113, 3: -5.003860153878911, 4: -5.191460336111927}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.89206324243404, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3993485320420795, 1: -4.711170503436255, 2: -4.42718601082363, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.839996477449615, 2: -4.467592854261464, 3: -4.7446543923489015, 4: -4.70204692310489}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.491479683459871, 2: -4.741816553177007, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.491479683459871, 2: -4.741816553177007, 3: -4.609589199436493, 4: -4.303322477343}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.491479683459871, 2: -4.741816553177007, 3: -4.609589199436493, 4: -4.81602345438213}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -5.497315698217486, 2: -5.368108115137192, 3: -5.753435681516361, 4: -5.361145162432666}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.459375699418373 -5.324943674254782 -5.05180681398109 -4.8453189038433 -4.5831175445772905 \n",
      "-5.368058807298931 -5.260183834229897 -5.040747004314277 -4.85087667252751 -4.57657801533315 \n",
      "-5.1178581930834115 -5.165755742016693 -5.113001094533576 -4.608934114857852 -4.803003611025391 \n",
      "-5.339253484277543 -4.925746456891868 -4.817839293924924 -4.52095362592308 -4.609589199436493 \n",
      "-5.015352973513144 -5.003860153878911 -4.92722438824637 -4.42718601082363 -5.361145162432666 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.5659407849663785, 2: -5.499222279641244, 3: -5.849535221369241, 4: -5.459375699418373}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.5659407849663785, 2: -5.499222279641244, 3: -5.849535221369241, 4: -5.459375699418373}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.5659407849663785, 2: -5.499222279641244, 3: -5.849535221369241, 4: -5.868031886470719}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.39262995864969, 2: -5.324943674254782, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -5.449136798766686, 2: -5.061763719196839, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.05180681398109, 1: -5.449136798766686, 2: -5.061763719196839, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.497144200722792, 1: -5.449136798766686, 2: -5.061763719196839, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -4.8453189038433, 2: -4.999302159198901, 3: -5.343830981248819, 4: -4.891866516288468}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.073288050962657, 1: -5.019946377722478, 2: -4.952754643352131, 3: -5.253739380505333, 4: -4.85087667252751}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.073288050962657, 1: -5.019946377722478, 2: -4.952754643352131, 3: -5.253739380505333, 4: -4.85087667252751}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.073288050962657, 1: -5.019946377722478, 2: -4.952754643352131, 3: -5.253739380505333, 4: -5.3142977720000335}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -4.57657801533315, 3: -5.215848205222523, 4: -4.662530703378137}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -4.57657801533315, 3: -5.215848205222523, 4: -4.662530703378137}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -5.064685993953168, 3: -5.215848205222523, 4: -4.662530703378137}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -5.183118469131608, 3: -5.215848205222523, 4: -4.662530703378137}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -4.8826460481575955, 2: -5.183118469131608, 3: -5.215848205222523, 4: -5.142902940074105}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803003611025391, 1: -4.830294666897772, 2: -5.09765464453657, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89268060371846, 1: -5.278697529746326, 2: -5.183118469131608, 3: -5.215848205222523, 4: -5.369233593015063}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.92521897019136, 2: -4.902786184374541, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5831175445772905, 1: -4.92521897019136, 2: -4.902786184374541, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.070636965565334, 1: -4.92521897019136, 2: -4.902786184374541, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -4.92521897019136, 2: -4.902786184374541, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -4.92521897019136, 2: -5.361535427780833, 3: -4.923528905753462, 4: -4.973257174785435}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -5.313741995131613, 2: -4.999302159198901, 3: -5.343830981248819, 4: -4.891866516288468}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -5.313741995131613, 2: -4.999302159198901, 3: -5.343830981248819, 4: -4.891866516288468}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -5.313741995131613, 2: -4.999302159198901, 3: -5.343830981248819, 4: -5.351598529822506}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -4.92521897019136, 2: -5.424211956438387, 3: -5.354764768769005, 4: -4.973257174785435}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101593271479451, 1: -5.278697529746326, 2: -5.183118469131608, 3: -5.215848205222523, 4: -5.369233593015063}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.354764768769005, 4: -4.973257174785435}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.354764768769005, 4: -4.973257174785435}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.354764768769005, 4: -5.425664029054746}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -5.313741995131613, 2: -5.389357581774892, 3: -5.343830981248819, 4: -5.4845946019333605}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.280563089847427, 1: -5.313741995131613, 2: -5.389357581774892, 3: -5.343830981248819, 4: -5.4845946019333605}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705312411761159, 1: -5.313741995131613, 2: -5.389357581774892, 3: -5.343830981248819, 4: -5.4845946019333605}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.073288050962657, 1: -5.019946377722478, 2: -5.1023036567550655, 3: -5.253739380505333, 4: -5.443161038315229}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -4.608934114857852, 2: -4.926482127331895, 3: -5.205429900873804, 4: -4.794167277023428}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52095362592308, 1: -4.839996477449615, 2: -4.832450492073976, 3: -4.7446543923489015, 4: -4.70204692310489}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -5.02286584848348, 2: -4.926482127331895, 3: -5.205429900873804, 4: -4.794167277023428}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -5.02286584848348, 2: -4.926482127331895, 3: -5.205429900873804, 4: -4.794167277023428}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -5.02286584848348, 2: -4.926482127331895, 3: -5.205429900873804, 4: -5.26269222209132}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -4.830294666897772, 2: -5.09765464453657, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.791675549916447, 2: -4.741816553177007, 3: -4.609589199436493, 4: -5.019700889040708}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.839996477449615, 2: -4.832450492073976, 3: -4.7446543923489015, 4: -4.70204692310489}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.839996477449615, 2: -4.832450492073976, 3: -4.7446543923489015, 4: -4.70204692310489}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.839996477449615, 2: -4.832450492073976, 3: -4.7446543923489015, 4: -5.17886270002545}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.178561195451052, 2: -4.948075972332161, 3: -4.817839293924924, 4: -4.903836497509421}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -4.938954543535943, 2: -5.052755056446251, 3: -5.383315136074598, 4: -4.925746456891868}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -4.938954543535943, 2: -5.052755056446251, 3: -5.383315136074598, 4: -4.925746456891868}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -4.938954543535943, 2: -5.052755056446251, 3: -5.383315136074598, 4: -5.3824292757715995}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.024406335320544, 2: -5.362816366252384, 3: -5.003860153878911, 4: -5.191460336111927}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.015352973513144}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.015352973513144}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.463971205896962}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.029071312339865, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.519944883584987}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080011400121054, 1: -5.476454894229277, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.519944883584987}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -5.413188755628208, 2: -5.339253484277543, 3: -5.373409971317849, 4: -5.462215684067729}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -5.447022178995512, 2: -5.052755056446251, 3: -5.383315136074598, 4: -5.4387961078412745}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.178561195451052, 2: -4.948075972332161, 3: -5.371638559474905, 4: -4.903836497509421}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.178561195451052, 2: -4.948075972332161, 3: -5.371638559474905, 4: -4.903836497509421}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.178561195451052, 2: -4.948075972332161, 3: -5.371638559474905, 4: -5.362491212733573}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.839996477449615, 2: -4.832450492073976, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.791675549916447, 2: -4.741816553177007, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 2, Actual action: 2\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.791675549916447, 2: -4.741816553177007, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.791675549916447, 2: -5.215053063391077, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -5.497315698217486, 2: -5.368108115137192, 3: -5.753435681516361, 4: -5.858208832772148}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.5659407849663785 -5.389849907370277 -5.330884684032757 -5.343830981248819 -5.378320505899912 \n",
      "-5.368058807298931 -5.260183834229897 -5.040747004314277 -5.073288050962657 -5.183118469131608 \n",
      "-5.1178581930834115 -5.165755742016693 -5.113001094533576 -5.02286584848348 -4.896540502195599 \n",
      "-5.356559044869886 -5.329431411363348 -5.178561195451052 -4.839996477449615 -4.82733512825277 \n",
      "-5.452040633423054 -5.024406335320544 -4.92722438824637 -4.42718601082363 -5.368108115137192 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.39262995864969, 2: -5.524457886750161, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.39262995864969, 2: -5.524457886750161, 3: -5.4670491732954325, 4: -5.389849907370277}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.39262995864969, 2: -5.524457886750161, 3: -5.4670491732954325, 4: -5.804763415706952}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260183834229897, 1: -5.331863126749658, 2: -5.502378562957405, 3: -5.451423229939014, 4: -5.466957877282012}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.700011901591186, 2: -5.524457886750161, 3: -5.4670491732954325, 4: -5.848506608076944}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.5659407849663785, 2: -5.763126604110497, 3: -5.849535221369241, 4: -5.941173235156479}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.478127062290395, 2: -5.655761390553912, 3: -5.368058807298931, 4: -5.612682382249039}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.478127062290395, 2: -5.655761390553912, 3: -5.368058807298931, 4: -5.612682382249039}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.478127062290395, 2: -5.655761390553912, 3: -5.784933514642027, 4: -5.612682382249039}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.1178581930834115, 2: -5.387591825433048, 3: -5.332163347728921, 4: -5.5278119978332585}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.356559044869886, 1: -5.413188755628208, 2: -5.5266569441492175, 3: -5.373409971317849, 4: -5.462215684067729}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.750598645652949, 2: -5.387591825433048, 3: -5.332163347728921, 4: -5.5278119978332585}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.750598645652949, 2: -5.387591825433048, 3: -5.332163347728921, 4: -5.5278119978332585}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.750598645652949, 2: -5.387591825433048, 3: -5.752268646433318, 4: -5.5278119978332585}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.165755742016693, 2: -5.274762299679798, 3: -5.340004938108444, 4: -5.345346477315538}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.329431411363348, 1: -5.447022178995512, 2: -5.377383068627256, 3: -5.383315136074598, 4: -5.4387961078412745}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.274762299679798, 3: -5.340004938108444, 4: -5.345346477315538}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -5.231531164935169, 2: -5.113001094533576, 3: -5.286470996865388, 4: -5.412995349587669}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -5.02286584848348, 2: -5.305186892920386, 3: -5.205429900873804, 4: -5.416719745347967}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.839996477449615, 2: -5.224116457280774, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -4.711170503436255, 2: -4.42718601082363, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -5.497315698217486, 2: -5.8025892364836436, 3: -5.753435681516361, 4: -5.858208832772148}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.7242373985249895 -5.524457886750161 -5.330884684032757 -5.343830981248819 -5.378320505899912 \n",
      "-5.519978780233411 -5.331863126749658 -5.040747004314277 -5.073288050962657 -5.183118469131608 \n",
      "-5.398212648624813 -5.340004938108444 -5.2106947497735945 -5.038102330666057 -4.896540502195599 \n",
      "-5.373409971317849 -5.377383068627256 -5.178561195451052 -4.970020316512102 -4.82733512825277 \n",
      "-5.452040633423054 -5.024406335320544 -4.92722438824637 -4.711170503436255 -5.497315698217486 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.519978780233411, 1: -5.593277842626603, 2: -5.655761390553912, 3: -5.915776271919423, 4: -5.612682382249039}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.804721712408773, 2: -5.763126604110497, 3: -5.849535221369241, 4: -5.941173235156479}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7242373985249895, 1: -5.804721712408773, 2: -5.763126604110497, 3: -5.849535221369241, 4: -5.941173235156479}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.10905603265774, 1: -5.804721712408773, 2: -5.763126604110497, 3: -5.849535221369241, 4: -5.941173235156479}, Best action: 2, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -5.804721712408773, 2: -5.763126604110497, 3: -5.849535221369241, 4: -5.941173235156479}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.700011901591186, 2: -5.524457886750161, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.449136798766686, 2: -5.330884684032757, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -5.497530765468369, 2: -5.389357581774892, 3: -5.343830981248819, 4: -5.4845946019333605}, Best action: 3, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -5.497530765468369, 2: -5.389357581774892, 3: -5.343830981248819, 4: -5.4845946019333605}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.449136798766686, 2: -5.875610095969297, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.3598388549045515, 2: -5.066088022524936, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.3598388549045515, 2: -5.066088022524936, 3: -5.3221412943762045, 4: -5.040747004314277}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.3598388549045515, 2: -5.066088022524936, 3: -5.3221412943762045, 4: -5.487079773925991}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.073288050962657, 1: -5.1352312708071075, 2: -5.1023036567550655, 3: -5.253739380505333, 4: -5.443161038315229}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -5.497530765468369, 2: -5.389357581774892, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.378320505899912, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.79427166036892, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.524812446917491, 2: -5.424211956438387, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.524812446917491, 2: -5.836032880358932, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.278697529746326, 2: -5.183118469131608, 3: -5.215848205222523, 4: -5.369233593015063}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.278697529746326, 2: -5.183118469131608, 3: -5.215848205222523, 4: -5.369233593015063}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.278697529746326, 2: -5.616637806909763, 3: -5.215848205222523, 4: -5.369233593015063}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.1352312708071075, 2: -5.1023036567550655, 3: -5.253739380505333, 4: -5.443161038315229}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.278697529746326, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.369233593015063}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.09765464453657, 3: -4.896540502195599, 4: -4.93812805082046}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038102330666057, 1: -5.322683731582536, 2: -5.305186892920386, 3: -5.205429900873804, 4: -5.416719745347967}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.1352312708071075, 2: -5.68597536477003, 3: -5.253739380505333, 4: -5.443161038315229}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.322683731582536, 2: -5.305186892920386, 3: -5.205429900873804, 4: -5.416719745347967}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2106947497735945, 1: -5.231531164935169, 2: -5.479821446724976, 3: -5.286470996865388, 4: -5.412995349587669}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.241453513543936, 1: -5.3598388549045515, 2: -5.515972123532246, 3: -5.3221412943762045, 4: -5.552239275637797}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.527918753371233, 2: -5.875610095969297, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.527918753371233, 2: -5.875610095969297, 3: -5.510705176976977, 4: -5.466887161446563}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.527918753371233, 2: -5.875610095969297, 3: -5.510705176976977, 4: -5.874867316916372}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.700011901591186, 2: -5.770462382741549, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.331863126749658, 2: -5.502378562957405, 3: -5.451423229939014, 4: -5.466957877282012}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.569007116540177, 3: -5.340004938108444, 4: -5.345346477315538}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.398212648624813, 1: -5.750598645652949, 2: -5.623021333576827, 3: -5.839176243244101, 4: -5.5278119978332585}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.593277842626603, 2: -5.655761390553912, 3: -5.915776271919423, 4: -5.612682382249039}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.750598645652949, 2: -5.623021333576827, 3: -5.839176243244101, 4: -5.5278119978332585}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.750598645652949, 2: -5.623021333576827, 3: -5.839176243244101, 4: -5.5278119978332585}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.750598645652949, 2: -5.623021333576827, 3: -5.839176243244101, 4: -5.930308918028266}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.569007116540177, 3: -5.806552739196944, 4: -5.345346477315538}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.569007116540177, 3: -5.806552739196944, 4: -5.345346477315538}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.569007116540177, 3: -5.806552739196944, 4: -5.76426529435714}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.231531164935169, 2: -5.479821446724976, 3: -5.286470996865388, 4: -5.412995349587669}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.178561195451052, 2: -5.309092495813137, 3: -5.371638559474905, 4: -5.444190658862408}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.952678635197489, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -4.92722438824637, 2: -4.952678635197489, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -5.3837741933041965, 2: -4.952678635197489, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -4.711170503436255, 2: -4.895544316638527, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -4.711170503436255, 2: -4.895544316638527, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -5.187165158126993, 2: -4.895544316638527, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -5.333104431677338, 2: -4.895544316638527, 3: -5.068527599206208, 4: -4.832577673906961}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -5.333104431677338, 2: -4.895544316638527, 3: -5.068527599206208, 4: -5.297645683255334}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.520304858945966, 1: -5.920914381810812, 2: -5.8025892364836436, 3: -5.753435681516361, 4: -5.858208832772148}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.804721712408773 -5.759873790148871 -5.527918753371233 -5.497530765468369 -5.650807204688351 \n",
      "-5.612682382249039 -5.451423229939014 -5.3221412943762045 -5.253739380505333 -5.369233593015063 \n",
      "-5.750598645652949 -5.649969914045999 -5.286470996865388 -5.305186892920386 -4.93812805082046 \n",
      "-5.373409971317849 -5.377383068627256 -5.309092495813137 -4.970020316512102 -4.82733512825277 \n",
      "-5.452040633423054 -5.024406335320544 -4.979966589802916 -4.958685065155994 -5.520304858945966 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -5.804721712408773, 2: -5.951123548678681, 3: -5.849535221369241, 4: -6.162249872845151}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.655761390553912, 3: -5.915776271919423, 4: -5.612682382249039}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.655761390553912, 3: -5.915776271919423, 4: -5.612682382249039}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.655761390553912, 3: -5.915776271919423, 4: -6.007540967846626}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.758590312542805, 2: -5.502378562957405, 3: -5.451423229939014, 4: -5.466957877282012}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.881228955305993, 3: -5.915776271919423, 4: -6.0819208231333315}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.758590312542805, 2: -5.502378562957405, 3: -6.208937776791755, 4: -5.466957877282012}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.758590312542805, 2: -5.502378562957405, 3: -6.208937776791755, 4: -5.466957877282012}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.758590312542805, 2: -5.502378562957405, 3: -6.208937776791755, 4: -5.874931668326631}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.3598388549045515, 2: -5.515972123532246, 3: -5.3221412943762045, 4: -5.552239275637797}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -5.758590312542805, 2: -5.761172304740466, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.649969914045999, 1: -5.7334150174059815, 2: -5.694440955251505, 3: -5.806552739196944, 4: -5.987322293833257}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -6.05233466163154, 2: -5.761172304740466, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.3598388549045515, 2: -5.515972123532246, 3: -6.096672282597292, 4: -5.552239275637797}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.617787684808869, 2: -5.479821446724976, 3: -5.286470996865388, 4: -5.412995349587669}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -5.7334150174059815, 2: -5.694440955251505, 3: -5.806552739196944, 4: -5.987322293833257}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.617787684808869, 2: -5.479821446724976, 3: -6.041144273440258, 4: -5.412995349587669}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.617787684808869, 2: -5.479821446724976, 3: -6.041144273440258, 4: -5.412995349587669}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.617787684808869, 2: -5.479821446724976, 3: -6.041144273440258, 4: -5.825825768124779}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.322683731582536, 2: -5.305186892920386, 3: -5.6412057374039914, 4: -5.416719745347967}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.09765464453657, 3: -5.470516938059066, 4: -4.93812805082046}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.09765464453657, 3: -5.470516938059066, 4: -4.93812805082046}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.09765464453657, 3: -5.470516938059066, 4: -5.393696526246619}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.09765464453657, 3: -5.470516938059066, 4: -5.568469914699284}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.116796718233337, 2: -5.538865726528279, 3: -5.470516938059066, 4: -5.568469914699284}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -4.82733512825277, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.153855072945703, 1: -5.920914381810812, 2: -5.8025892364836436, 3: -5.753435681516361, 4: -5.858208832772148}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-5.849535221369241 -5.759873790148871 -5.527918753371233 -5.497530765468369 -5.650807204688351 \n",
      "-5.915776271919423 -5.817586702946733 -5.515972123532246 -5.253739380505333 -5.369233593015063 \n",
      "-5.750598645652949 -5.7334150174059815 -5.617787684808869 -5.322683731582536 -5.321821125708078 \n",
      "-5.373409971317849 -5.377383068627256 -5.309092495813137 -4.970020316512102 -4.943350959793328 \n",
      "-5.452040633423054 -5.024406335320544 -4.979966589802916 -4.958685065155994 -5.753435681516361 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.026744900862599, 2: -5.951123548678681, 3: -5.849535221369241, 4: -6.162249872845151}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.026744900862599, 2: -5.951123548678681, 3: -5.849535221369241, 4: -6.162249872845151}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.026744900862599, 2: -5.951123548678681, 3: -6.223077051446009, 4: -6.162249872845151}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.7888103228263414, 2: -5.770462382741549, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.759873790148871, 1: -5.7888103228263414, 2: -5.770462382741549, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.141485149035472, 1: -5.7888103228263414, 2: -5.770462382741549, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.527918753371233, 2: -5.875610095969297, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.71802539295142, 2: -5.515972123532246, 3: -6.096672282597292, 4: -5.552239275637797}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.6299213467884925, 2: -5.68597536477003, 3: -5.253739380505333, 4: -5.443161038315229}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.71802539295142, 2: -5.707126110562545, 3: -6.096672282597292, 4: -5.552239275637797}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.71802539295142, 2: -5.707126110562545, 3: -6.096672282597292, 4: -5.552239275637797}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.71802539295142, 2: -5.707126110562545, 3: -6.096672282597292, 4: -5.952537740830396}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.6299213467884925, 2: -5.68597536477003, 3: -5.92268775131715, 4: -5.443161038315229}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.6299213467884925, 2: -5.68597536477003, 3: -5.92268775131715, 4: -5.443161038315229}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.6299213467884925, 2: -5.68597536477003, 3: -5.92268775131715, 4: -5.853276544866858}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.322683731582536, 2: -5.430402410456611, 3: -5.6412057374039914, 4: -5.416719745347967}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -4.970020316512102, 2: -5.224116457280774, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.958685065155994, 1: -5.333104431677338, 2: -4.961001367410085, 3: -5.068527599206208, 4: -5.395155464802741}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -5.413536934427566, 2: -5.224116457280774, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.943350959793328, 1: -5.14301641485353, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.321821125708078, 2: -5.598491914421831, 3: -5.470516938059066, 4: -5.568469914699284}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.14301641485353, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.14301641485353, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.019700889040708}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.14301641485353, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.467927809027044}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.153855072945703, 1: -5.920914381810812, 2: -5.8025892364836436, 3: -6.213467097460722, 4: -5.858208832772148}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.026744900862599 -5.7888103228263414 -5.549743032621719 -5.497530765468369 -5.650807204688351 \n",
      "-5.915776271919423 -5.817586702946733 -5.71802539295142 -5.68597536477003 -5.369233593015063 \n",
      "-5.750598645652949 -5.7334150174059815 -5.617787684808869 -5.416719745347967 -5.3433716501144914 \n",
      "-5.373409971317849 -5.377383068627256 -5.309092495813137 -5.235370856981285 -5.16961692765861 \n",
      "-5.452040633423054 -5.024406335320544 -4.979966589802916 -4.961001367410085 -5.8025892364836436 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -5.7888103228263414, 2: -5.954660428504853, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -6.05233466163154, 2: -5.817586702946733, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -5.71802539295142, 2: -5.87967305209159, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.617787684808869, 2: -5.745183527938011, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.408907874024665, 2: -5.309092495813137, 3: -5.371638559474905, 4: -5.444190658862408}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.235370856981285, 1: -5.413536934427566, 2: -5.426525923160673, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.457984829533056, 2: -5.430402410456611, 3: -5.6412057374039914, 4: -5.416719745347967}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.457984829533056, 2: -5.430402410456611, 3: -5.6412057374039914, 4: -5.416719745347967}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.457984829533056, 2: -5.430402410456611, 3: -5.6412057374039914, 4: -5.829214968266649}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3433716501144914, 1: -5.498139832693782, 2: -5.598491914421831, 3: -5.470516938059066, 4: -5.568469914699284}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.394067559753068, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.369233593015063}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.394067559753068, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.369233593015063}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.394067559753068, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.786002569643707}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.498139832693782, 2: -5.598491914421831, 3: -5.470516938059066, 4: -5.568469914699284}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.457984829533056, 2: -5.771171277638399, 3: -5.6412057374039914, 4: -5.881547449296519}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.413536934427566, 2: -5.426525923160673, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.413536934427566, 2: -5.426525923160673, 3: -5.276915267314079, 4: -5.261056327805155}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.413536934427566, 2: -5.426525923160673, 3: -5.276915267314079, 4: -5.687561258302692}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310115309598645, 1: -5.408907874024665, 2: -5.671559643736154, 3: -5.371638559474905, 4: -5.444190658862408}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666646820947948, 1: -5.762143690089529, 2: -5.745183527938011, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85232395212611, 1: -6.022210563990327, 2: -5.87967305209159, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.920729295398242, 2: -5.875610095969297, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.549743032621719, 1: -5.920729295398242, 2: -5.875610095969297, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.950266159685764, 1: -5.920729295398242, 2: -5.875610095969297, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -5.497530765468369, 2: -5.795375367956418, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.774365957260704, 2: -5.68597536477003, 3: -5.92268775131715, 4: -6.045563945385365}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.438497638724148, 1: -5.87052547580315, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.847794980364355}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.650807204688351, 2: -5.958701370039061, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -5.68650082692122, 3: -5.554450782493856, 4: -5.847794980364355}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.772708446333928, 1: -5.774365957260704, 2: -5.873780623843563, 3: -5.92268775131715, 4: -6.045563945385365}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -6.055393122010561, 2: -5.795375367956418, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.774662257232722, 1: -6.055393122010561, 2: -5.795375367956418, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154942654081777, 1: -6.055393122010561, 2: -5.795375367956418, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.055393122010561, 2: -5.795375367956418, 3: -5.848183905125898, 4: -5.7769625550048795}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.055393122010561, 2: -5.795375367956418, 3: -5.848183905125898, 4: -6.157035925054441}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.964185854288858, 2: -5.958701370039061, 3: -5.712732579653316, 4: -5.7799258656083685}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.055393122010561, 2: -6.106850926314828, 3: -5.848183905125898, 4: -6.209957640550143}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -5.920729295398242, 2: -5.940560929626309, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980524251636203, 1: -6.022210563990327, 2: -5.87967305209159, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -5.774365957260704, 2: -5.873780623843563, 3: -5.92268775131715, 4: -6.045563945385365}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.563347562420363, 1: -5.707254108475482, 2: -5.771171277638399, 3: -5.6412057374039914, 4: -5.881547449296519}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -5.983748121286565, 2: -5.873780623843563, 3: -5.92268775131715, 4: -6.045563945385365}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -5.68650082692122, 3: -6.131338919779867, 4: -5.847794980364355}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -5.68650082692122, 3: -6.131338919779867, 4: -5.847794980364355}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -6.074715752498311, 3: -6.131338919779867, 4: -5.847794980364355}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -6.244185509344959, 3: -6.131338919779867, 4: -5.847794980364355}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.87052547580315, 2: -6.244185509344959, 3: -6.131338919779867, 4: -6.221493432131563}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.498139832693782, 2: -5.598491914421831, 3: -5.868019405727682, 4: -5.568469914699284}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.214398923037104, 2: -5.302762501771429, 3: -5.16961692765861, 4: -5.612636076934064}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.413536934427566, 2: -5.426525923160673, 3: -5.728884927506311, 4: -5.743057492354674}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -4.961001367410085, 3: -5.068527599206208, 4: -5.395155464802741}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.153855072945703, 1: -5.920914381810812, 2: -6.1691952851377, 3: -6.213467097460722, 4: -5.858208832772148}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.026744900862599 -5.848506608076944 -5.940560929626309 -6.055393122010561 -5.7799258656083685 \n",
      "-5.915776271919423 -5.85432821379229 -5.980524251636203 -5.92268775131715 -5.940545812062278 \n",
      "-5.750598645652949 -5.7334150174059815 -5.745183527938011 -5.6412057374039914 -5.568469914699284 \n",
      "-5.373409971317849 -5.377383068627256 -5.371638559474905 -5.426525923160673 -5.214398923037104 \n",
      "-5.452040633423054 -5.024406335320544 -4.979966589802916 -5.068527599206208 -5.858208832772148 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.026744900862599, 2: -6.1606101248884535, 3: -6.342717779574333, 4: -6.162249872845151}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.916358776129029, 3: -5.915776271919423, 4: -6.0819208231333315}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.916358776129029, 3: -5.915776271919423, 4: -6.0819208231333315}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -5.916358776129029, 3: -6.283356407446675, 4: -6.0819208231333315}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.85432821379229, 1: -6.05233466163154, 2: -6.113359238585323, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -6.191126261669488, 2: -5.954660428504853, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -6.191126261669488, 2: -5.954660428504853, 3: -5.955116953152309, 4: -5.848506608076944}, Best action: 4, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -5.940560929626309, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.055393122010561, 2: -6.106850926314828, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -5.983748121286565, 2: -6.093443732190545, 3: -5.92268775131715, 4: -6.045563945385365}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980524251636203, 1: -6.022210563990327, 2: -6.16520373059033, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.068080157986558, 4: -5.951157925042989}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.068080157986558, 4: -6.3155537117891205}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -6.191126261669488, 2: -6.307320395847796, 3: -5.955116953152309, 4: -6.308125607896626}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.294453270340993, 2: -6.1606101248884535, 3: -6.342717779574333, 4: -6.162249872845151}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -6.191126261669488, 2: -6.307320395847796, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.188223044924202, 1: -6.191126261669488, 2: -6.307320395847796, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.531282970881024, 1: -6.191126261669488, 2: -6.307320395847796, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.05233466163154, 2: -6.113359238585323, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.05233466163154, 2: -6.113359238585323, 3: -6.208937776791755, 4: -5.944419802828162}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.05233466163154, 2: -6.113359238585323, 3: -6.208937776791755, 4: -6.309422020573627}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -5.7334150174059815, 2: -5.853970328691163, 3: -5.806552739196944, 4: -5.987322293833257}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.447022178995512, 2: -5.377383068627256, 3: -5.383315136074598, 4: -5.4387961078412745}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -5.408907874024665, 2: -5.671559643736154, 3: -5.371638559474905, 4: -5.444190658862408}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.447022178995512, 2: -5.788765540037399, 3: -5.383315136074598, 4: -5.4387961078412745}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.413188755628208, 2: -5.5266569441492175, 3: -5.373409971317849, 4: -5.462215684067729}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.413188755628208, 2: -5.5266569441492175, 3: -5.373409971317849, 4: -5.462215684067729}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.413188755628208, 2: -5.5266569441492175, 3: -5.789803073899243, 4: -5.462215684067729}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.452040633423054, 3: -5.491679988824896, 4: -5.519944883584987}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.024406335320544, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.191460336111927}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.024406335320544, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.191460336111927}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101197626790299, 1: -5.472209765141695, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.191460336111927}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.447022178995512, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.4387961078412745}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.447022178995512, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.4387961078412745}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.447022178995512, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.84930445813556}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.191460336111927}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.191460336111927}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.362816366252384, 3: -5.4628219239335385, 4: -5.6242289058618535}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.979966589802916, 1: -5.450047113840386, 2: -5.211315971303115, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -5.408907874024665, 2: -5.671559643736154, 3: -5.797649116167915, 4: -5.444190658862408}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.211315971303115, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -5.241249291286449, 3: -5.068527599206208, 4: -5.395155464802741}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.52663895248734, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.52663895248734, 3: -5.240555325281625, 4: -5.23613716957097}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.52663895248734, 3: -5.240555325281625, 4: -5.664884824309583}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.470054574365601, 3: -5.4628219239335385, 4: -5.806304147250616}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.514973194951946, 3: -5.491679988824896, 4: -5.519944883584987}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.514973194951946, 3: -5.491679988824896, 4: -5.519944883584987}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.514973194951946, 3: -5.897428789830656, 4: -5.519944883584987}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.470054574365601, 3: -5.89454298334152, 4: -5.806304147250616}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.52663895248734, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.450047113840386, 2: -5.52663895248734, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.8595428735947515, 2: -5.52663895248734, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -5.241249291286449, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.153855072945703, 1: -5.920914381810812, 2: -6.1691952851377, 3: -6.213467097460722, 4: -6.3674842529759195}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.162249872845151 -6.307320395847796 -6.254270793703707 -6.106850926314828 -5.7799258656083685 \n",
      "-5.9368555025076 -6.113359238585323 -6.022210563990327 -5.983748121286565 -5.940545812062278 \n",
      "-5.750598645652949 -5.806552739196944 -5.745183527938011 -5.6412057374039914 -5.568469914699284 \n",
      "-5.462215684067729 -5.649785090150212 -5.444190658862408 -5.426525923160673 -5.214398923037104 \n",
      "-5.519944883584987 -5.579191054214312 -5.698075821190757 -5.320065578395403 -5.920914381810812 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -5.9368555025076, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.0819208231333315}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.750598645652949, 2: -5.792032779983269, 3: -5.839176243244101, 4: -6.047678172000056}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.857471788635494, 2: -5.5266569441492175, 3: -5.863663199448773, 4: -5.462215684067729}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.857471788635494, 2: -5.5266569441492175, 3: -5.863663199448773, 4: -5.462215684067729}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.857471788635494, 2: -5.5266569441492175, 3: -5.863663199448773, 4: -5.870616272501634}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.649785090150212, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.897018410799921}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.861543619647272, 3: -5.89454298334152, 4: -5.806304147250616}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.579191054214312, 2: -5.861543619647272, 3: -5.89454298334152, 4: -5.806304147250616}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -5.977063859335024, 2: -5.861543619647272, 3: -5.89454298334152, 4: -5.806304147250616}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -6.200812745206502, 2: -5.861543619647272, 3: -5.89454298334152, 4: -5.806304147250616}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.815544610030462, 1: -6.200812745206502, 2: -5.861543619647272, 3: -5.89454298334152, 4: -6.183736773998061}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705500603876971, 1: -5.984123262928614, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.897018410799921}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -5.829021787328675, 2: -5.853970328691163, 3: -5.806552739196944, 4: -5.987322293833257}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.899454568660156, 2: -5.792032779983269, 3: -5.839176243244101, 4: -6.047678172000056}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -5.829021787328675, 2: -5.853970328691163, 3: -6.172201825706142, 4: -5.987322293833257}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -5.788765540037399, 3: -5.790793590374918, 4: -5.897018410799921}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -5.66205672415799, 2: -5.671559643736154, 3: -5.797649116167915, 4: -5.444190658862408}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -5.66205672415799, 2: -5.671559643736154, 3: -5.797649116167915, 4: -5.444190658862408}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -5.66205672415799, 2: -5.671559643736154, 3: -5.797649116167915, 4: -5.854213499564791}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.962531838874221, 2: -5.698075821190757, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -5.320065578395403, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.153855072945703, 1: -6.3009443952122375, 2: -6.1691952851377, 3: -6.213467097460722, 4: -6.3674842529759195}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.162249872845151 -6.307320395847796 -6.254270793703707 -6.106850926314828 -5.7799258656083685 \n",
      "-6.0819208231333315 -6.113359238585323 -6.022210563990327 -5.983748121286565 -5.940545812062278 \n",
      "-5.839176243244101 -5.853970328691163 -5.745183527938011 -5.6412057374039914 -5.568469914699284 \n",
      "-5.754708216147415 -5.790793590374918 -5.671559643736154 -5.426525923160673 -5.214398923037104 \n",
      "-5.519944883584987 -5.861543619647272 -5.711338295909075 -5.333104431677338 -6.153855072945703 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.294453270340993, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.162249872845151}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.294453270340993, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.162249872845151}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.294453270340993, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.507647384289087}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -6.151670453229649, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.0819208231333315}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -6.151670453229649, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.0819208231333315}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.088630170828583, 1: -6.151670453229649, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.434547949051332}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.455801193772098, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.6492718874051135}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.323255923742522, 1: -6.455801193772098, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.6492718874051135}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.654162890605695, 1: -6.455801193772098, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.6492718874051135}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.455801193772098, 2: -6.528521678877449, 3: -6.342717779574333, 4: -6.6492718874051135}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.455801193772098, 2: -6.528521678877449, 3: -6.671873179412643, 4: -6.6492718874051135}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.151670453229649, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.4752452332762855}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.899454568660156, 2: -6.200710925734554, 3: -5.839176243244101, 4: -6.047678172000056}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.899454568660156, 2: -6.200710925734554, 3: -5.839176243244101, 4: -6.047678172000056}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -5.899454568660156, 2: -6.200710925734554, 3: -6.2136503813521315, 4: -6.047678172000056}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.754708216147415, 1: -5.857471788635494, 2: -6.028991617436594, 3: -5.863663199448773, 4: -5.96365375201103}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.97037631739003, 1: -6.151259111945421, 2: -6.200710925734554, 3: -6.2999232387499395, 4: -6.047678172000056}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.2448998023506865, 2: -6.233641730784658, 3: -6.320586249409182, 4: -6.4752452332762855}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.149299630261999, 2: -6.113359238585323, 3: -6.208937776791755, 4: -6.43333327797891}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.022210563990327, 2: -6.16520373059033, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -5.762143690089529, 2: -5.745183527938011, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -5.707254108475482, 2: -5.771171277638399, 3: -5.6412057374039914, 4: -5.881547449296519}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -5.762143690089529, 2: -6.043895000091034, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -6.081647087580313, 2: -5.671559643736154, 3: -5.797649116167915, 4: -6.071687296524452}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.459764801044926, 2: -5.426525923160673, 3: -5.728884927506311, 4: -5.743057492354674}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.214398923037104, 2: -5.302762501771429, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.5068079042991425, 1: -6.3009443952122375, 2: -6.1691952851377, 3: -6.213467097460722, 4: -6.3674842529759195}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.528433186493226 -6.307320395847796 -6.254270793703707 -6.106850926314828 -5.7799258656083685 \n",
      "-6.2448998023506865 -6.149299630261999 -6.096672282597292 -5.983748121286565 -5.940545812062278 \n",
      "-6.047678172000056 -5.853970328691163 -5.921237948659709 -5.707254108475482 -5.568469914699284 \n",
      "-5.857471788635494 -5.790793590374918 -5.797649116167915 -5.459764801044926 -5.302762501771429 \n",
      "-5.519944883584987 -5.861543619647272 -5.711338295909075 -5.333104431677338 -6.1691952851377 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.33409266645776, 2: -6.307320395847796, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.330452747852027, 4: -6.4467002991480244}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.254270793703707, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.330452747852027, 4: -6.4467002991480244}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.591386422270373, 1: -6.2546081017340125, 2: -6.398924521791185, 3: -6.330452747852027, 4: -6.4467002991480244}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.155819714028821, 2: -6.16520373059033, 3: -6.096672282597292, 4: -6.118025923638701}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.149299630261999, 2: -6.3893264806906975, 3: -6.208937776791755, 4: -6.43333327797891}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -6.171802266163161, 2: -5.853970328691163, 3: -6.172201825706142, 4: -5.987322293833257}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.070177680435238, 2: -6.043895000091034, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.070177680435238, 2: -6.043895000091034, 3: -6.041144273440258, 4: -5.921237948659709}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.070177680435238, 2: -6.043895000091034, 3: -6.041144273440258, 4: -6.288326533280335}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -6.171802266163161, 2: -6.281599771283481, 3: -6.172201825706142, 4: -5.987322293833257}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -6.171802266163161, 2: -6.281599771283481, 3: -6.172201825706142, 4: -5.987322293833257}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.131546558244378, 1: -6.171802266163161, 2: -6.281599771283481, 3: -6.172201825706142, 4: -6.348463287388264}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.256645929266042, 2: -6.3893264806906975, 3: -6.208937776791755, 4: -6.43333327797891}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.2448998023506865, 2: -6.475185156332578, 3: -6.320586249409182, 4: -6.4752452332762855}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.151259111945421, 2: -6.200710925734554, 3: -6.2999232387499395, 4: -6.047678172000056}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.151259111945421, 2: -6.200710925734554, 3: -6.2999232387499395, 4: -6.047678172000056}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.151259111945421, 2: -6.200710925734554, 3: -6.2999232387499395, 4: -6.403387136520052}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -5.857471788635494, 2: -6.028991617436594, 3: -5.863663199448773, 4: -5.96365375201103}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.519944883584987}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.519944883584987}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.923149844062339}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.562454723520982, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.997903310458229}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.732796462276915, 1: -5.961833798404093, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.997903310458229}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -5.95690253456739, 2: -6.028991617436594, 3: -5.863663199448773, 4: -5.96365375201103}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -5.95690253456739, 2: -6.028991617436594, 3: -5.863663199448773, 4: -5.96365375201103}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -5.95690253456739, 2: -6.028991617436594, 3: -6.235933511498384, 4: -5.96365375201103}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -5.882241524731331, 3: -5.956871166894142, 4: -5.997903310458229}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1030099501433925, 1: -6.200812745206502, 2: -5.861543619647272, 3: -5.89454298334152, 4: -6.22896481152448}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.962531838874221, 2: -5.779060700619353, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.962531838874221, 2: -5.779060700619353, 3: -5.848941290914329, 4: -5.711338295909075}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.962531838874221, 2: -5.779060700619353, 3: -5.848941290914329, 4: -6.097317849277258}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -5.5166291669255605, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.333104431677338, 2: -5.5166291669255605, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.753125032826378, 2: -5.5166291669255605, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.845388429772858, 2: -5.5166291669255605, 3: -5.648123867273107, 4: -5.395155464802741}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.845388429772858, 2: -5.5166291669255605, 3: -5.648123867273107, 4: -5.809591472970494}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.5068079042991425, 1: -6.3009443952122375, 2: -6.625849049150485, 3: -6.213467097460722, 4: -6.3674842529759195}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.528433186493226 -6.308125607896626 -6.330452747852027 -6.106850926314828 -5.7799258656083685 \n",
      "-6.320586249409182 -6.222723173921554 -6.118025923638701 -5.983748121286565 -5.940545812062278 \n",
      "-6.200710925734554 -6.171802266163161 -6.043895000091034 -5.707254108475482 -5.568469914699284 \n",
      "-5.96365375201103 -5.790793590374918 -5.797649116167915 -5.459764801044926 -5.302762501771429 \n",
      "-5.956871166894142 -5.89454298334152 -5.779212036940271 -5.584571265635741 -6.213467097460722 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.528433186493226, 2: -6.528521678877449, 3: -6.7963862848966645, 4: -6.6492718874051135}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.423109299555114, 2: -6.475185156332578, 3: -6.320586249409182, 4: -6.4752452332762855}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.423109299555114, 2: -6.475185156332578, 3: -6.320586249409182, 4: -6.4752452332762855}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.423109299555114, 2: -6.475185156332578, 3: -6.651733486962355, 4: -6.4752452332762855}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.259678059989293, 2: -6.200710925734554, 3: -6.2999232387499395, 4: -6.522858594327797}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.171802266163161, 2: -6.281599771283481, 3: -6.172201825706142, 4: -6.501399040916772}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -5.88867098768229, 3: -5.790793590374918, 4: -5.897018410799921}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.260305888489117, 2: -6.028991617436594, 3: -6.348684404149425, 4: -5.96365375201103}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.260305888489117, 2: -6.028991617436594, 3: -6.348684404149425, 4: -5.96365375201103}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.260305888489117, 2: -6.028991617436594, 3: -6.348684404149425, 4: -6.3269249143300375}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -5.88867098768229, 3: -6.309638898166426, 4: -5.897018410799921}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -6.081647087580313, 2: -5.862641962133761, 3: -5.797649116167915, 4: -6.071687296524452}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -6.18496288286424, 3: -6.309638898166426, 4: -5.897018410799921}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -6.18496288286424, 3: -6.309638898166426, 4: -5.897018410799921}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -5.984123262928614, 2: -6.18496288286424, 3: -6.309638898166426, 4: -6.266286753827928}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1030099501433925, 1: -6.200812745206502, 2: -6.112338381651077, 3: -5.89454298334152, 4: -6.22896481152448}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -5.956871166894142, 4: -5.997903310458229}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -5.956871166894142, 4: -5.997903310458229}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -6.320752761873669, 4: -5.997903310458229}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -6.390376957658533, 4: -5.997903310458229}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -6.390376957658533, 4: -6.358092012516988}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.139748514284711, 2: -6.236074484387424, 3: -6.390376957658533, 4: -6.509005497822315}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222846837781198, 1: -6.487171147999087, 2: -6.236074484387424, 3: -6.390376957658533, 4: -6.509005497822315}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.260305888489117, 2: -6.2727226617663145, 3: -6.348684404149425, 4: -6.416175701556645}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.236074484387424, 3: -6.390376957658533, 4: -6.509005497822315}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1030099501433925, 1: -6.200812745206502, 2: -6.112338381651077, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.173857779137221, 1: -6.272992142799493, 2: -6.18496288286424, 3: -6.309638898166426, 4: -6.373768518354971}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.20772303482, 2: -6.281599771283481, 3: -6.172201825706142, 4: -6.501399040916772}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.259678059989293, 2: -6.519230928165616, 3: -6.2999232387499395, 4: -6.522858594327797}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.577250921202725, 2: -6.2727226617663145, 3: -6.348684404149425, 4: -6.416175701556645}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.272992142799493, 2: -6.18496288286424, 3: -6.309638898166426, 4: -6.373768518354971}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -6.081647087580313, 2: -5.862641962133761, 3: -6.256349824364728, 4: -6.071687296524452}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.459764801044926, 2: -5.666315719976121, 3: -5.728884927506311, 4: -5.743057492354674}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.845388429772858, 2: -5.584571265635741, 3: -5.648123867273107, 4: -5.949428772506754}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.5068079042991425, 1: -6.3009443952122375, 2: -6.625849049150485, 3: -6.809377590805585, 4: -6.3674842529759195}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.528521678877449 -6.308125607896626 -6.330452747852027 -6.106850926314828 -5.7799258656083685 \n",
      "-6.475185156332578 -6.222723173921554 -6.118025923638701 -5.983748121286565 -5.940545812062278 \n",
      "-6.2999232387499395 -6.20772303482 -6.043895000091034 -5.707254108475482 -5.568469914699284 \n",
      "-6.311475638700665 -6.267236277614771 -5.9086736850597665 -5.666315719976121 -5.302762501771429 \n",
      "-6.390376957658533 -6.112338381651077 -5.779212036940271 -5.627402836913026 -6.3009443952122375 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.5648867798005, 2: -6.475185156332578, 3: -6.767891881335879, 4: -6.4752452332762855}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.222723173921554, 1: -6.256645929266042, 2: -6.3893264806906975, 3: -6.579262617583232, 4: -6.43333327797891}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.33409266645776, 2: -6.596691382484782, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.33409266645776, 2: -6.596691382484782, 3: -6.485605896474879, 4: -6.308125607896626}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.33409266645776, 2: -6.596691382484782, 3: -6.485605896474879, 4: -6.640394303185929}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.256645929266042, 2: -6.3893264806906975, 3: -6.579262617583232, 4: -6.43333327797891}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.20772303482, 2: -6.281599771283481, 3: -6.5875594111619415, 4: -6.501399040916772}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.272992142799493, 2: -6.267236277614771, 3: -6.309638898166426, 4: -6.373768518354971}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -6.081647087580313, 2: -5.9086736850597665, 3: -6.256349824364728, 4: -6.071687296524452}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -5.666315719976121, 3: -5.728884927506311, 4: -5.743057492354674}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.518488073265248, 2: -5.302762501771429, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.518488073265248, 2: -5.302762501771429, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.518488073265248, 2: -5.725513876612001, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.5068079042991425, 1: -6.774994416150612, 2: -6.625849049150485, 3: -6.809377590805585, 4: -6.3674842529759195}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.528521678877449 -6.485605896474879 -6.330452747852027 -6.106850926314828 -5.7799258656083685 \n",
      "-6.4752452332762855 -6.3893264806906975 -6.118025923638701 -5.983748121286565 -5.940545812062278 \n",
      "-6.2999232387499395 -6.281599771283481 -6.043895000091034 -5.707254108475482 -5.568469914699284 \n",
      "-6.311475638700665 -6.272992142799493 -6.020995455927703 -5.728884927506311 -5.612636076934064 \n",
      "-6.390376957658533 -6.112338381651077 -5.779212036940271 -5.627402836913026 -6.3674842529759195 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.672518180670759, 2: -6.528521678877449, 3: -6.7963862848966645, 4: -6.6492718874051135}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.60129246935127, 2: -6.596691382484782, 3: -6.485605896474879, 4: -6.694654490149379}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.672518180670759, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.6492718874051135}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.672518180670759, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.6492718874051135}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.672518180670759, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.950837417538654}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.5648867798005, 2: -6.5879242865097165, 3: -6.767891881335879, 4: -6.4752452332762855}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.5648867798005, 2: -6.5879242865097165, 3: -6.767891881335879, 4: -6.4752452332762855}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.5648867798005, 2: -6.5879242865097165, 3: -6.767891881335879, 4: -6.7924731622814205}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.519230928165616, 3: -6.2999232387499395, 4: -6.522858594327797}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.519230928165616, 3: -6.2999232387499395, 4: -6.522858594327797}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.519230928165616, 3: -6.632930147262445, 4: -6.522858594327797}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.597233688349965, 2: -6.281599771283481, 3: -6.5875594111619415, 4: -6.501399040916772}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.070177680435238, 2: -6.043895000091034, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -5.707254108475482, 2: -5.771171277638399, 3: -6.131456962712917, 4: -5.881547449296519}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -5.76186919843247, 3: -5.728884927506311, 4: -5.743057492354674}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.020995455927703, 1: -6.081647087580313, 2: -6.080583101686635, 3: -6.256349824364728, 4: -6.071687296524452}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.070177680435238, 2: -6.127265327874244, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.081647087580313, 2: -6.080583101686635, 3: -6.256349824364728, 4: -6.071687296524452}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.081647087580313, 2: -6.080583101686635, 3: -6.256349824364728, 4: -6.071687296524452}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.081647087580313, 2: -6.080583101686635, 3: -6.256349824364728, 4: -6.425235439837252}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -5.76186919843247, 3: -6.349894812052071, 4: -5.743057492354674}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -5.76186919843247, 3: -6.349894812052071, 4: -5.743057492354674}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -5.76186919843247, 3: -6.349894812052071, 4: -6.126182318042753}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.70951105223702, 2: -5.942526727006051, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.70951105223702, 2: -5.942526727006051, 3: -5.80192660965219, 4: -5.612636076934064}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.705010207802876, 1: -5.70951105223702, 2: -5.942526727006051, 3: -5.80192660965219, 4: -6.0074988300099985}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.637203694672852, 2: -5.598491914421831, 3: -5.868019405727682, 4: -5.568469914699284}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.637203694672852, 2: -5.598491914421831, 3: -5.868019405727682, 4: -5.568469914699284}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.637203694672852, 2: -5.598491914421831, 3: -5.868019405727682, 4: -5.967307622376348}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.637203694672852, 2: -5.598491914421831, 3: -5.868019405727682, 4: -6.0315092129193175}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -5.637203694672852, 2: -5.9946276421238665, 3: -5.868019405727682, 4: -6.0315092129193175}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.70951105223702, 2: -5.942526727006051, 3: -5.80192660965219, 4: -6.121808151321329}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.5068079042991425, 1: -6.774994416150612, 2: -6.625849049150485, 3: -6.809377590805585, 4: -6.824850985188325}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.70301769051578 -6.567940569040388 -6.330452747852027 -6.106850926314828 -5.7799258656083685 \n",
      "-6.5879242865097165 -6.3893264806906975 -6.118025923638701 -5.983748121286565 -5.940545812062278 \n",
      "-6.522858594327797 -6.423714927202086 -6.127265327874244 -5.771171277638399 -5.78341637535365 \n",
      "-6.311475638700665 -6.272992142799493 -6.081647087580313 -5.811080079429981 -5.80192660965219 \n",
      "-6.390376957658533 -6.112338381651077 -5.779212036940271 -5.627402836913026 -6.5068079042991425 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.812200457020868, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.999823468097181}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.70301769051578, 1: -6.812200457020868, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.999823468097181}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.999746098369359, 1: -6.812200457020868, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.999823468097181}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -6.812200457020868, 2: -6.8061929440323965, 3: -6.7963862848966645, 4: -6.999823468097181}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -6.812200457020868, 2: -6.8061929440323965, 3: -7.084711519255965, 4: -6.999823468097181}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.60129246935127, 2: -6.596691382484782, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.567940569040388, 1: -6.60129246935127, 2: -6.596691382484782, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8768259178267535, 1: -6.60129246935127, 2: -6.596691382484782, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.4637653590772075, 2: -6.398924521791185, 3: -6.330452747852027, 4: -6.4467002991480244}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.60129246935127, 2: -6.68733586400862, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.3893264806906975, 3: -6.579262617583232, 4: -6.43333327797891}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.155819714028821, 2: -6.16520373059033, 3: -6.490599928771948, 4: -6.118025923638701}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.155819714028821, 2: -6.16520373059033, 3: -6.490599928771948, 4: -6.118025923638701}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.155819714028821, 2: -6.16520373059033, 3: -6.490599928771948, 4: -6.467403590511218}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.42508447822833, 2: -6.127265327874244, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.111122202127659, 2: -5.771171277638399, 3: -6.131456962712917, 4: -5.881547449296519}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78341637535365, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -5.868019405727682, 4: -6.0315092129193175}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -5.940545812062278, 2: -6.244185509344959, 3: -6.131338919779867, 4: -6.277274978613708}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -5.868019405727682, 4: -6.0315092129193175}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.111122202127659, 2: -6.161684391800296, 3: -6.131456962712917, 4: -5.881547449296519}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.111122202127659, 2: -6.161684391800296, 3: -6.131456962712917, 4: -5.881547449296519}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.111122202127659, 2: -6.161684391800296, 3: -6.131456962712917, 4: -6.252208178859833}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811080079429981, 1: -5.969479205269444, 2: -6.022422142159839, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.218087084551051, 2: -6.161684391800296, 3: -6.131456962712917, 4: -6.475229801609387}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.42508447822833, 2: -6.187375267674528, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.218087084551051, 2: -6.161684391800296, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -6.250855374502949, 4: -6.0315092129193175}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -6.250855374502949, 4: -6.0315092129193175}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -6.250855374502949, 4: -6.388673383756579}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.065597756897397, 3: -6.250855374502949, 4: -6.452001521462549}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.0884243217792715, 2: -6.419693958776631, 3: -6.250855374502949, 4: -6.452001521462549}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.841465507706007, 2: -5.942526727006051, 3: -5.80192660965219, 4: -6.121808151321329}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -5.969479205269444, 2: -6.022422142159839, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.627402836913026, 1: -5.845388429772858, 2: -5.662222086685487, 3: -5.648123867273107, 4: -5.949428772506754}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.055144218426496, 2: -6.022422142159839, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.841465507706007, 2: -5.942526727006051, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -6.774994416150612, 2: -6.625849049150485, 3: -6.809377590805585, 4: -6.824850985188325}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.812200457020868 -6.68733586400862 -6.398924521791185 -6.106850926314828 -5.7799258656083685 \n",
      "-6.5879242865097165 -6.43333327797891 -6.16520373059033 -5.983748121286565 -6.02100359966998 \n",
      "-6.522858594327797 -6.423714927202086 -6.207047083316944 -6.2140970615553215 -6.2084029859962016 \n",
      "-6.311475638700665 -6.272992142799493 -6.081647087580313 -6.055144218426496 -5.942526727006051 \n",
      "-6.390376957658533 -6.112338381651077 -5.779212036940271 -5.648123867273107 -6.625849049150485 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.735483696294592, 2: -6.68733586400862, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.4637653590772075, 2: -6.398924521791185, 3: -6.8800921749597315, 4: -6.4467002991480244}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.3029163907679475, 2: -6.106850926314828, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -5.7799258656083685}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -5.7799258656083685}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -6.159732537703616}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8730388507519855, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -6.27313472287947}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.244465354184307, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -6.27313472287947}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -5.964185854288858, 2: -5.958701370039061, 3: -6.208302221117309, 4: -6.27313472287947}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -5.964185854288858, 2: -6.3224182467355465, 3: -6.208302221117309, 4: -6.27313472287947}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.02100359966998, 1: -6.24715029984565, 2: -6.244185509344959, 3: -6.131338919779867, 4: -6.277274978613708}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.208302221117309, 4: -6.27313472287947}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.3029163907679475, 2: -6.192425043774262, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.27313472287947}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.27313472287947}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.608552597820318}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.35099464515007, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6794051270865635, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.37343150116157, 2: -6.36323236664753, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.37343150116157, 2: -6.690541453649253, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.24715029984565, 2: -6.244185509344959, 3: -6.131338919779867, 4: -6.277274978613708}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -5.983748121286565, 2: -6.093443732190545, 3: -6.3364934189570405, 4: -6.045563945385365}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2140970615553215, 1: -6.218087084551051, 2: -6.401690901644677, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -6.531793431988467, 2: -6.093443732190545, 3: -6.3364934189570405, 4: -6.045563945385365}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -6.531793431988467, 2: -6.093443732190545, 3: -6.3364934189570405, 4: -6.045563945385365}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -6.531793431988467, 2: -6.093443732190545, 3: -6.3364934189570405, 4: -6.4014631903006824}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.24715029984565, 2: -6.244185509344959, 3: -6.359969870220104, 4: -6.277274978613708}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.24715029984565, 2: -6.244185509344959, 3: -6.359969870220104, 4: -6.277274978613708}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.24715029984565, 2: -6.582208813503913, 3: -6.359969870220104, 4: -6.277274978613708}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.2084029859962016, 2: -6.473593096518873, 3: -6.250855374502949, 4: -6.452001521462549}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.951084280582494, 2: -5.942526727006051, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.951084280582494, 2: -5.942526727006051, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -5.951084280582494, 2: -6.307699321575507, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -6.774994416150612, 2: -6.979326954762032, 3: -6.809377590805585, 4: -6.824850985188325}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.812200457020868 -6.694654490149379 -6.4467002991480244 -6.19483393496213 -6.503727675137849 \n",
      "-6.5879242865097165 -6.43333327797891 -6.16520373059033 -6.154747272991898 -6.277274978613708 \n",
      "-6.522858594327797 -6.423714927202086 -6.207047083316944 -6.218087084551051 -6.250855374502949 \n",
      "-6.311475638700665 -6.272992142799493 -6.081647087580313 -6.055144218426496 -5.980961651686707 \n",
      "-6.390376957658533 -6.112338381651077 -5.779212036940271 -5.648123867273107 -6.774994416150612 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.659426501367501, 2: -6.5879242865097165, 3: -6.767891881335879, 4: -6.896805607866547}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.494533646216418, 3: -6.579262617583232, 4: -6.43333327797891}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.494533646216418, 3: -6.579262617583232, 4: -6.43333327797891}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.494533646216418, 3: -6.579262617583232, 4: -6.7543332829608085}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.47866688698102, 2: -6.16520373059033, 3: -6.490599928771948, 4: -6.532954327414466}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.154747272991898, 1: -6.531793431988467, 2: -6.567134635788472, 3: -6.3364934189570405, 4: -6.47583574210441}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19483393496213, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.537298880815538, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.583795576927169, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.280609119785167, 4: -6.209957640550143}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.583795576927169, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.280609119785167, 4: -6.55106145290063}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.4637653590772075, 2: -6.486441702494129, 3: -6.8800921749597315, 4: -6.4467002991480244}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.4637653590772075, 2: -6.486441702494129, 3: -6.8800921749597315, 4: -6.4467002991480244}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.4637653590772075, 2: -6.486441702494129, 3: -6.8800921749597315, 4: -6.766497272224702}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.318490344448442, 1: -6.47866688698102, 2: -6.50186566418247, 3: -6.490599928771948, 4: -6.532954327414466}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.664353714910959, 2: -6.486441702494129, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.583795576927169, 1: -6.3029163907679475, 2: -6.6004816299097975, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533290214618515, 1: -6.531793431988467, 2: -6.567134635788472, 3: -6.3364934189570405, 4: -6.47583574210441}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.47866688698102, 2: -6.50186566418247, 3: -6.490599928771948, 4: -6.532954327414466}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.207047083316944, 1: -6.42508447822833, 2: -6.509701884125693, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.575574826184826, 2: -6.50186566418247, 3: -6.490599928771948, 4: -6.532954327414466}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.5432683863998085, 3: -6.579262617583232, 4: -6.83600558173138}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.575574826184826, 2: -6.50186566418247, 3: -6.84910738586104, 4: -6.532954327414466}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533290214618515, 1: -6.531793431988467, 2: -6.567134635788472, 3: -6.781369520350331, 4: -6.47583574210441}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533290214618515, 1: -6.531793431988467, 2: -6.567134635788472, 3: -6.781369520350331, 4: -6.47583574210441}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533290214618515, 1: -6.531793431988467, 2: -6.567134635788472, 3: -6.781369520350331, 4: -6.7930105253150135}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418316501917678, 1: -6.218087084551051, 2: -6.401690901644677, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.055144218426496, 2: -6.23382927545785, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -5.845388429772858, 2: -5.662222086685487, 3: -5.648123867273107, 4: -5.949428772506754}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779212036940271, 1: -5.962531838874221, 2: -5.797720659720579, 3: -5.848941290914329, 4: -6.190770952429402}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.081647087580313, 2: -6.15993487897595, 3: -6.256349824364728, 4: -6.4677958563499}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -5.962531838874221, 2: -5.797720659720579, 3: -5.848941290914329, 4: -6.190770952429402}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -5.845388429772858, 2: -5.662222086685487, 3: -6.14597413664893, 4: -5.949428772506754}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -6.913718113687931, 2: -6.979326954762032, 3: -6.809377590805585, 4: -6.824850985188325}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.812200457020868 -6.694654490149379 -6.625371204631588 -6.583795576927169 -6.503727675137849 \n",
      "-6.630700315314302 -6.553920251130804 -6.532954327414466 -6.533290214618515 -6.277274978613708 \n",
      "-6.522858594327797 -6.423714927202086 -6.353845485348964 -6.401690901644677 -6.250855374502949 \n",
      "-6.311475638700665 -6.272992142799493 -6.15993487897595 -6.080494754333866 -5.980961651686707 \n",
      "-6.390376957658533 -6.112338381651077 -5.848941290914329 -5.845388429772858 -6.809377590805585 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -6.812200457020868, 2: -6.900651155325955, 3: -7.1214874365918375, 4: -6.999823468097181}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.659426501367501, 2: -6.769792383813889, 3: -6.767891881335879, 4: -6.896805607866547}, Best action: 0, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.640018907556181, 3: -6.8438700665403935, 4: -6.522858594327797}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.640018907556181, 3: -6.8438700665403935, 4: -6.522858594327797}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.546287433674576, 1: -6.606873162029644, 2: -6.640018907556181, 3: -6.8438700665403935, 4: -6.8358013208382955}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.630700315314302, 1: -6.849458111542266, 2: -6.769792383813889, 3: -6.767891881335879, 4: -6.896805607866547}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -6.975355511809763, 2: -6.900651155325955, 3: -7.1214874365918375, 4: -6.999823468097181}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.735483696294592, 2: -6.751862449051722, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.735483696294592, 2: -6.751862449051722, 3: -6.9344708184456305, 4: -6.694654490149379}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.735483696294592, 2: -6.751862449051722, 3: -6.9344708184456305, 4: -6.992135586035935}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.553920251130804, 2: -6.820838026627782, 3: -6.579262617583232, 4: -6.83600558173138}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.597233688349965, 2: -6.423714927202086, 3: -6.5875594111619415, 4: -6.501399040916772}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.42508447822833, 2: -6.509701884125693, 3: -6.353845485348964, 4: -6.422159514814642}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.597233688349965, 2: -6.68898633585287, 3: -6.5875594111619415, 4: -6.501399040916772}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.597233688349965, 2: -6.68898633585287, 3: -6.5875594111619415, 4: -6.501399040916772}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.54239425502576, 1: -6.597233688349965, 2: -6.68898633585287, 3: -6.5875594111619415, 4: -6.816273127234263}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.75860111614677, 2: -6.820838026627782, 3: -6.579262617583232, 4: -6.83600558173138}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.849458111542266, 2: -6.769792383813889, 3: -6.767891881335879, 4: -6.896805607866547}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.849458111542266, 2: -6.769792383813889, 3: -6.767891881335879, 4: -6.896805607866547}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.849458111542266, 2: -6.769792383813889, 3: -7.0587816120156495, 4: -6.896805607866547}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631854059788423, 1: -6.75860111614677, 2: -6.820838026627782, 3: -7.039918685640385, 4: -6.83600558173138}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.8822237730454106, 2: -6.751862449051722, 3: -6.9344708184456305, 4: -7.054955352602214}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.664353714910959, 2: -6.654006446771451, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.625371204631588, 1: -6.664353714910959, 2: -6.654006446771451, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.929087796214745, 1: -6.664353714910959, 2: -6.654006446771451, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.583795576927169, 1: -6.662851308431998, 2: -6.6004816299097975, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.583795576927169, 1: -6.662851308431998, 2: -6.6004816299097975, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.891253975003724, 1: -6.662851308431998, 2: -6.6004816299097975, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.503727675137849, 2: -6.731533661305797, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.553521448641488, 2: -6.618412624225368, 3: -6.359969870220104, 4: -6.277274978613708}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.553521448641488, 2: -6.618412624225368, 3: -6.359969870220104, 4: -6.277274978613708}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.553521448641488, 2: -6.618412624225368, 3: -6.359969870220104, 4: -6.612320230538474}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533290214618515, 1: -6.589829881685199, 2: -6.567134635788472, 3: -6.781369520350331, 4: -6.870053732442159}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.662851308431998, 2: -6.828067579852638, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.662851308431998, 2: -6.828067579852638, 3: -6.749888154288416, 4: -6.642399532316048}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.662851308431998, 2: -6.828067579852638, 3: -6.749888154288416, 4: -6.944583574407604}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.589829881685199, 2: -6.567134635788472, 3: -6.781369520350331, 4: -6.870053732442159}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.530825159072019, 1: -6.553521448641488, 2: -6.618412624225368, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.634965500190888, 2: -6.731533661305797, 3: -6.536694507568883, 4: -6.705160922353588}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.885664185831862, 2: -6.828067579852638, 3: -6.749888154288416, 4: -6.991367917270679}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -6.664353714910959, 2: -6.898275061988152, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.575574826184826, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.532954327414466}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.575574826184826, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.532954327414466}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.575574826184826, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.844988437947165}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.42508447822833, 2: -6.509701884125693, 3: -6.8015177716774815, 4: -6.422159514814642}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.42508447822833, 2: -6.509701884125693, 3: -6.8015177716774815, 4: -6.422159514814642}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.42508447822833, 2: -6.509701884125693, 3: -6.8015177716774815, 4: -6.744165158481324}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.204318443131701, 2: -6.15993487897595, 3: -6.256349824364728, 4: -6.4677958563499}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.080494754333866, 2: -6.23382927545785, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -5.845388429772858, 2: -6.0818180572210725, 3: -6.14597413664893, 4: -5.949428772506754}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -5.845388429772858, 2: -6.0818180572210725, 3: -6.14597413664893, 4: -5.949428772506754}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.219303471093301, 2: -6.0818180572210725, 3: -6.14597413664893, 4: -5.949428772506754}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.0818180572210725, 3: -6.14597413664893, 4: -5.949428772506754}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.0818180572210725, 3: -6.14597413664893, 4: -6.313980182981146}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -6.913718113687931, 2: -6.979326954762032, 3: -7.098820129267462, 4: -6.824850985188325}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.975355511809763 -6.8822237730454106 -6.812299668075008 -6.828067579852638 -6.634965500190888 \n",
      "-6.849458111542266 -6.75860111614677 -6.759506689618343 -6.589829881685199 -6.553521448641488 \n",
      "-6.606873162029644 -6.5875594111619415 -6.509701884125693 -6.401690901644677 -6.250855374502949 \n",
      "-6.311475638700665 -6.272992142799493 -6.204318443131701 -6.179732282534577 -5.980961651686707 \n",
      "-6.390376957658533 -6.112338381651077 -5.848941290914329 -6.136311103724651 -6.824850985188325 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -6.975355511809763, 2: -7.012735252553592, 3: -7.1214874365918375, 4: -6.999823468097181}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.849458111542266, 2: -6.948781026810011, 3: -7.089409992090816, 4: -6.896805607866547}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.606873162029644, 2: -6.640018907556181, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.311475638700665, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.348684404149425, 4: -6.416175701556645}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.672982583550503, 2: -6.640018907556181, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.597233688349965, 2: -6.68898633585287, 3: -6.5875594111619415, 4: -6.880966659294292}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.672982583550503, 2: -6.899925013796791, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.348684404149425, 4: -6.416175701556645}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.348684404149425, 4: -6.416175701556645}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.677302807775976, 4: -6.416175701556645}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.76483259903848, 4: -6.416175701556645}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.537092201296666, 3: -6.76483259903848, 4: -6.738719888416547}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.272992142799493, 2: -6.312749312659888, 3: -6.309638898166426, 4: -6.373768518354971}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.511125796115488, 1: -6.200812745206502, 2: -6.112338381651077, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -5.962531838874221, 2: -6.066171956187302, 3: -5.848941290914329, 4: -6.190770952429402}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.511125796115488, 1: -6.200812745206502, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.511125796115488, 1: -6.200812745206502, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.511125796115488, 1: -6.542739598137917, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 4, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.478293303417322, 2: -6.312749312659888, 3: -6.309638898166426, 4: -6.373768518354971}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.577250921202725, 2: -6.634832855797256, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.46704550805489, 3: -6.390376957658533, 4: -6.509005497822315}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.46704550805489, 3: -6.390376957658533, 4: -6.509005497822315}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.46704550805489, 3: -6.7152430314692655, 4: -6.509005497822315}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.22896481152448}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.248876283805714, 3: -6.314519943518406, 4: -6.568357978487278}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -5.962531838874221, 2: -6.066171956187302, 3: -6.507552452708699, 4: -6.190770952429402}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -5.962531838874221, 2: -6.066171956187302, 3: -6.507552452708699, 4: -6.190770952429402}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -6.325903973375541, 2: -6.066171956187302, 3: -6.507552452708699, 4: -6.190770952429402}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.136311103724651, 3: -6.14597413664893, 4: -6.457670644647184}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -6.913718113687931, 2: -6.979326954762032, 3: -7.098820129267462, 4: -7.2325230630847415}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.999823468097181 -6.8822237730454106 -6.812299668075008 -6.828067579852638 -6.634965500190888 \n",
      "-6.896805607866547 -6.75860111614677 -6.759506689618343 -6.589829881685199 -6.553521448641488 \n",
      "-6.709732625716084 -6.597233688349965 -6.509701884125693 -6.401690901644677 -6.250855374502949 \n",
      "-6.634832855797256 -6.312749312659888 -6.204318443131701 -6.179732282534577 -5.980961651686707 \n",
      "-6.509005497822315 -6.314519943518406 -6.190770952429402 -6.14597413664893 -6.913718113687931 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.936513072398238, 2: -6.948781026810011, 3: -7.089409992090816, 4: -6.896805607866547}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.936513072398238, 2: -6.948781026810011, 3: -7.089409992090816, 4: -6.896805607866547}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -6.936513072398238, 2: -6.948781026810011, 3: -7.089409992090816, 4: -7.176093103158558}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.709732625716084, 2: -6.899925013796791, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.733930427823684, 2: -6.634832855797256, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.478293303417322, 2: -6.312749312659888, 3: -6.85853713599085, 4: -6.373768518354971}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.204318443131701, 2: -6.441194238908027, 3: -6.256349824364728, 4: -6.4677958563499}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -6.446189681849269, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.190770952429402}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -6.446189681849269, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.190770952429402}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.404055344634081, 1: -6.446189681849269, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.533601566710756}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.534956315780986, 2: -6.441194238908027, 3: -6.256349824364728, 4: -6.4677958563499}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.478293303417322, 2: -6.556772870202667, 3: -6.85853713599085, 4: -6.373768518354971}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.478293303417322, 2: -6.556772870202667, 3: -6.85853713599085, 4: -6.373768518354971}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.478293303417322, 2: -6.556772870202667, 3: -6.85853713599085, 4: -6.700129351703024}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.354538417868691, 3: -6.314519943518406, 4: -6.618425587731357}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.592166048140318, 3: -6.809831164671388, 4: -6.509005497822315}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.592166048140318, 3: -6.809831164671388, 4: -6.509005497822315}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.592166048140318, 3: -6.809831164671388, 4: -6.823195003018307}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.589223053402678, 2: -6.592166048140318, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.896192978596438, 2: -6.592166048140318, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.354538417868691, 3: -6.803746447587916, 4: -6.618425587731357}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.446189681849269, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.740644985824681}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.446189681849269, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.740644985824681}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.766032610482835, 2: -6.477029189635698, 3: -6.507552452708699, 4: -6.740644985824681}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.21374278245969, 3: -6.14597413664893, 4: -6.457670644647184}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.822996904653199, 2: -6.525941969649203, 3: -6.507552452708699, 4: -6.740644985824681}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.756867484084777, 3: -6.803746447587916, 4: -6.618425587731357}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.756867484084777, 3: -6.803746447587916, 4: -6.618425587731357}, Best action: 4, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.822996904653199, 2: -6.525941969649203, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.21374278245969, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -7.177784353740696, 2: -6.979326954762032, 3: -7.098820129267462, 4: -7.2325230630847415}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.999823468097181 -6.8822237730454106 -6.812299668075008 -6.828067579852638 -6.634965500190888 \n",
      "-6.948781026810011 -6.75860111614677 -6.759506689618343 -6.589829881685199 -6.553521448641488 \n",
      "-6.8438700665403935 -6.597233688349965 -6.509701884125693 -6.401690901644677 -6.250855374502949 \n",
      "-6.676810228834235 -6.516869256735697 -6.418943466745313 -6.179732282534577 -5.980961651686707 \n",
      "-6.593132453454304 -6.661920087126354 -6.585725850757269 -6.274629111603215 -6.979326954762032 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -6.8822237730454106, 2: -6.941736920656758, 3: -6.9344708184456305, 4: -7.054955352602214}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -6.75860111614677, 2: -6.820838026627782, 3: -7.039918685640385, 4: -6.83600558173138}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.597233688349965, 2: -6.68898633585287, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.516869256735697, 1: -6.662590484591641, 2: -6.556772870202667, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.838387466790912, 2: -6.68898633585287, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.532055699793352, 2: -6.509701884125693, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418316501917678, 1: -6.426475525380567, 2: -6.401690901644677, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.334286947474522, 2: -6.473593096518873, 3: -6.250855374502949, 4: -6.452001521462549}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418316501917678, 1: -6.426475525380567, 2: -6.603361943511857, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.589829881685199, 2: -6.8466818424271825, 3: -6.781369520350331, 4: -6.870053732442159}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.426475525380567, 2: -6.603361943511857, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.242814103549402, 2: -6.23382927545785, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.242814103549402, 2: -6.23382927545785, 3: -6.349894812052071, 4: -6.179732282534577}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.242814103549402, 2: -6.23382927545785, 3: -6.349894812052071, 4: -6.523556377106465}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.980961651686707, 1: -6.0828539051402455, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29018374530581, 1: -6.334286947474522, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.452001521462549}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.553521448641488, 2: -6.618412624225368, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.334286947474522, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.452001521462549}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.0828539051402455, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.9801251197476955, 1: -7.177784353740696, 2: -7.172533951642985, 3: -7.098820129267462, 4: -7.2325230630847415}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.999823468097181 -6.931002611595349 -6.812299668075008 -6.828067579852638 -6.634965500190888 \n",
      "-6.948781026810011 -6.820838026627782 -6.759506689618343 -6.76442816372678 -6.618412624225368 \n",
      "-6.8438700665403935 -6.838387466790912 -6.532055699793352 -6.475229801609387 -6.452001521462549 \n",
      "-6.676810228834235 -6.556772870202667 -6.418943466745313 -6.242814103549402 -6.121808151321329 \n",
      "-6.593132453454304 -6.661920087126354 -6.585725850757269 -6.274629111603215 -6.9801251197476955 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -7.1455966215302125, 2: -7.012735252553592, 3: -7.1214874365918375, 4: -6.999823468097181}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -7.1455966215302125, 2: -7.012735252553592, 3: -7.1214874365918375, 4: -6.999823468097181}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -7.1455966215302125, 2: -7.012735252553592, 3: -7.1214874365918375, 4: -7.2698393559684344}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -7.062689281383425, 2: -6.941736920656758, 3: -6.9344708184456305, 4: -7.054955352602214}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.931002611595349, 1: -7.062689281383425, 2: -6.941736920656758, 3: -6.9344708184456305, 4: -7.054955352602214}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.207212376551768, 1: -7.062689281383425, 2: -6.941736920656758, 3: -6.9344708184456305, 4: -7.054955352602214}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -7.1455966215302125, 2: -7.215385640647591, 3: -7.1214874365918375, 4: -7.307299490165254}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.105047500603234, 1: -7.1455966215302125, 2: -7.215385640647591, 3: -7.1214874365918375, 4: -7.307299490165254}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.365593225548944, 1: -7.1455966215302125, 2: -7.215385640647591, 3: -7.1214874365918375, 4: -7.307299490165254}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.1455966215302125, 2: -7.215385640647591, 3: -7.1214874365918375, 4: -7.307299490165254}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.1455966215302125, 2: -7.215385640647591, 3: -7.380553567298572, 4: -7.307299490165254}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.0285347340698525, 2: -6.948781026810011, 3: -7.089409992090816, 4: -7.236184898958429}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -6.919619399178149, 2: -6.820838026627782, 3: -7.039918685640385, 4: -6.83600558173138}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.759506689618343, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.9107144530044256}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.532055699793352, 2: -6.736339818744757, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.418943466745313, 1: -6.534956315780986, 2: -6.441194238908027, 3: -6.688387482303999, 4: -6.4677958563499}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.752549778043039, 2: -6.736339818744757, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.548230701391065, 2: -6.603361943511857, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.548230701391065, 2: -6.603361943511857, 3: -6.524919663087659, 4: -6.475229801609387}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.548230701391065, 2: -6.603361943511857, 3: -6.524919663087659, 4: -6.792459119464542}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.752549778043039, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.534956315780986, 2: -6.441194238908027, 3: -6.688387482303999, 4: -6.4677958563499}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.242814103549402, 2: -6.367961865412018, 3: -6.349894812052071, 4: -6.601757350831506}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.274629111603215, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.267869521133486, 1: -7.177784353740696, 2: -7.172533951642985, 3: -7.098820129267462, 4: -7.2325230630847415}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.215385640647591 -6.941736920656758 -6.812299668075008 -6.828067579852638 -6.634965500190888 \n",
      "-7.0285347340698525 -6.83600558173138 -6.785866813465089 -6.76442816372678 -6.618412624225368 \n",
      "-6.8438700665403935 -6.838387466790912 -6.778090650636972 -6.548230701391065 -6.452001521462549 \n",
      "-6.676810228834235 -6.556772870202667 -6.4677958563499 -6.349894812052071 -6.121808151321329 \n",
      "-6.593132453454304 -6.661920087126354 -6.585725850757269 -6.340902218840772 -7.098820129267462 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.2430722938691305, 2: -7.215385640647591, 3: -7.4259886201693295, 4: -7.307299490165254}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.062689281383425, 2: -6.941736920656758, 3: -7.348535557333183, 4: -7.054955352602214}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -6.858128376696814, 2: -6.898275061988152, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -6.858128376696814, 2: -6.898275061988152, 3: -6.8800921749597315, 4: -6.812299668075008}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -6.858128376696814, 2: -6.898275061988152, 3: -6.8800921749597315, 4: -7.099192697948258}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785866813465089, 1: -6.86691578579445, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.9107144530044256}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -7.082364956576403, 2: -6.898275061988152, 3: -6.8800921749597315, 4: -7.165003254919245}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.062689281383425, 2: -7.112136423206432, 3: -7.348535557333183, 4: -7.054955352602214}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.062689281383425, 2: -7.112136423206432, 3: -7.348535557333183, 4: -7.054955352602214}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.062689281383425, 2: -7.112136423206432, 3: -7.348535557333183, 4: -7.320009370868015}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -6.919619399178149, 2: -7.057284221253637, 3: -7.039918685640385, 4: -6.83600558173138}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -6.919619399178149, 2: -7.057284221253637, 3: -7.039918685640385, 4: -6.83600558173138}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -6.919619399178149, 2: -7.057284221253637, 3: -7.039918685640385, 4: -7.1207650793755555}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.838387466790912, 2: -6.8417571597270985, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.662590484591641, 2: -6.556772870202667, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.534956315780986, 2: -6.600798847765819, 3: -6.688387482303999, 4: -6.4677958563499}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.534956315780986, 2: -6.600798847765819, 3: -6.688387482303999, 4: -6.4677958563499}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.534956315780986, 2: -6.600798847765819, 3: -6.688387482303999, 4: -6.785694229278409}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.822996904653199, 2: -6.585725850757269, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.340902218840772, 1: -6.340967652839801, 2: -6.377507215866966, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.606730990753545, 2: -6.367961865412018, 3: -6.349894812052071, 4: -6.601757350831506}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.600798847765819, 3: -6.688387482303999, 4: -6.871884038710439}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.606730990753545, 2: -6.367961865412018, 3: -6.88163654789552, 4: -6.601757350831506}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.262186737509658, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.262186737509658, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.121808151321329}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.262186737509658, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.47084541770241}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.267869521133486, 1: -7.177784353740696, 2: -7.172533951642985, 3: -7.454344381851295, 4: -7.2325230630847415}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.2430722938691305 -7.112136423206432 -6.898275061988152 -6.828067579852638 -6.634965500190888 \n",
      "-7.0285347340698525 -7.032193989710738 -6.795613517522819 -6.76442816372678 -6.618412624225368 \n",
      "-6.8438700665403935 -6.8417571597270985 -6.778090650636972 -6.548230701391065 -6.452001521462549 \n",
      "-6.676810228834235 -6.662590484591641 -6.688387482303999 -6.447588147740461 -6.315470817233468 \n",
      "-6.593132453454304 -6.661920087126354 -6.608048892198838 -6.340967652839801 -7.172533951642985 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.14343344934076, 2: -7.112136423206432, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -7.082364956576403, 2: -6.898275061988152, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.885664185831862, 2: -6.828067579852638, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.634965500190888, 2: -6.731533661305797, 3: -7.021078855730505, 4: -6.705160922353588}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.686124572318511, 2: -6.618412624225368, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.686124572318511, 2: -6.618412624225368, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.686124572318511, 2: -6.922755488045084, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.460540357911051, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.452001521462549}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.460540357911051, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.452001521462549}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.460540357911051, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.7713213845309195}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.435971174581784, 2: -6.351148199429371, 3: -6.315470817233468, 4: -6.619455799153064}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.447588147740461, 1: -6.606730990753545, 2: -6.495460789111479, 3: -6.88163654789552, 4: -6.601757350831506}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.548230701391065, 2: -6.603361943511857, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.606730990753545, 2: -6.495460789111479, 3: -6.88163654789552, 4: -6.601757350831506}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.435971174581784, 2: -6.351148199429371, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.435971174581784, 2: -6.351148199429371, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.435971174581784, 2: -6.679544861480728, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.267869521133486, 1: -7.177784353740696, 2: -7.378083897961509, 3: -7.454344381851295, 4: -7.2325230630847415}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.2430722938691305 -7.14343344934076 -6.98265400150635 -6.885664185831862 -6.705160922353588 \n",
      "-7.0285347340698525 -7.032193989710738 -6.795613517522819 -6.76442816372678 -6.712807617932132 \n",
      "-6.8438700665403935 -6.8417571597270985 -6.778090650636972 -6.603361943511857 -6.473593096518873 \n",
      "-6.676810228834235 -6.662590484591641 -6.688387482303999 -6.601757350831506 -6.457602443988143 \n",
      "-6.593132453454304 -6.661920087126354 -6.608048892198838 -6.340967652839801 -7.177784353740696 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.0285347340698525, 2: -7.119756904249504, 3: -7.089409992090816, 4: -7.236184898958429}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -6.899925013796791, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -6.899925013796791, 3: -6.8438700665403935, 4: -6.8860729533602365}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -6.899925013796791, 3: -7.127921760551758, 4: -6.8860729533602365}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -6.899925013796791, 3: -7.190511268276968, 4: -6.8860729533602365}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -6.899925013796791, 3: -7.190511268276968, 4: -7.166326387557816}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.894824771543251, 2: -6.8417571597270985, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778090650636972, 1: -6.792622311319806, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -6.86691578579445, 2: -6.795613517522819, 3: -6.84910738586104, 4: -6.9107144530044256}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.76442816372678, 2: -6.8466818424271825, 3: -6.781369520350331, 4: -6.870053732442159}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.816146309319405, 2: -6.603361943511857, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.661585397750215, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.810169828361044}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.661585397750215, 2: -6.473593096518873, 3: -6.723921904003614, 4: -6.810169828361044}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.661585397750215, 2: -6.790969717832175, 3: -6.723921904003614, 4: -6.810169828361044}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.457602443988143, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.267869521133486, 1: -7.31089156997065, 2: -7.378083897961509, 3: -7.454344381851295, 4: -7.2325230630847415}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.2430722938691305 -7.14343344934076 -6.98265400150635 -6.885664185831862 -6.705160922353588 \n",
      "-7.089409992090816 -7.032193989710738 -6.84910738586104 -6.781369520350331 -6.712807617932132 \n",
      "-6.925495998772042 -6.880966659294292 -6.77873494321308 -6.803946602531473 -6.723921904003614 \n",
      "-6.676810228834235 -6.662590484591641 -6.688387482303999 -6.601757350831506 -6.504103925497455 \n",
      "-6.593132453454304 -6.661920087126354 -6.608048892198838 -6.340967652839801 -7.2325230630847415 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.2430722938691305, 2: -7.244345469796732, 3: -7.4259886201693295, 4: -7.307299490165254}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.146388227304704, 2: -7.119756904249504, 3: -7.089409992090816, 4: -7.236184898958429}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.146388227304704, 2: -7.119756904249504, 3: -7.089409992090816, 4: -7.236184898958429}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.146388227304704, 2: -7.119756904249504, 3: -7.351363092802642, 4: -7.236184898958429}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.032193989710738, 1: -7.131055788018454, 2: -7.057284221253637, 3: -7.039918685640385, 4: -7.216968221271856}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.14343344934076, 2: -7.198816442531046, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.131055788018454, 2: -7.057284221253637, 3: -7.039918685640385, 4: -7.216968221271856}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.146388227304704, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.236184898958429}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.925495998772042, 1: -6.9451878757673855, 2: -7.13181580075863, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.152597467345453, 1: -7.224290581735824, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.236184898958429}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.366729322980474, 2: -7.244345469796732, 3: -7.4259886201693295, 4: -7.307299490165254}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.316677480302787, 2: -7.198816442531046, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -7.082364956576403, 2: -7.120562245879452, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.98265400150635, 1: -7.082364956576403, 2: -7.120562245879452, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2542151413707785, 1: -7.082364956576403, 2: -7.120562245879452, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -6.86691578579445, 2: -7.058748164370974, 3: -6.84910738586104, 4: -6.9107144530044256}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.131055788018454, 2: -7.057284221253637, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -6.86691578579445, 2: -7.058748164370974, 3: -7.30131095780155, 4: -6.9107144530044256}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.792622311319806, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.792622311319806, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -6.77873494321308}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.792622311319806, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -7.068648798323903}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.718128995760317, 3: -6.688387482303999, 4: -6.871884038710439}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.662590484591641, 2: -6.794591930663686, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.661920087126354, 1: -6.828285854667337, 2: -6.861699743824332, 3: -6.803746447587916, 4: -7.0349052208818055}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.962414319031511, 2: -6.794591930663686, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.718128995760317, 3: -6.96553704074963, 4: -6.871884038710439}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.606730990753545, 2: -6.693976120448938, 3: -6.88163654789552, 4: -6.601757350831506}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.606730990753545, 2: -6.693976120448938, 3: -6.88163654789552, 4: -6.601757350831506}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.606730990753545, 2: -6.693976120448938, 3: -6.88163654789552, 4: -6.907599189256671}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.340967652839801, 2: -6.377507215866966, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.340967652839801, 2: -6.377507215866966, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.670280564084219, 2: -6.377507215866966, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.267869521133486, 1: -7.31089156997065, 2: -7.378083897961509, 3: -7.454344381851295, 4: -7.49014086434247}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.307299490165254 -7.237642600596137 -7.120562245879452 -6.885664185831862 -6.705160922353588 \n",
      "-7.224290581735824 -7.131055788018454 -6.9107144530044256 -6.781369520350331 -6.712807617932132 \n",
      "-6.9451878757673855 -6.880966659294292 -6.8015177716774815 -6.803946602531473 -6.723921904003614 \n",
      "-6.676810228834235 -6.817430510938333 -6.871884038710439 -6.693976120448938 -6.504103925497455 \n",
      "-6.593132453454304 -6.803746447587916 -6.608048892198838 -6.457670644647184 -7.267869521133486 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.366729322980474, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.307299490165254}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.366729322980474, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.307299490165254}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.366729322980474, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.549642536050381}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.224290581735824, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.236184898958429}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -6.9451878757673855, 2: -7.13181580075863, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.733930427823684, 2: -6.676810228834235, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.962414319031511, 2: -7.0211436796322255, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.962414319031511, 2: -7.0211436796322255, 3: -6.85853713599085, 4: -6.817430510938333}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.962414319031511, 2: -7.0211436796322255, 3: -6.85853713599085, 4: -7.1038617649538836}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.733930427823684, 2: -7.0897997367434735, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593132453454304, 1: -6.929273796853302, 2: -6.706392723287672, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -6.76483259903848, 4: -6.868916671891954}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -7.055997665125017, 4: -6.868916671891954}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -7.169422270744985, 4: -6.868916671891954}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.909562878990574, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -7.169422270744985, 4: -7.150714171421678}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.002735072932469, 2: -7.13181580075863, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -6.913830330080355, 2: -7.0897997367434735, 3: -7.169422270744985, 4: -7.211817349124533}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -6.706392723287672, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -6.828285854667337, 2: -6.861699743824332, 3: -6.803746447587916, 4: -7.0349052208818055}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -6.809831164671388, 4: -6.919590173558}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -7.096946359850963, 4: -6.919590173558}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -7.214562676567077, 4: -6.919590173558}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -7.214562676567077, 4: -7.19682705793778}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -6.929273796853302, 2: -7.08167389487498, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.038827650566599, 1: -7.205639155136504, 2: -7.08167389487498, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.02356113887105, 2: -7.0897997367434735, 3: -7.169422270744985, 4: -7.211817349124533}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.08167389487498, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -6.828285854667337, 2: -6.861699743824332, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -6.828285854667337, 2: -6.861699743824332, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.113740127747277, 2: -6.861699743824332, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.608048892198838, 1: -6.822996904653199, 2: -6.694703382336752, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.919236353749552, 3: -6.96553704074963, 4: -6.871884038710439}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.919236353749552, 3: -6.96553704074963, 4: -6.871884038710439}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -6.887933570691486, 2: -6.919236353749552, 3: -6.96553704074963, 4: -7.1534144752265}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.694703382336752, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.52472503370482, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.52472503370482, 3: -6.78571490035894, 4: -6.457670644647184}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.52472503370482, 3: -6.78571490035894, 4: -6.776480286628938}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.31089156997065, 2: -7.378083897961509, 3: -7.454344381851295, 4: -7.49014086434247}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.404964146194282 -7.237642600596137 -7.120562245879452 -6.885664185831862 -6.705160922353588 \n",
      "-7.236184898958429 -7.131055788018454 -6.9107144530044256 -6.781369520350331 -6.712807617932132 \n",
      "-7.13181580075863 -6.880966659294292 -6.8015177716774815 -6.803946602531473 -6.723921904003614 \n",
      "-7.0897997367434735 -6.962414319031511 -6.919236353749552 -6.693976120448938 -6.504103925497455 \n",
      "-7.139078931768041 -6.938689577063492 -6.740644985824681 -6.574294675046708 -7.31089156997065 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.248031237545165, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.236184898958429}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.248031237545165, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.236184898958429}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.248031237545165, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.484928258052171}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.200476074658335, 2: -7.13181580075863, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.894824771543251, 2: -7.074429142988657, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.894824771543251, 2: -7.074429142988657, 3: -6.963871833792102, 4: -6.880966659294292}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8834421457449935, 1: -6.894824771543251, 2: -7.074429142988657, 3: -6.963871833792102, 4: -7.161679659957806}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.131055788018454, 2: -7.167930208618868, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -6.894824771543251, 2: -7.074429142988657, 3: -6.963871833792102, 4: -7.191756104049225}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -6.962414319031511, 2: -7.0211436796322255, 3: -7.040337360136268, 4: -7.165801256647977}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.169350805272437, 2: -6.938689577063492, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.800183560397894, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.800183560397894, 3: -6.911679971333269, 4: -6.740644985824681}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.800183560397894, 3: -6.911679971333269, 4: -7.03398693710046}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.574294675046708, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.492398925153393, 2: -7.378083897961509, 3: -7.454344381851295, 4: -7.49014086434247}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.404964146194282 -7.237642600596137 -7.120562245879452 -6.885664185831862 -6.705160922353588 \n",
      "-7.308052822090648 -7.167930208618868 -6.9107144530044256 -6.781369520350331 -6.712807617932132 \n",
      "-7.18676457410424 -6.963871833792102 -6.8015177716774815 -6.803946602531473 -6.723921904003614 \n",
      "-7.0897997367434735 -6.969765857714394 -6.919236353749552 -6.693976120448938 -6.504103925497455 \n",
      "-7.139078931768041 -7.0349052208818055 -6.822996904653199 -6.633677424853492 -7.378083897961509 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.316677480302787, 2: -7.275831385473248, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.237642600596137, 1: -7.316677480302787, 2: -7.275831385473248, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.486254766542485, 1: -7.316677480302787, 2: -7.275831385473248, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.156013478205083, 2: -7.120562245879452, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -6.885664185831862, 2: -6.957128813139883, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.925165990617282, 2: -6.8466818424271825, 3: -6.781369520350331, 4: -6.870053732442159}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.07746688258204, 2: -7.058748164370974, 3: -7.30131095780155, 4: -6.9107144530044256}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.07746688258204, 2: -7.058748164370974, 3: -7.30131095780155, 4: -6.9107144530044256}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.07746688258204, 2: -7.058748164370974, 3: -7.30131095780155, 4: -7.188750152234027}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.925165990617282, 2: -6.8466818424271825, 3: -7.1758156589686175, 4: -6.870053732442159}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.794733689616516, 2: -7.008036452382503, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.794733689616516, 2: -7.008036452382503, 3: -6.827962060863008, 4: -6.712807617932132}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -6.794733689616516, 2: -7.008036452382503, 3: -6.827962060863008, 4: -7.00865493231824}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.796816519405417, 2: -6.974981143960892, 3: -6.723921904003614, 4: -6.810169828361044}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.816146309319405, 2: -6.803946602531473, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.796816519405417, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -6.810169828361044}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.504103925497455, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.492398925153393, 2: -7.500298896279022, 3: -7.454344381851295, 4: -7.49014086434247}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.404964146194282 -7.316677480302787 -7.156013478205083 -6.935515517727309 -6.705160922353588 \n",
      "-7.308052822090648 -7.167930208618868 -7.07746688258204 -6.870053732442159 -6.827962060863008 \n",
      "-7.18676457410424 -6.963871833792102 -6.8015177716774815 -6.816146309319405 -6.810169828361044 \n",
      "-7.0897997367434735 -6.969765857714394 -6.919236353749552 -6.693976120448938 -6.593144998866377 \n",
      "-7.139078931768041 -7.0349052208818055 -6.822996904653199 -6.633677424853492 -7.454344381851295 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.488348303504065, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.622015005219222}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.404964146194282, 1: -7.488348303504065, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.622015005219222}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.638517373036797, 1: -7.488348303504065, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.622015005219222}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.488348303504065, 2: -7.455475865429821, 3: -7.4259886201693295, 4: -7.622015005219222}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.488348303504065, 2: -7.455475865429821, 3: -7.65764964435409, 4: -7.622015005219222}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.316677480302787, 2: -7.395238557709681, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.197913643751879, 2: -7.167930208618868, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.07746688258204, 2: -7.151687108803115, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.99685609179822, 2: -6.818570121178079, 3: -6.8015177716774815, 4: -7.108888952001433}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.074429142988657, 3: -6.963871833792102, 4: -7.191756104049225}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.200476074658335, 2: -7.18676457410424, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.074429142988657, 3: -7.417666488403645, 4: -7.191756104049225}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.99685609179822, 2: -6.818570121178079, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -6.816146309319405, 2: -7.085816040971535, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.696856897875594, 2: -6.693976120448938, 3: -6.88163654789552, 4: -6.942212021436038}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.593144998866377, 1: -6.688429341849295, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.848005831593481, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -6.810169828361044}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.848005831593481, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -6.810169828361044}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.837370747930186, 1: -6.848005831593481, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -7.09725454380855}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -7.025850111204579, 2: -7.008036452382503, 3: -6.827962060863008, 4: -7.104599781821202}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.925165990617282, 2: -7.022042354767746, 3: -7.1758156589686175, 4: -6.870053732442159}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.925165990617282, 2: -7.022042354767746, 3: -7.1758156589686175, 4: -6.870053732442159}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -6.925165990617282, 2: -7.022042354767746, 3: -7.1758156589686175, 4: -7.151748896522364}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -7.00373528849558, 2: -7.085816040971535, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -7.00373528849558, 2: -7.085816040971535, 3: -7.022057286523627, 4: -6.864430839047458}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.879593854356779, 1: -7.00373528849558, 2: -7.085816040971535, 3: -7.022057286523627, 4: -7.146632063533186}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.93367264263785, 1: -7.152705578690169, 2: -7.022042354767746, 3: -7.1758156589686175, 4: -7.224559342052236}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -7.081475730066954, 2: -6.957128813139883, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935515517727309, 1: -7.081475730066954, 2: -6.957128813139883, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.211319121131851, 1: -7.081475730066954, 2: -6.957128813139883, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -6.705160922353588}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -6.705160922353588}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -7.0016964393417656}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.722158729693156, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -7.045118214985633}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.017164444020772, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -7.045118214985633}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -6.924410775641636, 2: -6.731533661305797, 3: -7.021078855730505, 4: -7.045118214985633}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -6.924410775641636, 2: -7.025695631788275, 3: -7.021078855730505, 4: -7.045118214985633}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805067037997, 1: -7.025850111204579, 2: -7.008036452382503, 3: -7.14753972936445, 4: -7.104599781821202}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.021078855730505, 4: -7.045118214985633}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.081475730066954, 2: -7.026893228420395, 3: -6.973115324506718, 4: -6.991367917270679}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.156013478205083, 2: -7.189444215111754, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.116976083316964, 2: -7.151687108803115, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -6.99685609179822, 2: -7.102935522666526, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -7.011503096761918, 2: -6.919236353749552, 3: -6.96553704074963, 4: -7.194567639782754}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.696856897875594, 2: -6.90984506112666, 3: -6.88163654789552, 4: -6.942212021436038}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.633677424853492, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.492398925153393, 2: -7.500298896279022, 3: -7.643455396602498, 4: -7.49014086434247}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.488348303504065 -7.348535557333183 -7.165003254919245 -6.991367917270679 -7.045118214985633 \n",
      "-7.308052822090648 -7.197913643751879 -7.151461343063891 -7.022042354767746 -7.008036452382503 \n",
      "-7.190511268276968 -7.13048471245311 -7.08225601425718 -7.00373528849558 -6.848005831593481 \n",
      "-7.0897997367434735 -6.969765857714394 -6.96553704074963 -6.8488256829008085 -6.619455799153064 \n",
      "-7.139078931768041 -7.0349052208818055 -6.822996904653199 -6.677505019646254 -7.49014086434247 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.488348303504065, 2: -7.57205634558824, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.401573922369007, 2: -7.308052822090648, 3: -7.402139401722363, 4: -7.5193981282168005}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.197913643751879, 2: -7.349541195753339, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.13048471245311, 3: -7.417666488403645, 4: -7.191756104049225}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08225601425718, 1: -7.204267055716959, 2: -7.102935522666526, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.151461343063891, 1: -7.279151042688254, 2: -7.151687108803115, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.189444215111754, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.189444215111754, 3: -7.302523053103767, 4: -7.165003254919245}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.189444215111754, 3: -7.302523053103767, 4: -7.420152961976513}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.081475730066954, 2: -7.026893228420395, 3: -7.39368244979679, 4: -6.991367917270679}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.081475730066954, 2: -7.026893228420395, 3: -7.39368244979679, 4: -6.991367917270679}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.081475730066954, 2: -7.026893228420395, 3: -7.39368244979679, 4: -7.262144804716318}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.045118214985633}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.045118214985633}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.3110575756369265}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.054258710059773, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.345055312712108}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.319375426154393, 1: -7.139163181864941, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.345055312712108}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.025850111204579, 2: -7.008036452382503, 3: -7.14753972936445, 4: -7.104599781821202}, Best action: 2, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.025850111204579, 2: -7.008036452382503, 3: -7.14753972936445, 4: -7.104599781821202}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.025850111204579, 2: -7.008036452382503, 3: -7.14753972936445, 4: -7.286969504611948}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.025850111204579, 2: -7.2773131716680775, 3: -7.14753972936445, 4: -7.286969504611948}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -6.848005831593481, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.688429341849295, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.688429341849295, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.619455799153064}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.688429341849295, 2: -6.781091137559319, 3: -6.75409348139312, 4: -6.923704777229289}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.492398925153393, 2: -7.500298896279022, 3: -7.643455396602498, 4: -7.714576212272539}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.568357616243832 -7.348535557333183 -7.281952434500425 -7.081475730066954 -7.2113422914485525 \n",
      "-7.401573922369007 -7.216968221271856 -7.151687108803115 -7.022042354767746 -7.14753972936445 \n",
      "-7.190511268276968 -7.191756104049225 -7.102935522666526 -7.00373528849558 -6.94655978047333 \n",
      "-7.0897997367434735 -6.969765857714394 -6.96553704074963 -6.8488256829008085 -6.7376860635591775 \n",
      "-7.139078931768041 -7.0349052208818055 -6.822996904653199 -6.677505019646254 -7.492398925153393 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.401573922369007, 2: -7.461115333648087, 3: -7.402139401722363, 4: -7.5193981282168005}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.200476074658335, 2: -7.348964063231236, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.200476074658335, 2: -7.348964063231236, 3: -7.190511268276968, 4: -7.205571899931182}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.200476074658335, 2: -7.348964063231236, 3: -7.443365254132041, 4: -7.205571899931182}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.0897997367434735, 3: -7.169422270744985, 4: -7.211817349124533}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969765857714394, 1: -7.21657998932458, 2: -7.0211436796322255, 3: -7.040337360136268, 4: -7.165801256647977}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.349675842793627, 3: -7.417666488403645, 4: -7.191756104049225}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.349675842793627, 3: -7.417666488403645, 4: -7.191756104049225}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.229038075569849, 2: -7.349675842793627, 3: -7.417666488403645, 4: -7.444498054684795}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.21657998932458, 2: -7.0211436796322255, 3: -7.040337360136268, 4: -7.165801256647977}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -7.011503096761918, 2: -7.016377722654187, 3: -6.96553704074963, 4: -7.194567639782754}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.21657998932458, 2: -7.244199370970423, 3: -7.040337360136268, 4: -7.165801256647977}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.254490318423007, 3: -7.169422270744985, 4: -7.211817349124533}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.254490318423007, 3: -7.169422270744985, 4: -7.211817349124533}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.254490318423007, 3: -7.424174266377936, 4: -7.211817349124533}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.254490318423007, 3: -7.483989479428665, 4: -7.211817349124533}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.254490318423007, 3: -7.483989479428665, 4: -7.462753787703325}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.21657998932458, 2: -7.244199370970423, 3: -7.411265775317064, 4: -7.165801256647977}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.21657998932458, 2: -7.244199370970423, 3: -7.411265775317064, 4: -7.165801256647977}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.21657998932458, 2: -7.244199370970423, 3: -7.411265775317064, 4: -7.4208791435496595}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.169350805272437, 2: -7.053791396224341, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.169350805272437, 2: -7.053791396224341, 3: -7.096337888142616, 4: -7.0349052208818055}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.169350805272437, 2: -7.053791396224341, 3: -7.096337888142616, 4: -7.301763751002444}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.9051970428276235, 3: -6.911679971333269, 4: -7.11154737763234}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -6.822996904653199, 2: -6.9051970428276235, 3: -6.911679971333269, 4: -7.11154737763234}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.108927183234411, 2: -6.9051970428276235, 3: -6.911679971333269, 4: -7.11154737763234}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.677505019646254, 1: -6.732808901260664, 2: -6.73038184260275, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8488256829008085, 1: -6.9429644039188885, 2: -6.90984506112666, 3: -6.88163654789552, 4: -6.942212021436038}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.00373528849558, 2: -7.085816040971535, 3: -7.022057286523627, 4: -7.18713422838231}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -6.9429644039188885, 2: -6.90984506112666, 3: -6.88163654789552, 4: -6.942212021436038}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998329599857785, 1: -7.011503096761918, 2: -7.016377722654187, 3: -7.299226965785341, 4: -7.194567639782754}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.204267055716959, 2: -7.102935522666526, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.17449913264493, 2: -7.085816040971535, 3: -7.022057286523627, 4: -7.18713422838231}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.204267055716959, 2: -7.2981599543507905, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.204267055716959, 2: -7.2981599543507905, 3: -7.220887962539351, 4: -7.108888952001433}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.204267055716959, 2: -7.2981599543507905, 3: -7.220887962539351, 4: -7.369088946321304}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.011503096761918, 2: -7.016377722654187, 3: -7.299226965785341, 4: -7.194567639782754}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.204102323013816, 2: -6.999298770196228, 3: -6.911679971333269, 4: -7.11154737763234}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.069811472550221, 1: -7.169350805272437, 2: -7.132006632391525, 3: -7.096337888142616, 4: -7.3437474060419605}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.319931227846721, 2: -7.244199370970423, 3: -7.411265775317064, 4: -7.487517705707876}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.19961108645614, 2: -7.016377722654187, 3: -7.299226965785341, 4: -7.194567639782754}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -6.9429644039188885, 2: -6.90984506112666, 3: -7.256810630674358, 4: -6.942212021436038}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.7376860635591775, 2: -6.781091137559319, 3: -6.75409348139312, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.644514769634235, 2: -7.500298896279022, 3: -7.643455396602498, 4: -7.714576212272539}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.568357616243832 -7.348535557333183 -7.281952434500425 -7.081475730066954 -7.2113422914485525 \n",
      "-7.402139401722363 -7.216968221271856 -7.151687108803115 -7.022042354767746 -7.14753972936445 \n",
      "-7.205571899931182 -7.310030188059088 -7.220887962539351 -7.085816040971535 -6.94655978047333 \n",
      "-7.263171696974358 -7.3076858924469335 -7.194567639782754 -6.942212021436038 -6.749010712341926 \n",
      "-7.139078931768041 -7.096337888142616 -6.999298770196228 -6.73038184260275 -7.500298896279022 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.4376912170115625, 2: -7.395238557709681, 3: -7.348535557333183, 4: -7.352779255007375}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.568357616243832, 2: -7.57205634558824, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.464471519541245, 2: -7.461115333648087, 3: -7.402139401722363, 4: -7.5193981282168005}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.464471519541245, 2: -7.461115333648087, 3: -7.402139401722363, 4: -7.5193981282168005}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.464471519541245, 2: -7.461115333648087, 3: -7.635946855567351, 4: -7.5193981282168005}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.395483981462207, 2: -7.349541195753339, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.395483981462207, 2: -7.349541195753339, 3: -7.392566332680849, 4: -7.216968221271856}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.395483981462207, 2: -7.349541195753339, 3: -7.392566332680849, 4: -7.467441081357389}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.279151042688254, 2: -7.151687108803115, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.211134833622905, 1: -7.152705578690169, 2: -7.022042354767746, 3: -7.1758156589686175, 4: -7.224559342052236}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.149469734711178, 2: -7.318669907242517, 3: -7.14753972936445, 4: -7.286969504611948}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.211134833622905, 1: -7.152705578690169, 2: -7.391711416261979, 3: -7.1758156589686175, 4: -7.224559342052236}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.17449913264493, 2: -7.085816040971535, 3: -7.360405779773523, 4: -7.18713422838231}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -6.94655978047333, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.749010712341926, 2: -6.781091137559319, 3: -6.75409348139312, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.545699539147204, 1: -7.644514769634235, 2: -7.60234369106778, 3: -7.643455396602498, 4: -7.714576212272539}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.57205634558824 -7.352779255007375 -7.281952434500425 -7.081475730066954 -7.2113422914485525 \n",
      "-7.464471519541245 -7.38940049293709 -7.279151042688254 -7.1758156589686175 -7.149469734711178 \n",
      "-7.205571899931182 -7.310030188059088 -7.220887962539351 -7.17449913264493 -6.974981143960892 \n",
      "-7.263171696974358 -7.3076858924469335 -7.194567639782754 -6.942212021436038 -6.75409348139312 \n",
      "-7.139078931768041 -7.096337888142616 -6.999298770196228 -6.73038184260275 -7.545699539147204 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.652568677019498, 2: -7.57205634558824, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.4376912170115625, 2: -7.395238557709681, 3: -7.765223224890822, 4: -7.352779255007375}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.4376912170115625, 2: -7.395238557709681, 3: -7.765223224890822, 4: -7.352779255007375}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.4376912170115625, 2: -7.395238557709681, 3: -7.765223224890822, 4: -7.591029122056711}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.281952434500425, 3: -7.302523053103767, 4: -7.465465110438172}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.081475730066954, 2: -7.309235076980403, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.211134833622905, 1: -7.35478155105596, 2: -7.391711416261979, 3: -7.1758156589686175, 4: -7.224559342052236}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.279151042688254, 2: -7.303023018242186, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.299744213948849, 2: -7.2981599543507905, 3: -7.220887962539351, 4: -7.4723652097628666}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.310030188059088, 2: -7.349675842793627, 3: -7.417666488403645, 4: -7.499970646680057}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.319931227846721, 2: -7.3076858924469335, 3: -7.411265775317064, 4: -7.487517705707876}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.19961108645614, 2: -7.198612271778013, 3: -7.299226965785341, 4: -7.194567639782754}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.19961108645614, 2: -7.198612271778013, 3: -7.299226965785341, 4: -7.194567639782754}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.19961108645614, 2: -7.198612271778013, 3: -7.299226965785341, 4: -7.447056552202306}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -6.9429644039188885, 2: -7.0485102175956005, 3: -7.256810630674358, 4: -6.942212021436038}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -6.9429644039188885, 2: -7.0485102175956005, 3: -7.256810630674358, 4: -6.942212021436038}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -6.9429644039188885, 2: -7.0485102175956005, 3: -7.256810630674358, 4: -7.2174129395067945}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -6.732808901260664, 2: -6.73038184260275, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.644514769634235, 2: -7.60234369106778, 3: -7.643455396602498, 4: -7.714576212272539}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.612956831114798 -7.4376912170115625 -7.302523053103767 -7.25640625075649 -7.2113422914485525 \n",
      "-7.464471519541245 -7.38940049293709 -7.30131095780155 -7.211134833622905 -7.149469734711178 \n",
      "-7.205571899931182 -7.349675842793627 -7.2981599543507905 -7.17449913264493 -6.974981143960892 \n",
      "-7.263171696974358 -7.319931227846721 -7.19961108645614 -7.045905732900117 -6.75409348139312 \n",
      "-7.139078931768041 -7.096337888142616 -6.999298770196228 -6.732808901260664 -7.60234369106778 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.4376912170115625, 2: -7.537905327716312, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38940049293709, 1: -7.395483981462207, 2: -7.427820677705857, 3: -7.392566332680849, 4: -7.599872476695944}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.629183520980199, 2: -7.537905327716312, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.364190584804276, 3: -7.302523053103767, 4: -7.465465110438172}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.629183520980199, 2: -7.568834205785683, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.54204889888758, 1: -7.629183520980199, 2: -7.568834205785683, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.763264497987698, 1: -7.629183520980199, 2: -7.568834205785683, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.364190584804276, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362137128963964, 1: -7.380351975307249, 2: -7.364190584804276, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.599544787357207, 1: -7.380351975307249, 2: -7.364190584804276, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.420558256771275, 2: -7.309235076980403, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25640625075649, 1: -7.420558256771275, 2: -7.309235076980403, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.503329688188406, 1: -7.420558256771275, 2: -7.309235076980403, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.345055312712108}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.2113422914485525, 3: -7.250331298423492, 4: -7.345055312712108}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.462321485218183, 3: -7.250331298423492, 4: -7.345055312712108}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.420558256771275, 2: -7.472110763771368, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.420558256771275, 2: -7.472110763771368, 3: -7.39368244979679, 4: -7.317997995492151}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.420558256771275, 2: -7.472110763771368, 3: -7.39368244979679, 4: -7.559378175897858}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.380351975307249, 2: -7.514108121593185, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.4768343539257, 2: -7.303023018242186, 3: -7.30131095780155, 4: -7.3364610283638925}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.395483981462207, 2: -7.427820677705857, 3: -7.392566332680849, 4: -7.599872476695944}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.464471519541245, 2: -7.491855792595013, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.362785394228046, 2: -7.348964063231236, 3: -7.4767221458864555, 4: -7.205571899931182}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.362785394228046, 2: -7.348964063231236, 3: -7.4767221458864555, 4: -7.205571899931182}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.362785394228046, 2: -7.348964063231236, 3: -7.4767221458864555, 4: -7.457070428937375}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.550228591687925, 2: -7.349675842793627, 3: -7.417666488403645, 4: -7.499970646680057}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.299744213948849, 2: -7.2981599543507905, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.17449913264493, 2: -7.235295026280551, 3: -7.360405779773523, 4: -7.18713422838231}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.045905732900117, 2: -7.0485102175956005, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -6.732808901260664, 2: -6.830936574025177, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -6.732808901260664, 2: -6.830936574025177, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.026856100147204, 2: -6.830936574025177, 3: -6.78571490035894, 4: -6.862675305963799}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.204102323013816, 2: -6.999298770196228, 3: -7.317715289899006, 4: -7.11154737763234}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.830936574025177, 3: -7.248003493894839, 4: -6.862675305963799}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.644514769634235, 2: -7.684764254886144, 3: -7.643455396602498, 4: -7.714576212272539}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.612956831114798 -7.620214495039379 -7.465465110438172 -7.420558256771275 -7.345055312712108 \n",
      "-7.4829603908983815 -7.395483981462207 -7.303023018242186 -7.211134833622905 -7.149469734711178 \n",
      "-7.362785394228046 -7.3644994028694475 -7.299744213948849 -7.18713422838231 -6.974981143960892 \n",
      "-7.263171696974358 -7.319931227846721 -7.19961108645614 -7.0485102175956005 -6.75409348139312 \n",
      "-7.139078931768041 -7.096337888142616 -7.11154737763234 -6.862675305963799 -7.643455396602498 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.652568677019498, 2: -7.612956831114798, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.629183520980199, 2: -7.620214495039379, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.552097073349981, 2: -7.514108121593185, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.552097073349981, 2: -7.514108121593185, 3: -7.739311913409316, 4: -7.465465110438172}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.552097073349981, 2: -7.514108121593185, 3: -7.739311913409316, 4: -7.693573250498737}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.420558256771275, 2: -7.472110763771368, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.211134833622905, 1: -7.35478155105596, 2: -7.391711416261979, 3: -7.513693910474348, 4: -7.224559342052236}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.483075040911681, 2: -7.472110763771368, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.345055312712108}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.345055312712108}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.368642141461668, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.584000334568018}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.149469734711178, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.286969504611948}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.061354655044294, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.061354655044294, 2: -6.974981143960892, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.061354655044294, 2: -7.247232841004411, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.786917697943428, 2: -6.781091137559319, 3: -6.75409348139312, 4: -7.009998244620858}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.058165783311149, 2: -7.0485102175956005, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.786917697943428, 2: -6.781091137559319, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.786917697943428, 2: -6.781091137559319, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.786917697943428, 2: -7.0707929351789796, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 1, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.786917697943428, 2: -7.3344215710128715, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.644514769634235, 2: -7.684764254886144, 3: -7.830840572863236, 4: -7.714576212272539}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.622015005219222 -7.629183520980199 -7.552097073349981 -7.483075040911681 -7.414659719926041 \n",
      "-7.4829603908983815 -7.395483981462207 -7.303023018242186 -7.224559342052236 -7.26468170007944 \n",
      "-7.362785394228046 -7.3644994028694475 -7.299744213948849 -7.18713422838231 -7.076951185432857 \n",
      "-7.263171696974358 -7.319931227846721 -7.19961108645614 -7.058165783311149 -6.870748733198073 \n",
      "-7.139078931768041 -7.096337888142616 -7.11154737763234 -6.862675305963799 -7.644514769634235 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.4829603908983815, 2: -7.491855792595013, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.362785394228046, 2: -7.588133838985962, 3: -7.4767221458864555, 4: -7.598367934111039}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.263171696974358, 1: -7.338511968735839, 2: -7.429748049727162, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.386153548427021, 1: -7.5194476139720345, 2: -7.588133838985962, 3: -7.4767221458864555, 4: -7.598367934111039}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.483179577269899, 1: -7.612152208414556, 2: -7.491855792595013, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.652568677019498, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.652568677019498, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.622015005219222}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.652568677019498, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.836033654749492}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.612152208414556, 2: -7.491855792595013, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.395483981462207, 2: -7.427820677705857, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3644994028694475, 1: -7.550228591687925, 2: -7.546477147303503, 3: -7.417666488403645, 4: -7.499970646680057}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.427820677705857, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.4768343539257, 2: -7.303023018242186, 3: -7.618109825251643, 4: -7.3364610283638925}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.35478155105596, 2: -7.391711416261979, 3: -7.513693910474348, 4: -7.224559342052236}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.35478155105596, 2: -7.391711416261979, 3: -7.513693910474348, 4: -7.224559342052236}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.35478155105596, 2: -7.391711416261979, 3: -7.513693910474348, 4: -7.474349001267535}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.324633556913588, 2: -7.235295026280551, 3: -7.360405779773523, 4: -7.18713422838231}, Best action: 4, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.076951185432857, 2: -7.3444205546863195, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.870748733198073, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.725649393591112, 2: -7.684764254886144, 3: -7.830840572863236, 4: -7.714576212272539}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.678902519640837 -7.629183520980199 -7.552097073349981 -7.483075040911681 -7.414659719926041 \n",
      "-7.5193981282168005 -7.558230712546757 -7.3364610283638925 -7.391711416261979 -7.26468170007944 \n",
      "-7.4767221458864555 -7.417666488403645 -7.299744213948849 -7.18713422838231 -7.0835889384508555 \n",
      "-7.338511968735839 -7.319931227846721 -7.19961108645614 -7.058165783311149 -6.911733919777584 \n",
      "-7.139078931768041 -7.096337888142616 -7.11154737763234 -6.862675305963799 -7.684764254886144 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.629183520980199, 2: -7.709048188958858, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.558230712546757, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.4768343539257, 2: -7.482195368886529, 3: -7.618109825251643, 4: -7.3364610283638925}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.4768343539257, 2: -7.482195368886529, 3: -7.618109825251643, 4: -7.3364610283638925}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.418798770790978, 1: -7.4768343539257, 2: -7.482195368886529, 3: -7.618109825251643, 4: -7.576179535811142}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.552097073349981, 2: -7.662063000144052, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.4768343539257, 2: -7.482195368886529, 3: -7.618109825251643, 4: -7.666844957921807}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.299744213948849, 2: -7.4411602928774725, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.19961108645614, 2: -7.2430529645409925, 3: -7.299226965785341, 4: -7.475581595360421}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.204102323013816, 2: -7.132988501980016, 3: -7.317715289899006, 4: -7.11154737763234}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.204102323013816, 2: -7.132988501980016, 3: -7.317715289899006, 4: -7.11154737763234}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.127030960575339, 1: -7.204102323013816, 2: -7.132988501980016, 3: -7.317715289899006, 4: -7.3715081136454295}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.380314484527809, 2: -7.2430529645409925, 3: -7.299226965785341, 4: -7.475581595360421}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.058165783311149, 2: -7.097534843182608, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.874292528650542, 3: -7.248003493894839, 4: -6.862675305963799}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.874292528650542, 3: -7.248003493894839, 4: -6.862675305963799}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.874292528650542, 3: -7.248003493894839, 4: -7.145034528427057}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.725649393591112, 2: -7.848115077482575, 3: -7.830840572863236, 4: -7.714576212272539}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.678902519640837 -7.649246143950513 -7.624948852427185 -7.483075040911681 -7.414659719926041 \n",
      "-7.5193981282168005 -7.598356504229429 -7.482195368886529 -7.391711416261979 -7.26468170007944 \n",
      "-7.4767221458864555 -7.417666488403645 -7.40090928930747 -7.18713422838231 -7.0835889384508555 \n",
      "-7.338511968735839 -7.319931227846721 -7.299226965785341 -7.097534843182608 -6.911733919777584 \n",
      "-7.139078931768041 -7.096337888142616 -7.132988501980016 -6.936235984805811 -7.714576212272539 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.73366005970391, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.8821839938607425}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.678902519640837, 1: -7.73366005970391, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.8821839938607425}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887801292873162, 1: -7.73366005970391, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.8821839938607425}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.73366005970391, 2: -7.833669424093377, 3: -7.704700415433564, 4: -7.8821839938607425}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.73366005970391, 2: -7.833669424093377, 3: -7.911277378044543, 4: -7.8821839938607425}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.612152208414556, 2: -7.639527604243889, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.612152208414556, 2: -7.639527604243889, 3: -7.707098105811686, 4: -7.5193981282168005}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.612152208414556, 2: -7.639527604243889, 3: -7.707098105811686, 4: -7.742652296677289}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.5194476139720345, 2: -7.588133838985962, 3: -7.4767221458864555, 4: -7.598367934111039}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.5194476139720345, 2: -7.588133838985962, 3: -7.4767221458864555, 4: -7.598367934111039}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.5194476139720345, 2: -7.588133838985962, 3: -7.703817152756675, 4: -7.598367934111039}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.338511968735839, 2: -7.429748049727162, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.139078931768041, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.169350805272437, 2: -7.132006632391525, 3: -7.096337888142616, 4: -7.3437474060419605}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.214562676567077, 4: -7.2323944812449525}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.46525203567604, 4: -7.2323944812449525}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.504764733376016, 4: -7.2323944812449525}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2929672875422105, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.504764733376016, 4: -7.481478977932907}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.416505131605697, 2: -7.429748049727162, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.322014312472596, 2: -7.361941582572323, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.563033024350062, 2: -7.361941582572323, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.169350805272437, 2: -7.132006632391525, 3: -7.453429556833594, 4: -7.3437474060419605}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.204102323013816, 2: -7.132988501980016, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.936235984805811, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.725649393591112, 2: -7.848115077482575, 3: -7.830840572863236, 4: -7.8913686621363315}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.764078489825999 -7.649246143950513 -7.624948852427185 -7.483075040911681 -7.414659719926041 \n",
      "-7.639527604243889 -7.598356504229429 -7.482195368886529 -7.391711416261979 -7.26468170007944 \n",
      "-7.588133838985962 -7.417666488403645 -7.40090928930747 -7.18713422838231 -7.0835889384508555 \n",
      "-7.429748049727162 -7.319931227846721 -7.299226965785341 -7.097534843182608 -6.911733919777584 \n",
      "-7.4131195304943684 -7.169350805272437 -7.204102323013816 -6.951399607289382 -7.725649393591112 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.717360159009485, 2: -7.639527604243889, 3: -7.707098105811686, 4: -7.840108518483519}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.598356504229429, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.560476248691138, 2: -7.482195368886529, 3: -7.618109825251643, 4: -7.666844957921807}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.496067126392843, 2: -7.391711416261979, 3: -7.513693910474348, 4: -7.604807956482081}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.26468170007944, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.286969504611948}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.1730015924337245, 2: -7.3444205546863195, 3: -7.0835889384508555, 4: -7.147995760204306}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.324633556913588, 2: -7.355859962828669, 3: -7.360405779773523, 4: -7.18713422838231}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.324633556913588, 2: -7.355859962828669, 3: -7.360405779773523, 4: -7.18713422838231}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.204234225972337, 1: -7.324633556913588, 2: -7.355859962828669, 3: -7.360405779773523, 4: -7.440292147827901}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.496067126392843, 2: -7.523563318690544, 3: -7.513693910474348, 4: -7.604807956482081}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.324633556913588, 2: -7.355859962828669, 3: -7.360405779773523, 4: -7.479458937820383}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.1645835761617915, 2: -7.097534843182608, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.911733919777584, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.787935593841194, 1: -7.860582298796661, 2: -7.848115077482575, 3: -7.830840572863236, 4: -7.8913686621363315}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.764078489825999 -7.649246143950513 -7.624948852427185 -7.483075040911681 -7.414659719926041 \n",
      "-7.707098105811686 -7.599872476695944 -7.560476248691138 -7.513693910474348 -7.271854379845509 \n",
      "-7.588133838985962 -7.417666488403645 -7.40090928930747 -7.355859962828669 -7.114386344092056 \n",
      "-7.429748049727162 -7.319931227846721 -7.299226965785341 -7.1645835761617915 -6.9994012229891265 \n",
      "-7.4131195304943684 -7.169350805272437 -7.204102323013816 -6.951399607289382 -7.787935593841194 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.764078489825999, 2: -7.833669424093377, 3: -7.955392386164622, 4: -7.8821839938607425}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.717360159009485, 2: -7.818621528850226, 3: -7.707098105811686, 4: -7.840108518483519}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.717360159009485, 2: -7.818621528850226, 3: -7.707098105811686, 4: -7.840108518483519}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.717360159009485, 2: -7.818621528850226, 3: -7.913459276288634, 4: -7.840108518483519}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.596139456073233, 2: -7.588133838985962, 3: -7.761134282593016, 4: -7.598367934111039}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.550228591687925, 2: -7.546477147303503, 3: -7.417666488403645, 4: -7.499970646680057}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.596139456073233, 2: -7.667123239505549, 3: -7.761134282593016, 4: -7.598367934111039}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.429748049727162, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.319931227846721, 2: -7.458368377468724, 3: -7.411265775317064, 4: -7.487517705707876}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.169350805272437, 2: -7.390921349842965, 3: -7.453429556833594, 4: -7.3437474060419605}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.169350805272437, 2: -7.390921349842965, 3: -7.453429556833594, 4: -7.3437474060419605}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.4241092327979175, 2: -7.390921349842965, 3: -7.453429556833594, 4: -7.3437474060419605}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.59084632217378, 2: -7.390921349842965, 3: -7.453429556833594, 4: -7.3437474060419605}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.59084632217378, 2: -7.390921349842965, 3: -7.453429556833594, 4: -7.582810139498185}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.204102323013816, 2: -7.231649997890709, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.204102323013816, 2: -7.231649997890709, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.455733113942573, 2: -7.231649997890709, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -6.951399607289382, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.967697136143179, 1: -7.860582298796661, 2: -7.848115077482575, 3: -7.830840572863236, 4: -7.8913686621363315}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.833669424093377 -7.649246143950513 -7.624948852427185 -7.483075040911681 -7.414659719926041 \n",
      "-7.818124425479577 -7.599872476695944 -7.560476248691138 -7.513693910474348 -7.271854379845509 \n",
      "-7.598367934111039 -7.499970646680057 -7.40090928930747 -7.355859962828669 -7.114386344092056 \n",
      "-7.483989479428665 -7.411265775317064 -7.299226965785341 -7.1645835761617915 -6.9994012229891265 \n",
      "-7.4131195304943684 -7.453429556833594 -7.25379868169347 -7.03812082474816 -7.830840572863236 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.919157314690065, 2: -7.833669424093377, 3: -7.955392386164622, 4: -7.8821839938607425}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.785085229260893, 2: -7.709048188958858, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.785085229260893, 2: -7.709048188958858, 3: -7.765223224890822, 4: -7.649246143950513}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.785085229260893, 2: -7.709048188958858, 3: -7.765223224890822, 4: -7.860813990994966}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.711445534014815, 2: -7.662063000144052, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.624948852427185, 1: -7.711445534014815, 2: -7.662063000144052, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.838703455708738, 1: -7.711445534014815, 2: -7.662063000144052, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.483075040911681, 2: -7.596705879673944, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.58255989373929, 2: -7.523563318690544, 3: -7.513693910474348, 4: -7.604807956482081}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.560476248691138, 2: -7.635505784060856, 3: -7.618109825251643, 4: -7.666844957921807}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.40090928930747, 1: -7.461659401424359, 2: -7.4411602928774725, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.650784149208165, 2: -7.635505784060856, 3: -7.618109825251643, 4: -7.666844957921807}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.7204138992210325, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.7204138992210325, 3: -7.685478564096494, 4: -7.599872476695944}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.604792914470473, 2: -7.7204138992210325, 3: -7.685478564096494, 4: -7.815883953793309}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.550228591687925, 2: -7.546477147303503, 3: -7.794639608259684, 4: -7.499970646680057}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.550228591687925, 2: -7.546477147303503, 3: -7.794639608259684, 4: -7.499970646680057}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.550228591687925, 2: -7.546477147303503, 3: -7.794639608259684, 4: -7.724973288478852}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.461659401424359, 2: -7.4411602928774725, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.381466578669271, 2: -7.355859962828669, 3: -7.360405779773523, 4: -7.479458937820383}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.114386344092056, 1: -7.1730015924337245, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.147995760204306}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.271854379845509, 1: -7.364175210153137, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.286969504611948}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.427934699262221, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.414659719926041, 1: -7.427934699262221, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.647340345132697, 1: -7.427934699262221, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.364175210153137, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.286969504611948}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.364175210153137, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.286969504611948}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.364175210153137, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.531142249196873}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.364175210153137, 2: -7.318669907242517, 3: -7.408445491675481, 4: -7.581236849786126}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.364175210153137, 2: -7.559989615590691, 3: -7.408445491675481, 4: -7.581236849786126}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.1730015924337245, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.147995760204306}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.1730015924337245, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.147995760204306}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.1730015924337245, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.404676141785918}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -6.9994012229891265, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.967697136143179, 1: -7.860582298796661, 2: -7.848115077482575, 3: -8.028356290801959, 4: -7.8913686621363315}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.8792563190092535 -7.765223224890822 -7.711445534014815 -7.570813381172967 -7.5190005002448475 \n",
      "-7.818124425479577 -7.685478564096494 -7.635505784060856 -7.523563318690544 -7.408445491675481 \n",
      "-7.598367934111039 -7.550228591687925 -7.461659401424359 -7.360405779773523 -7.286815149864565 \n",
      "-7.483989479428665 -7.411265775317064 -7.299226965785341 -7.1645835761617915 -7.009998244620858 \n",
      "-7.4131195304943684 -7.453429556833594 -7.25379868169347 -7.03812082474816 -7.848115077482575 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.785085229260893, 2: -7.847113389361906, 3: -7.765223224890822, 4: -7.930410432156171}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.919157314690065, 2: -7.8792563190092535, 3: -7.955392386164622, 4: -7.8821839938607425}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.785085229260893, 2: -7.847113389361906, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.735455515257894, 2: -7.7204138992210325, 3: -7.685478564096494, 4: -7.841470656100414}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.818124425479577, 2: -7.818621528850226, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.6777098658863245, 2: -7.667123239505549, 3: -7.761134282593016, 4: -7.598367934111039}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.6777098658863245, 2: -7.667123239505549, 3: -7.761134282593016, 4: -7.598367934111039}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.6777098658863245, 2: -7.667123239505549, 3: -7.761134282593016, 4: -7.814514820041046}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.550228591687925, 2: -7.681987551961103, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.439167275055346, 2: -7.458368377468724, 3: -7.411265775317064, 4: -7.487517705707876}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.572119099528559, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.572119099528559, 3: -7.483989479428665, 4: -7.522412536692968}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.572119099528559, 3: -7.710430426280086, 4: -7.522412536692968}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.572119099528559, 3: -7.764197197349313, 4: -7.522412536692968}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.572119099528559, 3: -7.764197197349313, 4: -7.745395408390602}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.422299030051312, 1: -7.439167275055346, 2: -7.458368377468724, 3: -7.703158055868926, 4: -7.487517705707876}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652984689228689, 1: -7.658148137175615, 2: -7.681987551961103, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.735455515257894, 2: -7.7204138992210325, 3: -8.001228641048106, 4: -7.841470656100414}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.650784149208165, 2: -7.635505784060856, 3: -7.817707688648879, 4: -7.666844957921807}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.58255989373929, 2: -7.523563318690544, 3: -7.775355152487257, 4: -7.604807956482081}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.426294086780802, 2: -7.62098088178311, 3: -7.408445491675481, 4: -7.581236849786126}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.58255989373929, 2: -7.653197180126194, 3: -7.775355152487257, 4: -7.604807956482081}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.381466578669271, 2: -7.3982389349974325, 3: -7.360405779773523, 4: -7.479458937820383}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.461659401424359, 2: -7.60236259917897, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.380314484527809, 2: -7.34141958093613, 3: -7.299226965785341, 4: -7.475581595360421}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.439167275055346, 2: -7.458368377468724, 3: -7.703158055868926, 4: -7.487517705707876}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.59084632217378, 2: -7.474415016625487, 3: -7.453429556833594, 4: -7.644927307322621}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.4131195304943684, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.59084632217378, 2: -7.474415016625487, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.25379868169347, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -7.03812082474816, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.967697136143179, 1: -7.860582298796661, 2: -7.974642319909823, 3: -8.028356290801959, 4: -7.8913686621363315}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.8821839938607425 -7.807082156485173 -7.711445534014815 -7.570813381172967 -7.5190005002448475 \n",
      "-7.818621528850226 -7.735455515257894 -7.650784149208165 -7.604807956482081 -7.426294086780802 \n",
      "-7.6777098658863245 -7.658148137175615 -7.4723652097628666 -7.381466578669271 -7.286815149864565 \n",
      "-7.572482106263372 -7.458368377468724 -7.34141958093613 -7.1645835761617915 -7.009998244620858 \n",
      "-7.504764733376016 -7.4747826377410655 -7.317715289899006 -7.070883744500112 -7.860582298796661 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.8364904691779, 2: -7.818621528850226, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.735455515257894, 2: -7.856801075011397, 3: -8.001228641048106, 4: -7.841470656100414}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.658148137175615, 2: -7.681987551961103, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.681194668540746, 2: -7.458368377468724, 3: -7.703158055868926, 4: -7.487517705707876}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.380314484527809, 2: -7.34141958093613, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.1645835761617915, 2: -7.208257959338104, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -7.070883744500112, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.967697136143179, 1: -8.01914166824835, 2: -7.974642319909823, 3: -8.028356290801959, 4: -7.8913686621363315}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.8821839938607425 -7.807082156485173 -7.711445534014815 -7.570813381172967 -7.5190005002448475 \n",
      "-7.82215011195456 -7.744643364743922 -7.650784149208165 -7.604807956482081 -7.426294086780802 \n",
      "-7.6777098658863245 -7.681987551961103 -7.4723652097628666 -7.381466578669271 -7.286815149864565 \n",
      "-7.572482106263372 -7.487517705707876 -7.353210733345665 -7.208257959338104 -7.009998244620858 \n",
      "-7.504764733376016 -7.4747826377410655 -7.317715289899006 -7.099096990780439 -7.8913686621363315 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.919157314690065, 2: -7.99384466760225, 3: -7.955392386164622, 4: -7.8821839938607425}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.919157314690065, 2: -7.99384466760225, 3: -7.955392386164622, 4: -7.8821839938607425}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -7.919157314690065, 2: -7.99384466760225, 3: -7.955392386164622, 4: -8.072787434413275}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.82215011195456, 1: -7.8364904691779, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -8.027857322152201, 2: -7.99384466760225, 3: -7.955392386164622, 4: -8.12179616834028}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9295874657885035, 1: -8.027857322152201, 2: -7.99384466760225, 3: -7.955392386164622, 4: -8.12179616834028}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.115924593867538, 1: -8.027857322152201, 2: -7.99384466760225, 3: -7.955392386164622, 4: -8.12179616834028}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.027857322152201, 2: -7.99384466760225, 3: -7.955392386164622, 4: -8.12179616834028}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.027857322152201, 2: -7.99384466760225, 3: -8.139407071409805, 4: -8.12179616834028}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.90374615984425, 2: -7.847113389361906, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.807082156485173, 1: -7.90374615984425, 2: -7.847113389361906, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.004444762401508, 1: -7.90374615984425, 2: -7.847113389361906, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.711445534014815, 2: -7.727497083152867, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.650784149208165, 2: -7.757636866545426, 3: -7.817707688648879, 4: -7.666844957921807}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.5585397824285625, 2: -7.60236259917897, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.5585397824285625, 2: -7.60236259917897, 3: -7.543213248581797, 4: -7.4723652097628666}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.5585397824285625, 2: -7.60236259917897, 3: -7.543213248581797, 4: -7.699852340884209}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.707093199467228, 2: -7.681987551961103, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.5585397824285625, 2: -7.60236259917897, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.353210733345665, 1: -7.380314484527809, 2: -7.4374546547846645, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.611954672252844, 2: -7.60236259917897, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.381466578669271, 2: -7.3982389349974325, 3: -7.679984693131083, 4: -7.479458937820383}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.3438741906612695, 2: -7.208257959338104, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -7.056913335059798, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -7.056913335059798, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.009998244620858}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -7.056913335059798, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.279098402604981}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.967697136143179, 1: -8.01914166824835, 2: -7.974642319909823, 3: -8.028356290801959, 4: -8.073705901240833}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.023121013513215 -7.90374615984425 -7.727497083152867 -7.570813381172967 -7.5190005002448475 \n",
      "-7.8364904691779 -7.744643364743922 -7.666844957921807 -7.604807956482081 -7.426294086780802 \n",
      "-7.6777098658863245 -7.707093199467228 -7.611954672252844 -7.3982389349974325 -7.286815149864565 \n",
      "-7.572482106263372 -7.487517705707876 -7.380314484527809 -7.2455424611249795 -7.075552060859083 \n",
      "-7.504764733376016 -7.4747826377410655 -7.317715289899006 -7.099096990780439 -7.967697136143179 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.027857322152201, 2: -8.023121013513215, 3: -8.188954887898802, 4: -8.12179616834028}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.90374615984425, 2: -7.930982221488191, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.744643364743922, 1: -7.8766455426380375, 2: -7.856801075011397, 3: -8.001228641048106, 4: -7.841470656100414}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.963535741427002, 2: -7.930982221488191, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.963535741427002, 2: -7.930982221488191, 3: -8.058719940886578, 4: -7.930410432156171}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.963535741427002, 2: -7.930982221488191, 3: -8.058719940886578, 4: -8.116673493262116}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.727497083152867, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.73439957157539, 2: -7.596705879673944, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.570813381172967, 1: -7.73439957157539, 2: -7.596705879673944, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.789440176867401, 1: -7.73439957157539, 2: -7.596705879673944, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.5452387686619, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.5452387686619, 2: -7.5190005002448475, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.5452387686619, 2: -7.742290455222811, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.426294086780802, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.581236849786126}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.286815149864565, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075552060859083, 1: -7.159526013781955, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.359878684282314, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.359878684282314, 2: -7.3444205546863195, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.359878684282314, 2: -7.58342270476455, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.159526013781955, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.159526013781955, 2: -7.130845492435464, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.159526013781955, 2: -7.3890693981162725, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.01914166824835, 2: -7.974642319909823, 3: -8.028356290801959, 4: -8.073705901240833}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.027857322152201 -7.952370859502642 -7.739311913409316 -7.617453344978551 -7.552611506190992 \n",
      "-7.8364904691779 -7.841470656100414 -7.666844957921807 -7.604807956482081 -7.544949680068378 \n",
      "-7.6777098658863245 -7.707093199467228 -7.611954672252844 -7.3982389349974325 -7.411972717300958 \n",
      "-7.572482106263372 -7.487517705707876 -7.380314484527809 -7.2455424611249795 -7.175412880505152 \n",
      "-7.504764733376016 -7.4747826377410655 -7.317715289899006 -7.099096990780439 -7.974642319909823 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.963535741427002, 2: -7.952370859502642, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.805108547065391, 3: -7.739311913409316, 4: -7.755784903540353}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -7.963535741427002, 2: -7.96407973581181, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.8766455426380375, 2: -7.856801075011397, 3: -8.001228641048106, 4: -7.841470656100414}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.8766455426380375, 2: -7.856801075011397, 3: -8.001228641048106, 4: -7.841470656100414}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.8766455426380375, 2: -7.856801075011397, 3: -8.001228641048106, 4: -8.035738297051378}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.7176942348287385, 2: -7.757636866545426, 3: -7.817707688648879, 4: -7.666844957921807}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.7176942348287385, 2: -7.757636866545426, 3: -7.817707688648879, 4: -7.666844957921807}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.7176942348287385, 2: -7.757636866545426, 3: -7.817707688648879, 4: -7.876828911708845}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.611954672252844, 2: -7.639224188640007, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.380314484527809, 2: -7.4374546547846645, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.326257736215357, 3: -7.317715289899006, 4: -7.410045889430568}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.4747826377410655, 1: -7.59084632217378, 2: -7.52301843383426, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.681194668540746, 2: -7.592386698305138, 3: -7.703158055868926, 4: -7.487517705707876}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.681194668540746, 2: -7.592386698305138, 3: -7.703158055868926, 4: -7.487517705707876}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.681194668540746, 2: -7.592386698305138, 3: -7.703158055868926, 4: -7.713641112194168}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.4374546547846645, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.3438741906612695, 2: -7.298924374076706, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.3438741906612695, 2: -7.298924374076706, 3: -7.256810630674358, 4: -7.2455424611249795}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.3438741906612695, 2: -7.298924374076706, 3: -7.256810630674358, 4: -7.493443639623731}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.5126348589897, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.5126348589897, 3: -7.655648189373364, 4: -7.475581595360421}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.5126348589897, 3: -7.655648189373364, 4: -7.702779251777984}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.257908151971501, 1: -7.3438741906612695, 2: -7.298924374076706, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.476835604930791, 2: -7.3982389349974325, 3: -7.679984693131083, 4: -7.479458937820383}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.411972717300958, 2: -7.619844004745129, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.175412880505152, 2: -7.438123010975011, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.01914166824835, 2: -8.138884628188123, 3: -8.028356290801959, 4: -8.073705901240833}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.027857322152201 -7.96407973581181 -7.755784903540353 -7.617453344978551 -7.552611506190992 \n",
      "-7.8364904691779 -7.8766455426380375 -7.757636866545426 -7.604807956482081 -7.544949680068378 \n",
      "-7.6777098658863245 -7.707093199467228 -7.639224188640007 -7.476835604930791 -7.429937618834757 \n",
      "-7.572482106263372 -7.681194668540746 -7.530169088995886 -7.298924374076706 -7.2130460393316795 \n",
      "-7.504764733376016 -7.52301843383426 -7.326257736215357 -7.099096990780439 -8.01914166824835 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.8364904691779, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.6777098658863245, 2: -7.782397483217775, 3: -7.761134282593016, 4: -7.8918213060035995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.572482106263372, 2: -7.669274124294419, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.504764733376016, 4: -7.555451400702481}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.729335907372175, 4: -7.555451400702481}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.792849225306227, 4: -7.555451400702481}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.792849225306227, 4: -7.775460774639258}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.619475984318587, 2: -7.695588116516082, 3: -7.792849225306227, 4: -7.8493216247619815}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6366658853548355, 1: -7.833723145729914, 2: -7.695588116516082, 3: -7.792849225306227, 4: -7.8493216247619815}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.609101543923323, 1: -7.73610764466091, 2: -7.669274124294419, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699990812431321, 1: -7.801481492661964, 2: -7.782397483217775, 3: -7.761134282593016, 4: -7.8918213060035995}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.902594038285713, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.902594038285713, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -7.840108518483519}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.902594038285713, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -8.034498751820003}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.801481492661964, 2: -7.782397483217775, 3: -7.761134282593016, 4: -7.8918213060035995}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.801481492661964, 2: -7.782397483217775, 3: -7.761134282593016, 4: -7.8918213060035995}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.801481492661964, 2: -7.782397483217775, 3: -7.962632197159644, 4: -7.8918213060035995}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.707093199467228, 2: -7.790615978963246, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.681194668540746, 2: -7.683576940206092, 3: -7.703158055868926, 4: -7.821197336846579}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.59084632217378, 2: -7.52301843383426, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.326257736215357, 3: -7.686345465560164, 4: -7.410045889430568}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -7.099096990780439, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.049471446858933, 2: -8.138884628188123, 3: -8.028356290801959, 4: -8.073705901240833}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.027857322152201 -7.96407973581181 -7.755784903540353 -7.617453344978551 -7.552611506190992 \n",
      "-7.942407656426546 -7.8766455426380375 -7.757636866545426 -7.604807956482081 -7.544949680068378 \n",
      "-7.801481492661964 -7.785143818163723 -7.639224188640007 -7.476835604930791 -7.429937618834757 \n",
      "-7.669274124294419 -7.683576940206092 -7.530169088995886 -7.298924374076706 -7.2130460393316795 \n",
      "-7.695588116516082 -7.586570609717866 -7.382894336153692 -7.099114679305462 -8.028356290801959 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.027857322152201, 2: -8.104346490825163, 3: -8.188954887898802, 4: -8.12179616834028}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.976778172728914, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -8.104551046193428}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.976778172728914, 2: -7.9475811202439175, 3: -7.942407656426546, 4: -8.104551046193428}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.976778172728914, 2: -7.9475811202439175, 3: -8.127590967348157, 4: -8.104551046193428}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.8766455426380375, 2: -7.8958245234178035, 3: -8.001228641048106, 4: -8.067582700464369}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.790615978963246, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.790615978963246, 3: -7.794639608259684, 4: -7.785143818163723}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.790615978963246, 3: -7.794639608259684, 4: -7.984480874528988}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.6392501996928095, 2: -7.639224188640007, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.476835604930791, 2: -7.643521794513519, 3: -7.679984693131083, 4: -7.479458937820383}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.3438741906612695, 2: -7.298924374076706, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.2130460393316795, 2: -7.438123010975011, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.049471446858933, 2: -8.138884628188123, 3: -8.205400060023479, 4: -8.073705901240833}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.104346490825163 -7.96407973581181 -7.755784903540353 -7.617453344978551 -7.552611506190992 \n",
      "-7.976778172728914 -7.8958245234178035 -7.757636866545426 -7.604807956482081 -7.544949680068378 \n",
      "-7.801481492661964 -7.794639608259684 -7.6392501996928095 -7.479458937820383 -7.429937618834757 \n",
      "-7.669274124294419 -7.683576940206092 -7.530169088995886 -7.3438741906612695 -7.241376475888904 \n",
      "-7.695588116516082 -7.586570609717866 -7.382894336153692 -7.099114679305462 -8.049471446858933 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -7.976778172728914, 2: -8.074841001561204, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.801481492661964, 2: -7.920985239890232, 3: -8.000005181122361, 4: -7.8918213060035995}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.73610764466091, 2: -7.669274124294419, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.7617643982598254, 2: -7.683576940206092, 3: -7.703158055868926, 4: -7.821197336846579}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.530169088995886, 3: -7.655648189373364, 4: -7.755512160959456}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.3438741906612695, 2: -7.4724597292663315, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.099114679305462, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.115299305114281, 1: -7.360194358167971, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.3846703093035515, 2: -7.4724597292663315, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.182680401049645}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.212878294627631, 3: -7.248003493894839, 4: -7.436239164955177}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.166137464596313, 2: -8.138884628188123, 3: -8.205400060023479, 4: -8.073705901240833}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.104346490825163 -7.96407973581181 -7.755784903540353 -7.617453344978551 -7.552611506190992 \n",
      "-8.016877826329083 -7.8958245234178035 -7.757636866545426 -7.604807956482081 -7.544949680068378 \n",
      "-7.8918213060035995 -7.794639608259684 -7.6392501996928095 -7.479458937820383 -7.429937618834757 \n",
      "-7.73610764466091 -7.703158055868926 -7.565380833270976 -7.4564381557805675 -7.241376475888904 \n",
      "-7.695588116516082 -7.586570609717866 -7.382894336153692 -7.248003493894839 -8.073705901240833 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.136135933920722, 2: -8.104346490825163, 3: -8.188954887898802, 4: -8.12179616834028}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -8.047944805584036, 2: -7.96407973581181, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.805108547065391, 3: -8.124395141896803, 4: -7.755784903540353}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.805108547065391, 3: -8.124395141896803, 4: -7.755784903540353}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.805108547065391, 3: -8.124395141896803, 4: -7.957764262221722}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.73439957157539, 2: -7.750060993165721, 3: -7.617453344978551, 4: -7.644820601925185}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.850648064139166, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.73439957157539, 2: -7.750060993165721, 3: -8.02077026645058, 4: -7.644820601925185}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.73439957157539, 2: -7.750060993165721, 3: -8.02077026645058, 4: -7.644820601925185}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.73439957157539, 2: -7.750060993165721, 3: -8.02077026645058, 4: -7.856786747751919}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.620184670990483, 2: -7.653197180126194, 3: -7.775355152487257, 4: -7.604807956482081}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.620184670990483, 2: -7.653197180126194, 3: -7.775355152487257, 4: -7.604807956482081}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.620184670990483, 2: -7.653197180126194, 3: -7.775355152487257, 4: -7.820375240398694}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.559812303495211, 2: -7.643521794513519, 3: -7.679984693131083, 4: -7.479458937820383}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.559812303495211, 2: -7.643521794513519, 3: -7.679984693131083, 4: -7.479458937820383}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.559812303495211, 2: -7.643521794513519, 3: -7.679984693131083, 4: -7.706307633416549}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.4564381557805675, 2: -7.4724597292663315, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.260989609467838, 3: -7.248003493894839, 4: -7.486055335143899}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.382894336153692, 3: -7.686345465560164, 4: -7.410045889430568}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.260989609467838, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.166137464596313, 2: -8.138884628188123, 3: -8.205400060023479, 4: -8.271891247692466}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.12179616834028 -7.978593745448867 -7.868279714260095 -7.750060993165721 -7.552611506190992 \n",
      "-8.016877826329083 -7.8958245234178035 -7.757636866545426 -7.653197180126194 -7.544949680068378 \n",
      "-7.8918213060035995 -7.794639608259684 -7.6392501996928095 -7.643521794513519 -7.429937618834757 \n",
      "-7.73610764466091 -7.703158055868926 -7.565380833270976 -7.4724597292663315 -7.241376475888904 \n",
      "-7.695588116516082 -7.586570609717866 -7.410045889430568 -7.318595509779163 -8.138884628188123 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -8.047944805584036, 2: -7.978593745448867, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.868279714260095, 2: -7.877369493973316, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.837452708007678, 2: -7.757636866545426, 3: -7.817707688648879, 4: -7.939015221382163}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.720380206733559, 2: -7.653197180126194, 3: -7.775355152487257, 4: -7.854387107542161}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.544949680068378, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.581236849786126}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.453281704939269, 2: -7.619844004745129, 3: -7.429937618834757, 4: -7.450598904049909}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.69569613653178, 2: -7.643521794513519, 3: -7.679984693131083, 4: -7.794078729172776}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.453281704939269, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.450598904049909}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.453281704939269, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.450598904049909}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.453281704939269, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.680045002685417}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.241376475888904, 2: -7.438123010975011, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.166137464596313, 2: -8.176549396632394, 3: -8.205400060023479, 4: -8.271891247692466}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.12179616834028 -8.047944805584036 -7.877369493973316 -7.750060993165721 -7.552611506190992 \n",
      "-8.016877826329083 -7.8958245234178035 -7.759078506492582 -7.6735232020170985 -7.581236849786126 \n",
      "-7.8918213060035995 -7.794639608259684 -7.6392501996928095 -7.679984693131083 -7.501640682084068 \n",
      "-7.73610764466091 -7.703158055868926 -7.565380833270976 -7.4724597292663315 -7.284702624391748 \n",
      "-7.695588116516082 -7.586570609717866 -7.410045889430568 -7.318595509779163 -8.166137464596313 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.016877826329083, 2: -8.074841001561204, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.892260189944676, 2: -7.920985239890232, 3: -8.000005181122361, 4: -7.8918213060035995}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.892260189944676, 2: -7.920985239890232, 3: -8.000005181122361, 4: -7.8918213060035995}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.892260189944676, 2: -7.920985239890232, 3: -8.000005181122361, 4: -8.081557388463276}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.73610764466091, 2: -7.890624733996376, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.827038839113376, 1: -7.869071681710409, 2: -7.695588116516082, 3: -7.792849225306227, 4: -7.8493216247619815}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.59084632217378, 2: -7.586570609717866, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.410045889430568}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.410045889430568}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479575997335738, 1: -7.503209809685732, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.643141759381817}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.565380833270976, 2: -7.601555003335217, 3: -7.655648189373364, 4: -7.755512160959456}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.503209809685732, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.503209809685732, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.727920926814016, 2: -7.519691017284318, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.318595509779163, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.21028478578619, 2: -8.176549396632394, 3: -8.205400060023479, 4: -8.271891247692466}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.12179616834028 -8.047944805584036 -7.877369493973316 -7.750060993165721 -7.552611506190992 \n",
      "-8.074841001561204 -7.8958245234178035 -7.759078506492582 -7.6735232020170985 -7.581236849786126 \n",
      "-7.920985239890232 -7.794639608259684 -7.6392501996928095 -7.679984693131083 -7.501640682084068 \n",
      "-7.764197197349313 -7.703158055868926 -7.601555003335217 -7.4724597292663315 -7.284702624391748 \n",
      "-7.792849225306227 -7.59084632217378 -7.580031464649554 -7.354864562250156 -8.176549396632394 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -8.047944805584036, 2: -8.071165943095563, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.99363104697642, 2: -7.8958245234178035, 3: -8.001228641048106, 4: -8.067582700464369}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.759078506492582, 1: -7.837452708007678, 2: -7.87485340255676, 3: -7.817707688648879, 4: -7.939015221382163}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.9705138333278045, 2: -7.877369493973316, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.833334401908025, 2: -7.750060993165721, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.669822087158639, 2: -7.78587244813842, 3: -7.552611506190992, 4: -7.627000168040753}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.833334401908025, 2: -7.792621419331275, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.669822087158639, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.627000168040753}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.669822087158639, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.627000168040753}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.669822087158639, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.840570152917085}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.67274443926299, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.581236849786126}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.67274443926299, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.581236849786126}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.67274443926299, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.798925533305375}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.67274443926299, 2: -7.62098088178311, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.633059811124644, 1: -7.67274443926299, 2: -7.83509260242263, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.8077840570426265, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.681361140915668, 1: -7.8077840570426265, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890038638233259, 1: -7.8077840570426265, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.8077840570426265, 2: -7.78587244813842, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.8077840570426265, 2: -7.985143927805963, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.67274443926299, 2: -7.866287707253225, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501640682084068, 1: -7.51084311596394, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.743603396414395, 2: -7.866287707253225, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.51084311596394, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.3387089939119035, 2: -7.438123010975011, 3: -7.284702624391748, 4: -7.344009641658935}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.516526645632877, 2: -7.4724597292663315, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.3387089939119035, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.344009641658935}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.195497734560021, 1: -8.21028478578619, 2: -8.23649023218631, 3: -8.205400060023479, 4: -8.271891247692466}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.12179616834028 -8.056606321623294 -7.890141375687556 -7.832275780222635 -7.895701401507285 \n",
      "-8.074841001561204 -7.974436042600772 -7.817707688648879 -7.6735232020170985 -7.758143263572231 \n",
      "-7.920985239890232 -7.794639608259684 -7.6392501996928095 -7.679984693131083 -7.55169343735371 \n",
      "-7.764197197349313 -7.703158055868926 -7.601555003335217 -7.516526645632877 -7.344009641658935 \n",
      "-7.792849225306227 -7.59084632217378 -7.580031464649554 -7.354864562250156 -8.195497734560021 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.136135933920722, 2: -8.161339235090082, 3: -8.188954887898802, 4: -8.12179616834028}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.136135933920722, 2: -8.161339235090082, 3: -8.188954887898802, 4: -8.12179616834028}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.136135933920722, 2: -8.161339235090082, 3: -8.188954887898802, 4: -8.290834513189655}, Best action: 1, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -8.100412344526825, 2: -8.071165943095563, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056606321623294, 1: -8.100412344526825, 2: -8.071165943095563, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.231511752677198, 1: -8.100412344526825, 2: -8.071165943095563, 3: -8.058719940886578, 4: -8.135762948731648}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.136135933920722, 2: -8.241985044023876, 3: -8.188954887898802, 4: -8.339768231741933}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.094063040495824, 2: -8.074841001561204, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.99363104697642, 2: -7.974436042600772, 3: -8.001228641048106, 4: -8.067582700464369}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -7.837452708007678, 2: -7.87485340255676, 3: -7.817707688648879, 4: -7.939015221382163}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -7.99363104697642, 2: -8.02978683206567, 3: -8.001228641048106, 4: -8.067582700464369}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.866833190694731, 3: -7.794639608259684, 4: -8.00884703041313}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.955473211169805, 2: -7.920985239890232, 3: -8.000005181122361, 4: -8.100886492701516}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.866833190694731, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.6392501996928095, 2: -7.720159258857942, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.734138029172541, 2: -7.601555003335217, 3: -7.655648189373364, 4: -7.755512160959456}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.516526645632877, 2: -7.591600257995275, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.354864562250156, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.21028478578619, 2: -8.23649023218631, 3: -8.205400060023479, 4: -8.271891247692466}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.155460292180097 -8.071165943095563 -7.890141375687556 -7.832275780222635 -7.895701401507285 \n",
      "-8.094063040495824 -8.001228641048106 -7.837452708007678 -7.6735232020170985 -7.758143263572231 \n",
      "-7.955473211169805 -7.874475980820649 -7.720159258857942 -7.679984693131083 -7.55169343735371 \n",
      "-7.764197197349313 -7.703158055868926 -7.655648189373364 -7.5273609748086034 -7.344009641658935 \n",
      "-7.792849225306227 -7.59084632217378 -7.580031464649554 -7.381860504844034 -8.205400060023479 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.254234804656647, 2: -8.241985044023876, 3: -8.188954887898802, 4: -8.339768231741933}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155460292180097, 1: -8.254234804656647, 2: -8.241985044023876, 3: -8.188954887898802, 4: -8.339768231741933}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.321468865883887, 1: -8.254234804656647, 2: -8.241985044023876, 3: -8.188954887898802, 4: -8.339768231741933}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.254234804656647, 2: -8.241985044023876, 3: -8.188954887898802, 4: -8.339768231741933}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.254234804656647, 2: -8.241985044023876, 3: -8.351948947987909, 4: -8.339768231741933}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.100412344526825, 2: -8.071165943095563, 3: -8.296142100564442, 4: -8.135762948731648}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.9705138333278045, 2: -7.965286353861566, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890141375687556, 1: -7.9705138333278045, 2: -7.965286353861566, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.080028651875676, 1: -7.9705138333278045, 2: -7.965286353861566, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.833334401908025, 2: -7.857132278046137, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.832275780222635, 1: -7.833334401908025, 2: -7.857132278046137, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.027370960002598, 1: -7.833334401908025, 2: -7.857132278046137, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6735232020170985, 1: -7.720380206733559, 2: -7.776728958868006, 3: -7.775355152487257, 4: -7.854387107542161}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -7.898887233824652, 2: -7.857132278046137, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.895701401507285, 2: -8.022819478985124, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.758143263572231, 2: -7.866287707253225, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.55169343735371, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.372224064384808, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.344009641658935}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.372224064384808, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.344009641658935}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.372224064384808, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.58304877390963}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.21028478578619, 2: -8.23649023218631, 3: -8.326462842668226, 4: -8.271891247692466}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.254234804656647 -8.098131108616476 -7.9705138333278045 -7.898887233824652 -7.896612905890207 \n",
      "-8.094063040495824 -8.001228641048106 -7.837452708007678 -7.720380206733559 -7.7827180630963735 \n",
      "-7.955473211169805 -7.874475980820649 -7.720159258857942 -7.679984693131083 -7.603817153479108 \n",
      "-7.764197197349313 -7.703158055868926 -7.655648189373364 -7.5273609748086034 -7.387553082925295 \n",
      "-7.792849225306227 -7.59084632217378 -7.580031464649554 -7.381860504844034 -8.21028478578619 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.094063040495824, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.955473211169805, 2: -8.064233408451756, 3: -8.000005181122361, 4: -8.100886492701516}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.890624733996376, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.890624733996376, 3: -7.764197197349313, 4: -7.807956011457193}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.890624733996376, 3: -7.965419449587875, 4: -7.807956011457193}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.890624733996376, 3: -8.020986314239114, 4: -7.807956011457193}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.890624733996376, 3: -8.020986314239114, 4: -8.005239970426047}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.7617643982598254, 2: -7.767794656107277, 3: -7.703158055868926, 4: -7.821197336846579}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.897902712461702, 1: -7.907037138844117, 2: -7.928620498653467, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -7.984547050969924, 2: -8.064233408451756, 3: -8.000005181122361, 4: -8.100886492701516}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -7.907037138844117, 2: -7.928620498653467, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.827038839113376, 1: -7.869071681710409, 2: -7.81468100552308, 3: -7.792849225306227, 4: -7.8493216247619815}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.827038839113376, 1: -7.869071681710409, 2: -7.81468100552308, 3: -7.792849225306227, 4: -7.8493216247619815}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.827038839113376, 1: -7.869071681710409, 2: -7.81468100552308, 3: -7.991492795028668, 4: -7.8493216247619815}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.59084632217378, 2: -7.660794231410547, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.59084632217378, 2: -7.660794231410547, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.80767015317814, 2: -7.660794231410547, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.873158134249137, 2: -7.660794231410547, 3: -7.6499697753837985, 4: -7.644927307322621}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.873158134249137, 2: -7.660794231410547, 3: -7.6499697753837985, 4: -7.856883849663585}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.827038839113376, 1: -7.869071681710409, 2: -7.83005362151307, 3: -8.02904089397656, 4: -7.8493216247619815}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.002911586382456, 2: -7.928620498653467, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.7617643982598254, 2: -7.767794656107277, 3: -8.067617002680871, 4: -7.821197336846579}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.873158134249137, 2: -7.660794231410547, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.580031464649554, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.381860504844034, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.277219541380235, 2: -8.23649023218631, 3: -8.326462842668226, 4: -8.271891247692466}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.254234804656647 -8.098131108616476 -7.9705138333278045 -7.898887233824652 -7.896612905890207 \n",
      "-8.104551046193428 -8.001228641048106 -7.837452708007678 -7.720380206733559 -7.7827180630963735 \n",
      "-8.000005181122361 -7.874475980820649 -7.720159258857942 -7.679984693131083 -7.603817153479108 \n",
      "-7.979891212455805 -7.767794656107277 -7.655648189373364 -7.5273609748086034 -7.387553082925295 \n",
      "-7.83005362151307 -7.712367605397486 -7.637310155388623 -7.399411872959365 -8.23649023218631 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.100412344526825, 2: -8.098131108616476, 3: -8.296142100564442, 4: -8.135762948731648}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -7.9705138333278045, 2: -8.040672017366491, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -7.837452708007678, 2: -7.87485340255676, 3: -8.156611916915788, 4: -7.939015221382163}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.8211845726708065, 2: -7.720159258857942, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.69569613653178, 2: -7.699337291731778, 3: -7.679984693131083, 4: -7.794078729172776}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.8211845726708065, 2: -7.892803527321972, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.8211845726708065, 2: -7.892803527321972, 3: -7.876731241946674, 4: -7.779987965439676}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810759887384577, 1: -7.8211845726708065, 2: -7.892803527321972, 3: -7.876731241946674, 4: -7.979789048550105}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -7.9370742704757005, 2: -7.87485340255676, 3: -8.156611916915788, 4: -7.939015221382163}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.720380206733559, 2: -7.776728958868006, 3: -7.775355152487257, 4: -7.854387107542161}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692237794975436, 1: -7.69569613653178, 2: -7.699337291731778, 3: -7.9697887213192455, 4: -7.794078729172776}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.90275063460346, 2: -7.776728958868006, 3: -7.775355152487257, 4: -7.854387107542161}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -7.9370742704757005, 2: -7.940993307709859, 3: -8.156611916915788, 4: -7.939015221382163}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -7.8211845726708065, 2: -7.892803527321972, 3: -7.876731241946674, 4: -8.024694413636517}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.734138029172541, 2: -7.748542083296152, 3: -7.655648189373364, 4: -7.755512160959456}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.881419767268526, 2: -7.767794656107277, 3: -8.067617002680871, 4: -7.821197336846579}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.734138029172541, 2: -7.748542083296152, 3: -7.957478490384231, 4: -7.755512160959456}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.637310155388623, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.409743138555314, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.399411872959365, 2: -7.409743138555314, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.633464804393022, 2: -7.409743138555314, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.277219541380235, 2: -8.283135221197977, 3: -8.326462842668226, 4: -8.271891247692466}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.254234804656647 -8.100412344526825 -8.01791434934514 -7.898887233824652 -7.896612905890207 \n",
      "-8.104551046193428 -8.001228641048106 -7.939015221382163 -7.776728958868006 -7.7827180630963735 \n",
      "-8.000005181122361 -7.874475980820649 -7.876731241946674 -7.69569613653178 -7.603817153479108 \n",
      "-7.979891212455805 -7.821197336846579 -7.748542083296152 -7.5273609748086034 -7.387553082925295 \n",
      "-7.83005362151307 -7.712367605397486 -7.657254632635948 -7.441206224486429 -8.271891247692466 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.254234804656647, 2: -8.261842918309792, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.104551046193428}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.105180858484145, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.275141452036019}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.290109827882342, 2: -8.261842918309792, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.100412344526825, 2: -8.16592931585717, 3: -8.296142100564442, 4: -8.135762948731648}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.013021187387984, 2: -8.02978683206567, 3: -8.001228641048106, 4: -8.067582700464369}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.29271064057576}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.15029980413239, 4: -8.29271064057576}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.153339605097125, 2: -8.166777294662745, 3: -8.316772821760475, 4: -8.29271064057576}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -8.103154787560728, 2: -8.064233408451756, 3: -8.000005181122361, 4: -8.100886492701516}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -8.103154787560728, 2: -8.064233408451756, 3: -8.000005181122361, 4: -8.100886492701516}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.020486981214782, 1: -8.103154787560728, 2: -8.064233408451756, 3: -8.18000471482135, 4: -8.100886492701516}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.195338157218826, 2: -8.166777294662745, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.013021187387984, 2: -8.02978683206567, 3: -8.301865705452048, 4: -8.067582700464369}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -7.874475980820649, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -7.883193490659506, 2: -7.892803527321972, 3: -7.876731241946674, 4: -8.024694413636517}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -7.892477001464727, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.881419767268526, 2: -7.941431269240486, 3: -8.067617002680871, 4: -7.821197336846579}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.881419767268526, 2: -7.941431269240486, 3: -8.067617002680871, 4: -7.821197336846579}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8411475012803695, 1: -7.881419767268526, 2: -7.941431269240486, 3: -8.067617002680871, 4: -8.017289576530388}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.918833727291905, 1: -8.024417542992202, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.079627663203524, 2: -8.02978683206567, 3: -8.301865705452048, 4: -8.067582700464369}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.028866930910922, 2: -7.940993307709859, 3: -8.156611916915788, 4: -7.939015221382163}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.028866930910922, 2: -7.940993307709859, 3: -8.156611916915788, 4: -7.939015221382163}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.028866930910922, 2: -7.940993307709859, 3: -8.156611916915788, 4: -8.124503851457769}, Best action: 2, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.079627663203524, 2: -8.133581012526118, 3: -8.301865705452048, 4: -8.067582700464369}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.079627663203524, 2: -8.133581012526118, 3: -8.301865705452048, 4: -8.067582700464369}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.079627663203524, 2: -8.133581012526118, 3: -8.301865705452048, 4: -8.241500257422576}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.024417542992202, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.024417542992202, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.00884703041313}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.024417542992202, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.188050797675949}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.09837006923448, 1: -7.881419767268526, 2: -7.941431269240486, 3: -8.067617002680871, 4: -8.053058433690138}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712367605397486, 1: -7.873158134249137, 2: -7.805904909507194, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.09837006923448, 1: -7.935159737098816, 2: -7.941431269240486, 3: -8.067617002680871, 4: -8.053058433690138}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -7.873158134249137, 2: -7.805904909507194, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.657254632635948, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.441206224486429, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.277219541380235, 2: -8.283135221197977, 3: -8.326462842668226, 4: -8.413119316541131}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.287518290897708 -8.135762948731648 -8.01791434934514 -7.898887233824652 -7.896612905890207 \n",
      "-8.195338157218826 -8.098096786520891 -7.940993307709859 -7.776728958868006 -7.7827180630963735 \n",
      "-8.064233408451756 -8.067599904058872 -7.883193490659506 -7.69569613653178 -7.603817153479108 \n",
      "-7.979891212455805 -7.941431269240486 -7.748542083296152 -7.5273609748086034 -7.387553082925295 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.448668450966634 -8.277219541380235 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.195338157218826, 2: -8.207224891250542, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.103154787560728, 2: -8.064233408451756, 3: -8.214594926266109, 4: -8.100886492701516}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.086391765786725, 2: -8.067599904058872, 3: -8.095462005137056, 4: -8.218583289591278}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -7.883193490659506, 2: -7.892803527321972, 3: -8.080579495381096, 4: -8.024694413636517}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.859635028782039, 2: -7.748542083296152, 3: -7.957478490384231, 4: -7.755512160959456}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.609092959985913, 2: -7.591600257995275, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.609092959985913, 2: -7.591600257995275, 3: -7.6809021553093775, 4: -7.5273609748086034}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.609092959985913, 2: -7.591600257995275, 3: -7.6809021553093775, 4: -7.749898487075829}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.387553082925295, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.365945861485272, 2: -8.283135221197977, 3: -8.326462842668226, 4: -8.413119316541131}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.287518290897708 -8.135762948731648 -8.01791434934514 -7.898887233824652 -7.896612905890207 \n",
      "-8.207224891250542 -8.098096786520891 -7.940993307709859 -7.776728958868006 -7.7827180630963735 \n",
      "-8.100886492701516 -8.086391765786725 -7.892803527321972 -7.69569613653178 -7.603817153479108 \n",
      "-7.979891212455805 -7.941431269240486 -7.755512160959456 -7.609092959985913 -7.438123010975011 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.448668450966634 -8.283135221197977 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.19103643370165, 2: -8.16592931585717, 3: -8.296142100564442, 4: -8.135762948731648}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.19103643370165, 2: -8.16592931585717, 3: -8.296142100564442, 4: -8.135762948731648}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.19103643370165, 2: -8.16592931585717, 3: -8.296142100564442, 4: -8.3035442833458}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.045388076819, 2: -8.040672017366491, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.045388076819, 2: -8.040672017366491, 3: -8.124395141896803, 4: -8.01791434934514}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.045388076819, 2: -8.040672017366491, 3: -8.124395141896803, 4: -8.196302057904077}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -7.898887233824652, 2: -8.081231363025514, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.90275063460346, 2: -7.776728958868006, 3: -8.106565674334043, 4: -7.854387107542161}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.792686010613728, 2: -7.866287707253225, 3: -7.7827180630963735, 4: -7.852887067574857}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.90275063460346, 2: -7.981674526994863, 3: -8.106565674334043, 4: -7.854387107542161}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.90275063460346, 2: -7.981674526994863, 3: -8.106565674334043, 4: -7.854387107542161}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.90275063460346, 2: -7.981674526994863, 3: -8.106565674334043, 4: -8.047492267863367}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.69569613653178, 2: -7.699337291731778, 3: -7.9697887213192455, 4: -7.794078729172776}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.609092959985913, 2: -7.643078022969016, 3: -7.6809021553093775, 4: -7.824186057683756}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.448668450966634, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.298204669811629, 1: -8.365945861485272, 2: -8.318281510592433, 3: -8.326462842668226, 4: -8.413119316541131}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.287518290897708 -8.19103643370165 -8.045388076819 -7.950542327751259 -7.896612905890207 \n",
      "-8.207224891250542 -8.098096786520891 -7.940993307709859 -7.923788934051088 -7.792686010613728 \n",
      "-8.100886492701516 -8.086391765786725 -7.892803527321972 -7.699337291731778 -7.603817153479108 \n",
      "-7.979891212455805 -7.941431269240486 -7.755512160959456 -7.61836435254507 -7.438123010975011 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.4664126276440825 -8.298204669811629 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.290109827882342, 2: -8.287518290897708, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.19103643370165, 2: -8.21110355455528, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098096786520891, 1: -8.195128860954988, 2: -8.133581012526118, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.278562040452087, 2: -8.21110355455528, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.045388076819, 2: -8.102165861134619, 3: -8.124395141896803, 4: -8.232574539857266}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.028866930910922, 2: -7.940993307709859, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.923788934051088, 2: -7.981674526994863, 3: -8.106565674334043, 4: -8.10597724081514}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.832934911241768, 2: -7.699337291731778, 3: -7.9697887213192455, 4: -7.794078729172776}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.603817153479108, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.448094837462891, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.448094837462891, 2: -7.438123010975011, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.448094837462891, 2: -7.66869193998726, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.365945861485272, 2: -8.318281510592433, 3: -8.326462842668226, 4: -8.413119316541131}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.290109827882342 -8.237874697678919 -8.102165861134619 -7.950542327751259 -7.896612905890207 \n",
      "-8.207224891250542 -8.133581012526118 -8.028866930910922 -7.9288420997078495 -7.792686010613728 \n",
      "-8.100886492701516 -8.086391765786725 -7.892803527321972 -7.794078729172776 -7.619844004745129 \n",
      "-7.979891212455805 -7.941431269240486 -7.755512160959456 -7.61836435254507 -7.48261750732616 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.4664126276440825 -8.318281510592433 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.278562040452087, 2: -8.237874697678919, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.136743386926886, 2: -8.102165861134619, 3: -8.124395141896803, 4: -8.232574539857266}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -7.98903918006555, 2: -8.081231363025514, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -7.98903918006555, 2: -8.081231363025514, 3: -8.02077026645058, 4: -7.950542327751259}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -7.98903918006555, 2: -8.081231363025514, 3: -8.02077026645058, 4: -8.134993518253644}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -7.9288420997078495, 2: -7.981674526994863, 3: -8.106565674334043, 4: -8.10597724081514}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.832934911241768, 2: -7.829025623491256, 3: -7.9697887213192455, 4: -7.794078729172776}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.832934911241768, 2: -7.829025623491256, 3: -7.9697887213192455, 4: -7.794078729172776}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.832934911241768, 2: -7.829025623491256, 3: -7.9697887213192455, 4: -7.992611643547227}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.68526135423767, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.68526135423767, 2: -7.619844004745129, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.68526135423767, 2: -7.834058044318067, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.48261750732616, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.365945861485272, 2: -8.404506656179167, 3: -8.326462842668226, 4: -8.413119316541131}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.290109827882342 -8.250714327385849 -8.124395141896803 -8.02077026645058 -7.896612905890207 \n",
      "-8.207224891250542 -8.133581012526118 -8.028866930910922 -7.981674526994863 -7.792686010613728 \n",
      "-8.100886492701516 -8.086391765786725 -7.892803527321972 -7.832934911241768 -7.70516268126935 \n",
      "-7.979891212455805 -7.941431269240486 -7.755512160959456 -7.61836435254507 -7.49269665329388 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.4664126276440825 -8.326462842668226 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.290109827882342, 2: -8.363491340388107, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.251562876567805, 2: -8.207224891250542, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.195128860954988, 2: -8.133581012526118, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.028866930910922, 2: -8.112368367352367, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -7.964638436535833, 2: -7.892803527321972, 3: -8.080579495381096, 4: -8.024694413636517}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.832934911241768, 2: -7.85497620619268, 3: -7.9697887213192455, 4: -8.040771919382639}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.61836435254507, 1: -7.694330741281566, 2: -7.643078022969016, 3: -7.6809021553093775, 4: -7.824186057683756}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.8541686166856834, 2: -7.85497620619268, 3: -7.9697887213192455, 4: -8.040771919382639}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.694330741281566, 2: -7.643078022969016, 3: -7.6809021553093775, 4: -7.824186057683756}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.49269665329388, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.365945861485272, 2: -8.404506656179167, 3: -8.447635244851519, 4: -8.413119316541131}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.339768231741933 -8.250714327385849 -8.124395141896803 -8.02077026645058 -7.896612905890207 \n",
      "-8.251562876567805 -8.195128860954988 -8.056577140767644 -7.981674526994863 -7.792686010613728 \n",
      "-8.100886492701516 -8.086391765786725 -7.964638436535833 -7.85497620619268 -7.70516268126935 \n",
      "-7.979891212455805 -7.941431269240486 -7.755512160959456 -7.6809021553093775 -7.525685813132459 \n",
      "-7.83005362151307 -7.873158134249137 -7.686345465560164 -7.4664126276440825 -8.365945861485272 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.251562876567805, 2: -8.30892310927121, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.103154787560728, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.100886492701516}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.103154787560728, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.100886492701516}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.103154787560728, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.271806708358378}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.002911586382456, 2: -7.979891212455805, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.09837006923448, 1: -8.01629895041071, 2: -7.941431269240486, 3: -8.067617002680871, 4: -8.053058433690138}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.859635028782039, 2: -7.772016597924584, 3: -7.957478490384231, 4: -7.755512160959456}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.859635028782039, 2: -7.772016597924584, 3: -7.957478490384231, 4: -7.755512160959456}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.859635028782039, 2: -7.772016597924584, 3: -7.957478490384231, 4: -7.957516066473104}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.694330741281566, 2: -7.733392091464944, 3: -7.6809021553093775, 4: -7.824186057683756}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.793234778669532, 1: -7.859635028782039, 2: -7.898732405593054, 3: -7.957478490384231, 4: -7.991085050966223}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -7.964638436535833, 2: -8.03395763083803, 3: -8.080579495381096, 4: -8.024694413636517}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.130680611460978, 1: -7.859635028782039, 2: -7.898732405593054, 3: -7.957478490384231, 4: -7.991085050966223}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.6931025050976025, 3: -7.686345465560164, 4: -7.72277073378013}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -7.873158134249137, 2: -7.882966743385838, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -7.873158134249137, 2: -7.882966743385838, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.064573902166716, 2: -7.882966743385838, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.091010151668732, 2: -7.882966743385838, 3: -8.004898437220215, 4: -7.8821639030272355}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.091010151668732, 2: -7.882966743385838, 3: -8.004898437220215, 4: -8.072769151754784}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.6931025050976025, 3: -8.045892635297818, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.4664126276440825, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.420360516168449, 2: -8.404506656179167, 3: -8.447635244851519, 4: -8.413119316541131}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.339768231741933 -8.250714327385849 -8.124395141896803 -8.02077026645058 -7.896612905890207 \n",
      "-8.286874346745007 -8.195128860954988 -8.056577140767644 -7.981674526994863 -7.792686010613728 \n",
      "-8.174027360845276 -8.086391765786725 -8.024694413636517 -7.85497620619268 -7.70516268126935 \n",
      "-8.002911586382456 -7.976107977301208 -7.898732405593054 -7.694330741281566 -7.525685813132459 \n",
      "-7.83005362151307 -7.919709703467642 -7.717104478901468 -7.486055335143899 -8.404506656179167 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.278562040452087, 2: -8.286541817286933, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.250714327385849, 1: -8.278562040452087, 2: -8.286541817286933, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.408150037921123, 1: -8.278562040452087, 2: -8.286541817286933, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.195128860954988, 2: -8.216740315290458, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.086391765786725, 2: -8.092146717840087, 3: -8.095462005137056, 4: -8.218583289591278}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.09837006923448, 1: -8.01629895041071, 2: -7.976107977301208, 3: -8.067617002680871, 4: -8.053058433690138}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.130680611460978, 1: -7.9119033299819375, 2: -7.898732405593054, 3: -7.957478490384231, 4: -7.991085050966223}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.694330741281566, 2: -7.733392091464944, 3: -7.980610386253259, 4: -7.824186057683756}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.554291654269534, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.554291654269534, 3: -7.604944761673974, 4: -7.486055335143899}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.554291654269534, 3: -7.604944761673974, 4: -7.712310354980948}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.420360516168449, 2: -8.423529270800454, 3: -8.447635244851519, 4: -8.413119316541131}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.339768231741933 -8.286541817286933 -8.124395141896803 -8.02077026645058 -7.896612905890207 \n",
      "-8.286874346745007 -8.216740315290458 -8.056577140767644 -7.981674526994863 -7.792686010613728 \n",
      "-8.174027360845276 -8.092146717840087 -8.024694413636517 -7.85497620619268 -7.70516268126935 \n",
      "-8.002911586382456 -8.01629895041071 -7.9119033299819375 -7.733137895594715 -7.525685813132459 \n",
      "-7.83005362151307 -7.919709703467642 -7.717104478901468 -7.570055811825269 -8.413119316541131 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.376863144701172, 2: -8.363491340388107, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.376863144701172, 2: -8.363491340388107, 3: -8.41120278045813, 4: -8.339768231741933}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.376863144701172, 2: -8.363491340388107, 3: -8.41120278045813, 4: -8.489189090885159}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.286541817286933, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.136743386926886, 2: -8.15015587159198, 3: -8.124395141896803, 4: -8.232574539857266}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.309414246665105, 3: -8.296142100564442, 4: -8.344757174178888}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.376863144701172, 2: -8.448448006041227, 3: -8.41120278045813, 4: -8.523346894802883}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365200345786418, 1: -8.376863144701172, 2: -8.448448006041227, 3: -8.41120278045813, 4: -8.523346894802883}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.51233231466564, 1: -8.376863144701172, 2: -8.448448006041227, 3: -8.41120278045813, 4: -8.523346894802883}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.286874346745007, 2: -8.30892310927121, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.174027360845276, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.290736048760028}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.002911586382456, 2: -8.130548449330375, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -7.869071681710409, 2: -7.83005362151307, 3: -8.02904089397656, 4: -7.8493216247619815}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.091010151668732, 2: -7.919709703467642, 3: -8.004898437220215, 4: -8.092479977318007}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.717104478901468, 3: -8.045892635297818, 4: -7.72277073378013}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.570055811825269, 3: -7.604944761673974, 4: -7.790207275456417}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.420360516168449, 2: -8.423529270800454, 3: -8.447635244851519, 4: -8.49652419936508}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.41120278045813 -8.309414246665105 -8.136743386926886 -8.02077026645058 -7.896612905890207 \n",
      "-8.29271064057576 -8.216740315290458 -8.056577140767644 -7.981674526994863 -7.792686010613728 \n",
      "-8.199761121054317 -8.092146717840087 -8.024694413636517 -7.85497620619268 -7.70516268126935 \n",
      "-8.020986314239114 -8.01629895041071 -7.9119033299819375 -7.733137895594715 -7.525685813132459 \n",
      "-7.8493216247619815 -7.942825598256953 -7.72277073378013 -7.577497599278971 -8.420360516168449 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.30892310927121, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.30892310927121, 3: -8.335882362304718, 4: -8.29271064057576}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.30892310927121, 3: -8.335882362304718, 4: -8.44636668292394}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.269490216382746, 2: -8.216740315290458, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056577140767644, 1: -8.09605755022189, 2: -8.112368367352367, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.136743386926886, 2: -8.15015587159198, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.296419857487543, 1: -8.09605755022189, 2: -8.112368367352367, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -8.062768216967035, 2: -8.03395763083803, 3: -8.080579495381096, 4: -8.024694413636517}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -8.062768216967035, 2: -8.03395763083803, 3: -8.080579495381096, 4: -8.024694413636517}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -8.062768216967035, 2: -8.03395763083803, 3: -8.080579495381096, 4: -8.20247191640923}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.876310060273472, 2: -7.85497620619268, 3: -7.9697887213192455, 4: -8.040771919382639}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.729446316357957, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.729446316357957, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.70516268126935}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.729446316357957, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.911698039955109}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.525685813132459, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.45913167048321, 2: -8.423529270800454, 3: -8.447635244851519, 4: -8.49652419936508}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.41120278045813 -8.309414246665105 -8.15015587159198 -8.02077026645058 -7.896612905890207 \n",
      "-8.335882362304718 -8.247501515550837 -8.112368367352367 -7.981674526994863 -7.792686010613728 \n",
      "-8.199761121054317 -8.092146717840087 -8.059707244809434 -7.876310060273472 -7.768750140273088 \n",
      "-8.020986314239114 -8.01629895041071 -7.9119033299819375 -7.733137895594715 -7.556535855381827 \n",
      "-7.8493216247619815 -7.942825598256953 -7.72277073378013 -7.577497599278971 -8.423529270800454 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.309414246665105, 3: -8.505426490143442, 4: -8.344757174178888}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.271480954372418, 2: -8.15015587159198, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -8.121266018769912, 2: -8.081231363025514, 3: -8.02077026645058, 4: -8.18462108767846}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.271480954372418, 2: -8.211839502984168, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.159884811815434, 1: -8.271480954372418, 2: -8.211839502984168, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.325495178752046, 1: -8.271480954372418, 2: -8.211839502984168, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -8.121266018769912, 2: -8.081231363025514, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04773796154576, 1: -8.121266018769912, 2: -8.081231363025514, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.223441545006642, 1: -8.121266018769912, 2: -8.081231363025514, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.973666183644236, 2: -8.022819478985124, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.973666183644236, 2: -8.022819478985124, 3: -7.967284500277433, 4: -7.896612905890207}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.973666183644236, 2: -8.022819478985124, 3: -7.967284500277433, 4: -8.085917744360088}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.268141558551331, 1: -8.121266018769912, 2: -8.10437959007362, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -7.973666183644236, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.792686010613728, 2: -7.866287707253225, 3: -8.040325363418788, 4: -7.852887067574857}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.768750140273088, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.952021320245456}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.556535855381827, 1: -7.575627290661614, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.797669056886589, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.952021320245456}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.575627290661614, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.442710282608306, 1: -8.45913167048321, 2: -8.47297846687878, 3: -8.447635244851519, 4: -8.49652419936508}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.41120278045813 -8.332567680656014 -8.232574539857266 -8.121266018769912 -7.9955605468154465 \n",
      "-8.335882362304718 -8.247501515550837 -8.112368367352367 -7.981674526994863 -7.852887067574857 \n",
      "-8.199761121054317 -8.092146717840087 -8.059707244809434 -7.876310060273472 -7.816025011124566 \n",
      "-8.020986314239114 -8.01629895041071 -7.9119033299819375 -7.733137895594715 -7.59615805797889 \n",
      "-7.8493216247619815 -7.942825598256953 -7.72277073378013 -7.577497599278971 -8.442710282608306 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536492378674513, 1: -8.450054535333573, 2: -8.448448006041227, 3: -8.41120278045813, 4: -8.523346894802883}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536492378674513, 1: -8.450054535333573, 2: -8.448448006041227, 3: -8.41120278045813, 4: -8.523346894802883}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536492378674513, 1: -8.450054535333573, 2: -8.448448006041227, 3: -8.554194530216897, 4: -8.523346894802883}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.332567680656014, 3: -8.505426490143442, 4: -8.344757174178888}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.38413951529238, 1: -8.271480954372418, 2: -8.239851699150483, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.38413951529238, 1: -8.271480954372418, 2: -8.239851699150483, 3: -8.432314615646877, 4: -8.232574539857266}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.38413951529238, 1: -8.271480954372418, 2: -8.239851699150483, 3: -8.432314615646877, 4: -8.391642831270111}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.268141558551331, 1: -8.121266018769912, 2: -8.169107567759193, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -8.006087980600734, 2: -7.981674526994863, 3: -8.106565674334043, 4: -8.10597724081514}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.971956214682574, 2: -7.866287707253225, 3: -8.040325363418788, 4: -7.852887067574857}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.971956214682574, 2: -7.866287707253225, 3: -8.040325363418788, 4: -7.852887067574857}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.971956214682574, 2: -7.866287707253225, 3: -8.040325363418788, 4: -8.04612723149312}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.971956214682574, 2: -7.866287707253225, 3: -8.040325363418788, 4: -8.076305766024424}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.885208505254156, 1: -7.971956214682574, 2: -8.058321813600434, 3: -8.040325363418788, 4: -8.076305766024424}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -8.009442286961544, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9955605468154465, 1: -8.009442286961544, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.175960097602056, 1: -8.009442286961544, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.164924893445928, 1: -7.971956214682574, 2: -8.09285107061591, 3: -8.040325363418788, 4: -8.076305766024424}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.816025011124566, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.952021320245456}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.59615805797889, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.45913167048321, 2: -8.47297846687878, 3: -8.447635244851519, 4: -8.49652419936508}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.450054535333573 -8.344757174178888 -8.271480954372418 -8.169107567759193 -8.022819478985124 \n",
      "-8.335882362304718 -8.247501515550837 -8.112368367352367 -8.006087980600734 -8.028175880479157 \n",
      "-8.199761121054317 -8.092146717840087 -8.059707244809434 -7.876310060273472 -7.834246415439425 \n",
      "-8.020986314239114 -8.01629895041071 -7.9119033299819375 -7.733137895594715 -7.6022003541276195 \n",
      "-7.8493216247619815 -7.942825598256953 -7.72277073378013 -7.577497599278971 -8.447635244851519 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536492378674513, 1: -8.450054535333573, 2: -8.494224621935494, 3: -8.598662337915083, 4: -8.523346894802883}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.386451966312393, 3: -8.335882362304718, 4: -8.474864386802075}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.386451966312393, 3: -8.335882362304718, 4: -8.474864386802075}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.349649596959175, 2: -8.386451966312393, 3: -8.485652949697293, 4: -8.474864386802075}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.199761121054317, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.290736048760028}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.042634592063832, 2: -8.130548449330375, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.042634592063832, 2: -8.130548449330375, 3: -8.020986314239114, 4: -8.09193003157967}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.042634592063832, 2: -8.130548449330375, 3: -8.199097545957594, 4: -8.09193003157967}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -7.869071681710409, 2: -8.097970221960098, 3: -8.02904089397656, 4: -7.8493216247619815}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -7.869071681710409, 2: -8.097970221960098, 3: -8.02904089397656, 4: -7.8493216247619815}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -7.869071681710409, 2: -8.097970221960098, 3: -8.02904089397656, 4: -8.042882678533402}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -7.869071681710409, 2: -8.097970221960098, 3: -8.02904089397656, 4: -8.078236330038772}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.060855230356472, 2: -8.097970221960098, 3: -8.02904089397656, 4: -8.078236330038772}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.20960864715666, 2: -8.097970221960098, 3: -8.02904089397656, 4: -8.078236330038772}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.20960864715666, 2: -8.097970221960098, 3: -8.206427213518669, 4: -8.078236330038772}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.20960864715666, 2: -8.097970221960098, 3: -8.264014148683273, 4: -8.078236330038772}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.20960864715666, 2: -8.097970221960098, 3: -8.264014148683273, 4: -8.251195060335284}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.091010151668732, 2: -7.942825598256953, 3: -8.004898437220215, 4: -8.092479977318007}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.72277073378013}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.72277073378013}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.9277213677399185}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.763741816681699, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.9814030082861676}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.775916074683065, 1: -7.965005053180346, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.9814030082861676}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.130680611460978, 1: -7.9119033299819375, 2: -7.922281140997374, 3: -7.957478490384231, 4: -7.991085050966223}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.086233304753677, 1: -7.994992525811317, 2: -7.803455655468615, 3: -8.045892635297818, 4: -7.9814030082861676}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.577497599278971, 3: -7.604944761673974, 4: -7.790207275456417}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.45913167048321, 2: -8.47297846687878, 3: -8.589307698105346, 4: -8.49652419936508}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.494224621935494 -8.344757174178888 -8.271480954372418 -8.169107567759193 -8.022819478985124 \n",
      "-8.376771467749915 -8.247501515550837 -8.112368367352367 -8.006087980600734 -8.028175880479157 \n",
      "-8.214594926266109 -8.092146717840087 -8.059707244809434 -7.876310060273472 -7.834246415439425 \n",
      "-8.062213975263589 -8.01629895041071 -7.922281140997374 -7.733137895594715 -7.6022003541276195 \n",
      "-8.104886487820647 -7.949726854187601 -7.818118620962828 -7.593112881047305 -8.45913167048321 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.402610849679345, 1: -8.376771467749915, 2: -8.386451966312393, 3: -8.511781468506662, 4: -8.474864386802075}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.216975026639114, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.290736048760028}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.216975026639114, 2: -8.241179263132862, 3: -8.214594926266109, 4: -8.290736048760028}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317138306798302, 1: -8.216975026639114, 2: -8.241179263132862, 3: -8.375281382902159, 4: -8.290736048760028}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.062213975263589, 2: -8.130548449330375, 3: -8.234443774167463, 4: -8.09193003157967}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104886487820647, 1: -8.20960864715666, 2: -8.143485756784143, 3: -8.264014148683273, 4: -8.284475385821208}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.271179452661082, 2: -8.130548449330375, 3: -8.234443774167463, 4: -8.09193003157967}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.271179452661082, 2: -8.130548449330375, 3: -8.234443774167463, 4: -8.09193003157967}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.157273382531809, 1: -8.271179452661082, 2: -8.130548449330375, 3: -8.234443774167463, 4: -8.2636563287375}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.09837006923448, 1: -8.01629895041071, 2: -8.095584046260495, 3: -8.067617002680871, 4: -8.053058433690138}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.098716147589789, 1: -8.091010151668732, 2: -7.949726854187601, 3: -8.004898437220215, 4: -8.092479977318007}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.086233304753677, 1: -7.994992525811317, 2: -7.818118620962828, 3: -8.045892635297818, 4: -7.9814030082861676}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.593112881047305, 1: -7.665238422669106, 2: -7.609646413019298, 3: -7.604944761673974, 4: -7.790207275456417}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.733137895594715, 2: -7.733392091464944, 3: -7.980610386253259, 4: -7.824186057683756}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9231529835364505, 1: -7.665238422669106, 2: -7.609646413019298, 3: -7.604944761673974, 4: -7.790207275456417}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.086233304753677, 1: -7.994992525811317, 2: -7.8322332957446, 3: -8.045892635297818, 4: -7.9814030082861676}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9231529835364505, 1: -7.665238422669106, 2: -7.609646413019298, 3: -8.004603445720523, 4: -7.790207275456417}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.531098055925753, 2: -8.47297846687878, 3: -8.589307698105346, 4: -8.49652419936508}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.494224621935494 -8.344757174178888 -8.271480954372418 -8.169107567759193 -8.022819478985124 \n",
      "-8.386451966312393 -8.247501515550837 -8.112368367352367 -8.006087980600734 -8.028175880479157 \n",
      "-8.241179263132862 -8.092146717840087 -8.059707244809434 -7.876310060273472 -7.834246415439425 \n",
      "-8.157273382531809 -8.053058433690138 -7.922281140997374 -7.733392091464944 -7.6022003541276195 \n",
      "-8.143485756784143 -8.004898437220215 -7.847036924120092 -7.624077199473742 -8.47297846687878 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.401642145349987, 3: -8.505426490143442, 4: -8.344757174178888}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.401642145349987, 3: -8.505426490143442, 4: -8.344757174178888}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.365910581418749, 2: -8.401642145349987, 3: -8.505426490143442, 4: -8.493729028502788}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.269490216382746, 2: -8.247501515550837, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.296419857487543, 1: -8.209608230067769, 2: -8.112368367352367, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -8.006087980600734, 2: -8.05900597743512, 3: -8.106565674334043, 4: -8.10597724081514}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.876310060273472, 2: -7.926679392447442, 3: -7.9697887213192455, 4: -8.040771919382639}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.83331904651539, 2: -7.733392091464944, 3: -7.980610386253259, 4: -7.824186057683756}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.6022003541276195, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.531098055925753, 2: -8.506551157772778, 3: -8.589307698105346, 4: -8.49652419936508}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.494224621935494 -8.401642145349987 -8.271480954372418 -8.169107567759193 -8.022819478985124 \n",
      "-8.386451966312393 -8.268648432937114 -8.196168101021831 -8.031629465419082 -8.028175880479157 \n",
      "-8.241179263132862 -8.092146717840087 -8.059707244809434 -7.926679392447442 -7.834246415439425 \n",
      "-8.157273382531809 -8.053058433690138 -7.922281140997374 -7.824186057683756 -7.629806369542658 \n",
      "-8.143485756784143 -8.004898437220215 -7.847036924120092 -7.624077199473742 -8.49652419936508 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536492378674513, 1: -8.49707016700018, 2: -8.494224621935494, 3: -8.598662337915083, 4: -8.523346894802883}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.417067285738053, 2: -8.401642145349987, 3: -8.505426490143442, 4: -8.525760473799467}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.38413951529238, 1: -8.271480954372418, 2: -8.302210645118677, 3: -8.432314615646877, 4: -8.413444159438903}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.296419857487543, 1: -8.209608230067769, 2: -8.196168101021831, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.031629465419082, 1: -8.080419946881586, 2: -8.05900597743512, 3: -8.106565674334043, 4: -8.10597724081514}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.268141558551331, 1: -8.177282968742832, 2: -8.169107567759193, 3: -8.31158372421556, 4: -8.18462108767846}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.205244262199058, 1: -8.158228762589038, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.205244262199058, 1: -8.158228762589038, 2: -8.022819478985124, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.205244262199058, 1: -8.158228762589038, 2: -8.200765725876462, 3: -8.261275917987374, 4: -8.16209221966073}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.164924893445928, 1: -8.028175880479157, 2: -8.09285107061591, 3: -8.040325363418788, 4: -8.076305766024424}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.834490528075357, 2: -7.90846750136432, 3: -7.834246415439425, 4: -7.952021320245456}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967261453012221, 1: -7.9516786001139526, 2: -7.926679392447442, 3: -7.9697887213192455, 4: -8.040771919382639}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.922482819304067, 1: -7.834490528075357, 2: -7.90846750136432, 3: -8.10403494942637, 4: -7.952021320245456}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.642404636898477, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.642404636898477, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.629806369542658}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.642404636898477, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.843123796283819}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.531098055925753, 2: -8.506551157772778, 3: -8.589307698105346, 4: -8.62997436370426}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.49707016700018 -8.417067285738053 -8.302210645118677 -8.177282968742832 -8.16209221966073 \n",
      "-8.386451966312393 -8.268648432937114 -8.209608230067769 -8.05900597743512 -8.040325363418788 \n",
      "-8.241179263132862 -8.092146717840087 -8.059707244809434 -7.9516786001139526 -7.863592212137089 \n",
      "-8.157273382531809 -8.053058433690138 -7.922281140997374 -7.824186057683756 -7.654546901485798 \n",
      "-8.143485756784143 -8.004898437220215 -7.847036924120092 -7.624077199473742 -8.506551157772778 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.446450256558304, 1: -8.417067285738053, 2: -8.440063787576658, 3: -8.505426490143442, 4: -8.525760473799467}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.269490216382746, 2: -8.295768529110502, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.269490216382746, 2: -8.295768529110502, 3: -8.301865705452048, 4: -8.268648432937114}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.360803557841866, 1: -8.269490216382746, 2: -8.295768529110502, 3: -8.301865705452048, 4: -8.424470073972774}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.196010706702383, 1: -8.16928663819265, 2: -8.092146717840087, 3: -8.095462005137056, 4: -8.218583289591278}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.059707244809434, 1: -8.062768216967035, 2: -8.065926490099875, 3: -8.080579495381096, 4: -8.227752872619728}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.296419857487543, 1: -8.209608230067769, 2: -8.225236677091639, 3: -8.250403179067717, 4: -8.319306037847564}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.355753390835837, 1: -8.062768216967035, 2: -8.065926490099875, 3: -8.080579495381096, 4: -8.227752872619728}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.130680611460978, 1: -8.011989413927772, 2: -7.922281140997374, 3: -7.957478490384231, 4: -7.991085050966223}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.83331904651539, 2: -7.8311214959898665, 3: -7.980610386253259, 4: -7.824186057683756}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.83331904651539, 2: -7.8311214959898665, 3: -7.980610386253259, 4: -7.824186057683756}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02371301476991, 1: -7.83331904651539, 2: -7.8311214959898665, 3: -7.980610386253259, 4: -8.020009312492217}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9717655216163195, 1: -7.654546901485798, 2: -7.699826012343668, 3: -7.681162643144903, 4: -7.874660135516148}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.557345280431914, 1: -8.531098055925753, 2: -8.568479617225101, 3: -8.589307698105346, 4: -8.62997436370426}, Best action: 1, Actual action: 1\n",
      "[133, 60, 49, 39, 32, 50, 14, 53, 33, 29, 69, 15, 85, 48, 24, 80, 47, 49, 46, 7, 44, 32, 31, 42, 29, 40, 64, 21, 55, 26, 24, 51, 55, 21, 26, 37, 34, 13, 32, 36, 33, 33, 54, 30, 30, 19, 24, 26, 17, 15, 32, 40, 15, 17, 46, 25, 43, 15, 18, 35, 21, 19, 17, 26, 13, 18, 34, 31, 7, 26, 22, 27, 23, 12, 13, 20, 11, 15, 27, 18, 20, 25, 21, 38, 9, 15, 12, 13, 10, 21, 11, 16, 15, 19, 20, 26, 17, 9, 16, 13]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(0.9, 0.01, 0.9, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 159)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 49)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 43)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 84)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 97)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 64)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 48)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 50)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 58)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 36)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 68)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 47)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 45)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 82)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 48)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 78)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
